{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 4C16 Lab 5 - Convolutional Neural Nets for Image Classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "\n",
    "import keras\n",
    "from keras import datasets\n",
    "from keras.layers import Dense, Flatten, Dropout, Activation\n",
    "from keras.layers import PReLU, LeakyReLU, Conv2D, MaxPool2D, Lambda\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import pickle\n",
    "import sklearn as skl\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define some useful functions\n",
    "class PlotLossAccuracy(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.acc = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.val_acc = []\n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(int(self.i))\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        \n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(16, 6))\n",
    "        plt.plot([1, 2])\n",
    "        plt.subplot(121) \n",
    "        plt.plot(self.x, self.losses, label=\"train loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"validation loss\")\n",
    "        plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.title('Model Loss')\n",
    "        plt.legend()\n",
    "        plt.subplot(122)         \n",
    "        plt.plot(self.x, self.acc, label=\"training accuracy\")\n",
    "        plt.plot(self.x, self.val_acc, label=\"validation accuracy\")\n",
    "        plt.legend()\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.show();\n",
    "        \n",
    "def save_model_to_disk():    \n",
    "    # save model and weights (don't change the filenames)\n",
    "    model_json = model.to_json()\n",
    "    with open(\"model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"model.h5\")\n",
    "    print(\"Saved model to model.json and weights to model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('loading the dataset...')\n",
    "\n",
    "pkl_file = open('/home/tcd/codiad/workspace/data/cifar10-dataset.pkl', 'rb')\n",
    "dataset = pickle.load(pkl_file)\n",
    "\n",
    "print('loaded.')\n",
    "\n",
    "print('let\\'s look at some of the pictures and their ground truth labels:')\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.plot([3, 3])\n",
    "\n",
    "X = dataset['X'].astype('float32')/255\n",
    "Y = dataset['Y'].astype('float32')\n",
    "Y = keras.utils.to_categorical(Y)\n",
    "\n",
    "for i in range(0,9):\n",
    "    # pictures are 32x32x3 (width=32, height=32, 3 colour channels)\n",
    "    pic = X[i]\n",
    "\n",
    "    # Y[i] returns an array of zeros and with Y[i][classid] = 1\n",
    "    # for instance  Y[i] = [ 0 0 0 0 0 1 0 0 0 0] => classid=5 \n",
    "    #          and  Y[i] = [ 1 0 0 0 0 0 0 0 0 0] => classid=0\n",
    "    # we can get the classid by using the argmax function on the vector Y[i]\n",
    "    classid = Y[i].argmax(-1)\n",
    "\n",
    "    # getting back the name of the label for that classid\n",
    "    classname = dataset['labels'][classid]\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(pic)\n",
    "    plt.title('label: {}'.format(classname))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's split data between validation set and training set\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = skl.model_selection.train_test_split(X, Y, test_size=.1, random_state=0)\n",
    "# print(X_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model below contains 2 hidden layers with 64 nodes each. \n",
    "# The activation functions for these 2 layers is the ReLU\n",
    "# The network ends with a 10 nodes layer with softmax activation\n",
    "# The first 2 hidden layers transform the original features into \n",
    "# a new feature vector of size 64.\n",
    "# The last layer essentially does the classification using multonomial regression\n",
    "# based on these new features. \n",
    "\n",
    "inputs = keras.layers.Input(shape=(32, 32, 3))\n",
    "\n",
    "# Replace these two lines with some convolutional layers;\n",
    "# see keras docs for Conv2D, MaxPool2D, etc.\n",
    "# Maybe stick in some Dropout as well?\n",
    "x = Flatten()(inputs)  # Don't flatten until after your 2D layers \n",
    "x = Dense(30, activation='relu')(x)\n",
    "\n",
    "# The last layers of your model should look something like\n",
    "# this to be well-structured for the final classification:\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(100, activation=None)(x)  # You could have a few more non-2D layers here\n",
    "\n",
    "predictions = Dense(10, activation='softmax')(x)  # There are 10 classes in this problem, hence the '10'.\n",
    "\n",
    "# Create the model.\n",
    "model = keras.models.Model(inputs=inputs, outputs=predictions)\n",
    "opt = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Setup the optimisation strategy.\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display a summary.\n",
    "model.summary()\n",
    "\n",
    "# Keep things sane.\n",
    "if (model.count_params() > 10000000):    \n",
    "    raise(\"Your model is unecessarily complex, scale down!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that you can evaluate this cell repeatedly to push the training of your model further.\n",
    "# You might want to reduce the value of 'num_epochs' if each evaluation starts to take too long.\n",
    "\n",
    "num_epochs = 40\n",
    "\n",
    "# Create an instance of our callback functions class, to plot our loss function and accuracy with each epoch.\n",
    "pltCallBack = PlotLossAccuracy()\n",
    "\n",
    "# Run the training.\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=4096, epochs=num_epochs, \n",
    "          validation_data=(X_validation, Y_validation), \n",
    "          callbacks=[pltCallBack])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write model to model.json and weights to model.h5 for submission\n",
    "\n",
    "save_model_to_disk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In the terminal, add these files to git and submit the lab\n",
    "# Do the following: \n",
    "#  git add lab-05/model.json lab-05/model.h5\n",
    "#  git commit -m \"Added NN model.\"\n",
    "#  git push\n",
    "#  submit-lab 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Question 1: design a network using a mix of convolutional and Dense layers, and achieve 60% accuracy on the server's test set\n",
    "#\n",
    "#  Do 'git commit -a -m \"model update\"' followed by 'submit-lab 5' to check your solution.\n",
    "#\n",
    "# Question 2: push your accuracy up to as high as 80%.\n",
    "#\n",
    "# You may want to test the following:\n",
    "#\n",
    "# Change the architecture: \n",
    "#    for instance you may want to add layers, \n",
    "#    change the number of units per layer, \n",
    "#    change the activation functions\n",
    "#\n",
    "# Always check on your accuray and loss graphs that that you are not overfitting. \n",
    "#\n",
    "# Remember that you can help avoiding overfitting using \n",
    "#   - Dropout [https://keras.io/layers/core/#dropout]\n",
    "#   - Regularisers (eg. L2, L1) [https://keras.io/regularizers/]\n",
    "#\n",
    "# Optimiser. You may get faster convergence using different optimiser that rmsprop (but rmsprop is not bad)\n",
    "#\n",
    "# Learning Rate. You can tune it.\n",
    "##\n",
    "# Also note that Deeper networks will require longer training times.\n",
    "#\n",
    "# Good luck!\n",
    "#\n",
    "#\n",
    "# F.A.Q.\n",
    "#\n",
    "#   I reached 61% on my validation set, but the submission didn't pass, how come? \n",
    "#     > the test set on the server is different from your validation set\n",
    "#   Can I use convolutional layers? \n",
    "#     > You must!\n",
    "#\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}