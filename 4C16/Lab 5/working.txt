print("Accuracy: {0:.2f}%".format((
    model.evaluate(X_validation, Y_validation, verbose=0)[1]) * 100))
		
85.67% -> Could do ~40 epochs?
weight_decay = 1e-4
x = Conv2D(32, (3,3), padding='same', kernel_regularizer=l2(weight_decay), 
           input_shape=X_train.shape[1:])(inputs)
x = Activation('elu')(x)
x = BatchNormalization()(x)
x = Conv2D(32, (3,3), padding='same', kernel_regularizer=l2(weight_decay))(x)
x = Activation('elu')(x)
x = BatchNormalization()(x)
x = MaxPool2D(pool_size=(2, 2))(x)
x = Dropout(0.2)(x)

x = Conv2D(64, (3,3), padding='same', kernel_regularizer=l2(weight_decay))(x)
x = Activation('elu')(x)
x = BatchNormalization()(x)
x = Conv2D(64, (3,3), padding='same', kernel_regularizer=l2(weight_decay))(x)
x = Activation('elu')(x)
x = BatchNormalization()(x)
x = MaxPool2D(pool_size=(2, 2))(x)
x = Dropout(0.3)(x)

x = Conv2D(128, (3,3), padding='same', kernel_regularizer=l2(weight_decay))(x)
x = Activation('elu')(x)
x = BatchNormalization()(x)
x = Conv2D(128, (3,3), padding='same', kernel_regularizer=l2(weight_decay))(x)
x = Activation('elu')(x)
x = BatchNormalization()(x)
x = MaxPool2D(pool_size=(2, 2))(x)
x = Dropout(0.4)(x)

x = Flatten()(x)
predictions = Dense(10, activation='softmax')(x)

opt = keras.optimizers.rmsprop(lr=0.001, decay=1e-6)

model.fit(X_train, Y_train,
          batch_size=64, epochs=125, 
          validation_data=(X_validation, Y_validation), 
          callbacks=[pltCallBack])