{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 4C16 Lab 6 - Self Driving Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### First!  Read https://github.com/frcs/EE4C16-self-driving-lab for more info.\n",
    "\n",
    "### Second!  Read this carefully!\n",
    "\n",
    "# In this lab you will train a neural net to drive a virtual driving simulator,\n",
    "# using data recorded from your own manual operation of the sim.\n",
    "#\n",
    "# Your model will attempt to predict the correct steering angle, given the input\n",
    "# images, using your recorded laps as training data.\n",
    "#\n",
    "# Your model will be operating in cruise control mode; it does not have any throttle\n",
    "# input, and will not be able to reverse.\n",
    "#\n",
    "# Step 1 is to run the simulator on your local machine (within Windows, in the CADLab)\n",
    "# and drive around while recording training data.  For each timestep in your driving,\n",
    "# three images are recorded: the center (straight ahead) view, and also left and right \n",
    "# views.  Your steering angle is also recorded.\n",
    "#\n",
    "# Step 2: You will upload the training data to your cloud instance and train there, to \n",
    "# take advantage of the GPU.\n",
    "#\n",
    "# Step 3: You will download the model and use it to pilot the car around the track ('autonomous mode')\n",
    "#\n",
    "# Step 4: You will upload the record of the car's positions back to your instance using Jupyter\n",
    "#\n",
    "# Step 5: You will 'git add' the record of the car's positions, and 'submit-lab 6' to check your score.\n",
    "#\n",
    "# You can repeat steps 2--5 with more training, more complex models, etc.\n",
    "# You can also repeat step 1 if you decide you need more or more varied training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import some necessary modules.\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Conv2D, Flatten, Lambda, Dropout, Activation\n",
    "from keras.regularizers import l2\n",
    "from keras.models import save_model\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import random\n",
    "import ntpath\n",
    "import csv\n",
    "import PIL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define some callbacks to plot progress of training.\n",
    "class PlotLossAccuracy(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.acc = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.val_acc = []\n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(int(self.i))\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        \n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(16, 6))\n",
    "        plt.plot([1, 2])\n",
    "        plt.subplot(121) \n",
    "        plt.plot(self.x, self.losses, label=\"train loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"validation loss\")\n",
    "        plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.title('Model Loss')\n",
    "        plt.legend()\n",
    "        plt.subplot(122)         \n",
    "        plt.plot(self.x, self.acc, label=\"training accuracy\")\n",
    "        plt.plot(self.x, self.val_acc, label=\"validation accuracy\")\n",
    "        plt.legend()\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def import_csv_data(logfile):\n",
    "    with open(logfile, 'r') as f:\n",
    "        data = list(csv.reader(f, skipinitialspace=True, delimiter=',', quoting=csv.QUOTE_NONE))\n",
    "\n",
    "    # Each row of the CSV contains the data from one timestep of the training recording.\n",
    "    # Column semantics are as follows:\n",
    "    center = 0   # Path (or filename) of image file containing center view\n",
    "    left = 1     # Image file containing left view\n",
    "    right = 2    # Image file containing right view\n",
    "    angle = 3    # Desired orientation of car (steering angle)\n",
    "    accel = 4    # Acceleration (throttle)\n",
    "    stop = 5     # Not sure what this..\n",
    "    speed = 6    # Speed\n",
    "\n",
    "    # Condense the recorded data into a map of image files (input) to steering angle (output).\n",
    "    # Note that in the simulation, when our NN-model is driving, it will be provided the \n",
    "    # only front image as input.\n",
    "    parsed_data = dict()\n",
    "\n",
    "    for row in data:  # 'row' is an array with values corresponding to columns in the CSV.\n",
    "        # Skip examples with a quasi-static car.\n",
    "        if float(row[speed]) < 0.01:\n",
    "            continue  \n",
    "        \n",
    "        center_image = './IMG/' + ntpath.basename(row[center])\n",
    "        left_image = './IMG/' + ntpath.basename(row[left])\n",
    "        right_image = './IMG/' + ntpath.basename(row[right])\n",
    "        \n",
    "        parsed_data[center_image] = float(row[angle])\n",
    "        \n",
    "        # This is a trick to maximize the data available.  Have a think about what is going on here...\n",
    "        parsed_data[left_image] = float(row[angle]) + 0.20\n",
    "        parsed_data[right_image] = float(row[angle]) - 0.20\n",
    "\n",
    "    return parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You should have generated some training data on your local workstation at this point, and the instructions\n",
    "# on how to zip them (https://github.com/frcs/EE4C16-self-driving-lab)\n",
    "\n",
    "# Run this cell to extract the uploaded training data:\n",
    "!rm -rf IMG\n",
    "!unzip -o -qq recordings.zip\n",
    "driving_log = './driving_log.csv'\n",
    "training_data = import_csv_data(driving_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(path_to_jpg):\n",
    "    im = PIL.Image.open(path_to_jpg)\n",
    "    im_width = im.size[0]\n",
    "    im_height = im.size[1]\n",
    "    \n",
    "    # We are going to discard the sky and the car, to focus training on the road.\n",
    "    # This crop isolates that portion.  You can see the effects by changing the values\n",
    "    # and re-evaluating that cell, but they must match the original values (top=50, bottom=140)\n",
    "    # when you train so as to match the input supplied from the simulator.\n",
    "    left = 0\n",
    "    right = im_width\n",
    "    top = 50 # 0\n",
    "    bottom = 140 # im_height\n",
    "    \n",
    "    im = im.crop((left, top, right, bottom))\n",
    "    \n",
    "    # We can shrink the image a bit to reduce training time.\n",
    "    im = im.resize((200, 66), PIL.Image.BICUBIC)\n",
    "    im = np.asarray(im)\n",
    "    return im\n",
    "\n",
    "A = next(iter(training_data.items()))\n",
    "print(A)\n",
    "im = load_image(A[0])\n",
    "plt.imshow(im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_generator(training_data, batch_size, reject_above=True, reject_thresh=0.0):\n",
    "    inputs_batch = []\n",
    "    targets_batch = []\n",
    "    \n",
    "    while True:\n",
    "        random.seed(42)\n",
    "        for idx, (k, v) in enumerate(training_data.items()):\n",
    "            sample = random.random()\n",
    "            reject_item = ((sample > reject_thresh and reject_above) or\n",
    "                        (sample <= reject_thresh and not reject_above))\n",
    "            \n",
    "            if not reject_item:\n",
    "                decoded_image = load_image(k)\n",
    "                # Important--as we've stressed before--to scale the input data to -1..1.\n",
    "                decoded_image = 2.0*decoded_image/255 - 1\n",
    "                label = v\n",
    "\n",
    "                inputs_batch.append(decoded_image)\n",
    "                targets_batch.append(label)\n",
    "\n",
    "            if (len(inputs_batch)+1) % batch_size == 0:\n",
    "                yield (np.asarray(inputs_batch), np.asarray(targets_batch))\n",
    "                inputs_batch.clear()\n",
    "                targets_batch.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define your model in this cell.\n",
    "# See the paper 'End to End Learning for Self-Driving Cars' (Bojarski et al) for some ideas.\n",
    "\n",
    "inputs = Input(shape=(66, 200, 3))\n",
    "\n",
    "x = inputs\n",
    "\n",
    "## Add your layers here.  Go nuts!\n",
    "## (DO NOT ADD A LAMBDA LAYER to scale the input -- which you might see used in other online examples\n",
    "##   -- we do our scaling of input data in the data_generator, above).\n",
    "\n",
    "## Your output is a single float: the desired steering angle.\n",
    "output = Dense(1)(x)\n",
    "\n",
    "model = keras.models.Model(inputs=inputs, outputs=output)\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training.  Re-evaluate this cell repeatedly to train more.\n",
    "batch_size = 64\n",
    "validation_fraction = 0.1  # Probably best to leave this value alone...\n",
    "model.fit_generator(\n",
    "    generator=data_generator(training_data, batch_size=64, reject_above=False, reject_thresh=validation_fraction),\n",
    "    validation_data=data_generator(training_data, batch_size=64, reject_above=True, reject_thresh=validation_fraction),\n",
    "    steps_per_epoch=(1-validation_fraction)*len(training_data)//batch_size,\n",
    "    validation_steps=validation_fraction*len(training_data)//batch_size,\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    "    callbacks=[PlotLossAccuracy()],\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the model to disk (when done training).\n",
    "save_model(model, './model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now: \n",
    "# * download your model using the Jupyter interface\n",
    "# * run the simulator in autonomous mode\n",
    "# * kick off your robot driver (python drive.py model.h5)\n",
    "# * wait for the car to crash, or head happily into the sunset, or whatever\n",
    "# * close or quit the simulator\n",
    "# * terminate your robot driver (ctrl-c in the console window)\n",
    "# * upload the file 'car_positions.npz' from your workstation to the lab-06 dir on your instance (using Jupyter)\n",
    "# * add this file to your repo: git add lab-06/car_positions.npz (in your remote terminal)\n",
    "# * commit this addition: git commit -m 'added car positions'\n",
    "# * 'git push'\n",
    "# * 'submit-lab 6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
