{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 7 - Text generation with LSTM\n",
    "#\n",
    "# Step 1 (not assessed): build and train a model to generate text in the style of a corpus.\n",
    "#\n",
    "# Based on the Keras text generation example (https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py)\n",
    "#\n",
    "# Step 2: build a model to distinguish genuine from fake sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import essential modules\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Activation, Conv1D, Dropout, Flatten\n",
    "from keras.layers import CuDNNGRU, CuDNNLSTM\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.optimizers import RMSprop, Adam, Nadam, SGD\n",
    "from keras.models import Model, Sequential\n",
    "from keras.models import save_model\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras import initializers\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to sample an index from an array of predictions.\n",
    "#\n",
    "# The input array 'preds' should be the output of a text generation model.\n",
    "# The elements contain the values of the units in the final layer.\n",
    "# Each unit corresponds to a character in the text alphabet.\n",
    "# The final layer should have SoftMax activation, and thus the\n",
    "# value corresponds to the 'strength of prediction' of that character\n",
    "# as the next output value---so the maximum value indicates which character\n",
    "# is most strongly predicted (considerd most likely) as the next one.\n",
    "#\n",
    "def sample(preds, temperature=1.0):\n",
    "    # Convert to high-precision datatype (we are going to be manipulating some\n",
    "    # very small values in this function)\n",
    "    preds = np.asarray(preds).astype('float64')  \n",
    "    \n",
    "    # The next line has the effect of raising each prediction value to the power 1/T.\n",
    "    # It's done using logs to improve numerical precision.  This is a kind of value-dependent\n",
    "    # scaling: for T < 1.0 (1/T > 1.0), small values are made smaller (proportionally) than \n",
    "    # large values (unlike a linear scaling, such as multiplication by 0.9, which scales all values\n",
    "    # the same).\n",
    "    #\n",
    "    # Example: Consider that we have only two symbols (letters) in our alphabet, and our \n",
    "    # probabilities are [0.2, 0.8].  A temperature of 1.0 means 'do not adjust the\n",
    "    # probabilities at all', so in this case there will be a 20% chance that the \n",
    "    # function will return 'symbol 0' and an 80% chance  that it will return 'symbol 1'.\n",
    "    # Note that symbol 1 is 4x more likely than symbol 0.\n",
    "    #\n",
    "    # Now: if we supply a temperature of 0.5, our probabilites will be raised to the\n",
    "    # power 1/0.5 = 2, becoming [0.04, 0.64].  These will then be normalized to sum to 1,\n",
    "    # but anyway it is clear that symbol 1 is here 16x (the square of 4x) more likely than \n",
    "    # symbol 0.\n",
    "    #\n",
    "    # Conversely, for a temperature of 2, our probabilities will be raised to 0.5 (square-rooted),\n",
    "    # becoming [.4472, 0.8944] - and so here symbol 1 is only 2x (sqrt of 4x) more likely than\n",
    "    # symbol 0.\n",
    "    #\n",
    "    # So: low temperatures make the distribution peakier, exaggerating the difference between\n",
    "    # values.  High temperatures flatten the distribution, reducing the difference between values.\n",
    "    #\n",
    "    # As the return value is a sample of the manipulated distribution, manipulating it to\n",
    "    # be peakier (by supplying a low temperature) makes the sample more conservative, i.e.\n",
    "    # more likely to pick the highest-probability symbol.\n",
    "    #\n",
    "    # Making the distribution flatter (by suppyling a high temperature) causes the\n",
    "    # sample to be less conservative, i.e. more likely to pick some lower-likelihood\n",
    "    # symbol.\n",
    "    #\n",
    "    # Phew!\n",
    "    preds = np.exp(np.log(preds) / temperature)\n",
    "    \n",
    "    preds = preds / np.sum(preds)  # ensure that probs sum to 1\n",
    "    probas = np.random.multinomial(1, preds, 1)  # take 1 sample from the distribution\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original corpus length: 600901\n",
      "length for training: 480139\n"
     ]
    }
   ],
   "source": [
    "# Decide how much data to use for training.\n",
    "# You might want to reduce this to ~100k for faster experimentation, and then bring it back\n",
    "# to 600k when you're happy with your network architecture.\n",
    "# IMPORTANT: mke sure you end up with a 57-symbol alphabet after reducing the corpus size!\n",
    "# If the number of symbols (shown in the next cell) gets smaller than it was with the full\n",
    "# corpus, bring your sample size back up.  This is necessary because the encoding used for\n",
    "# training must match that used for assessment.\n",
    "#desired_num_chars = 600*1000  # Max: 600893\n",
    "desired_num_chars = 480139  # Max: 600893\n",
    "\n",
    "random.seed(43)  # Fix random seed for repeatable results.\n",
    "\n",
    "# Slurp down all of Nietzsche from Amazon.\n",
    "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path).read().lower()\n",
    "print('original corpus length:', len(text))\n",
    "\n",
    "start_index = random.randint(0, len(text) - desired_num_chars - 1)\n",
    "text = text[start_index:start_index + desired_num_chars]\n",
    "text\n",
    "print('length for training:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " higher, a something deeper, a something below us, a\n",
      "vastly extensive order, (ordnung) a comparative classification\n",
      "(rangordnung), that we perceive: here--_our_ problem!\"\n",
      "\n",
      "[2] rangordnung: the meaning is \"the problem of grasping the relative\n",
      "importance of things.\"\n",
      "\n",
      "[3] uebereinander: one over another.\n",
      "\n",
      "\n",
      "8\n",
      "\n",
      "to what stage in the development just outlined the present book belongs\n",
      "(or is assigned) is something that will be hidden from no augur or\n",
      "psychologist for an instant. but where are there psychologists to-day?\n",
      "in france, certainly; in russia, perhaps; certainly not in germany.\n",
      "grounds are not wanting, to be sure, upon which the germans of to-day\n",
      "may adduce this fact to their credit: unhappily for one who in this\n",
      "matter is fashioned and mentored in an un-german school! this _german_\n",
      "book, which has found its readers in a wide circle of lands and\n",
      "peoples--it has been some ten years on its rounds--and which must make\n",
      "its way by means of any musical art and tune that will captivate the\n",
      "f\n"
     ]
    }
   ],
   "source": [
    "# Let's have a quick look at a random exceprt.\n",
    "#\n",
    "# Caution: Nietzsche might drive you mad: dare you behold more than 1000 of his terrible chars..? \n",
    "sample_length = 1000\n",
    "\n",
    "random.seed(None)  # Seeds random from current time (so re-eval this cell for a new sample).\n",
    "\n",
    "start_index = random.randint(0, len(text) - sample_length - 1)\n",
    "print(text[start_index:start_index+sample_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 57\n",
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¤', '¦', '«', 'ã']\n"
     ]
    }
   ],
   "source": [
    "# Establish the alphabet (set of symbols) we are going to use.\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "print(chars)\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))  # Map to look up index of a particular char (e.g. x['a'] = 0)\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))  # Map to look up char at an index (e.g. x[0] = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 160033\n"
     ]
    }
   ],
   "source": [
    "# Establish a training set of semi-redundant (i.e. overlapping) sequences of maxlen characters.\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []  # Not syntactic sentences, but just sequences of 40 chars pulled from the corpus.\n",
    "next_chars = [] # next_chars[n] stores the character which followed sentences[n]\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160033, 40, 57)\n",
      "(160033, 57)\n"
     ]
    }
   ],
   "source": [
    "# Convert the data to one-hot encoding.\n",
    "# 'x' will contain the one-hot encoding of the training 'sentences'.\n",
    "# 'y' will contain the one-hot encoding of the 'next char' for each sentence.\n",
    "#\n",
    "# \n",
    "# Let's consider that we have N sentences of length L:\n",
    "#\n",
    "# The 'native' encoding is an NxL matrix where element [n][l]\n",
    "# is the symbol index for character at index (l) of sentence (n)\n",
    "# (e.g., say, 5, corresponding to 'e').\n",
    "#\n",
    "# The one-hot encoding is an NxLxS matrix, where S is the \n",
    "# number of symbols in the alphabet, such that element [n][l][s]\n",
    "# is 1 if the character at index (l) in sentence (n) has the\n",
    "# symbol index (s), and 0 otherwise.\n",
    "def onehot_encode(sentence, maxlen):\n",
    "    x = np.zeros((maxlen, len(chars)), dtype=np.bool)\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[t, char_indices[char]] = 1\n",
    "    return x\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    x[i,:,:] = onehot_encode(sentence, maxlen)\n",
    "    y[i, :] = onehot_encode(next_chars[i], 1)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the generator model: a single GRU layer with 128 cells.\n",
    "generator_model = Sequential()\n",
    "generator_model.add(GRU(128, input_shape=(maxlen, len(chars))))\n",
    "generator_model.add(Dense(len(chars)))\n",
    "generator_model.add(Activation('softmax'))\n",
    "\n",
    "# You could experiment with NAdam instead of RMSProp.\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "generator_model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "trained_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence_list(seed_list, length=400, temperature=0.25):\n",
    "    sentence_list_1 = [];\n",
    "    sentence_list_2 = [];\n",
    "    sentence_list_3 = [];\n",
    "    generated_list_1 = [];\n",
    "    generated_list_2 = [];\n",
    "    generated_list_3 = [];\n",
    "    n = len(seed_list)\n",
    "    # copy lists\n",
    "    temperature_1 = temperature\n",
    "    temperature_2 = (temperature + 0.005)\n",
    "    temperature_3 = max(0.01, (temperature - 0.005))\n",
    "    for seed in seed_list:\n",
    "        sentence_list_1.append(seed[:])\n",
    "        sentence_list_2.append(seed[:])\n",
    "        sentence_list_3.append(seed[:])\n",
    "        generated_list_1.append(seed[:])\n",
    "        generated_list_2.append(seed[:]) \n",
    "        generated_list_3.append(seed[:]) \n",
    "    \n",
    "    for i in range(length):\n",
    "      \n",
    "        workdone = (i+1)*1.0 / length\n",
    "        sys.stdout.write(\"\\rgenerating sentences: [{0:20s}] {1:.1f}%\".format('#' * int(workdone * 20), workdone*100))\n",
    "        sys.stdout.flush()\n",
    "            \n",
    "        x_pred_list = np.zeros((n, maxlen, len(chars)))\n",
    "        for j, sentence in enumerate(sentence_list_1):\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred_list[j, t, char_indices[char]] = 1.\n",
    "\n",
    "        start = time.time()\n",
    "        pred_list = generator_model.predict(x_pred_list, verbose=0)\n",
    "        end = time.time()\n",
    "\n",
    "        for j in range(n):\n",
    "            next_index_1 = sample(pred_list[j,:], temperature_1)\n",
    "            next_char_1 = indices_char[next_index_1]\n",
    "            generated_list_1[j] += next_char_1\n",
    "            sentence_list_1[j] = sentence_list_1[j][1:] + next_char_1\n",
    "            next_index_2 = sample(pred_list[j,:], temperature_2)\n",
    "            next_char_2 = indices_char[next_index_2]\n",
    "            generated_list_2[j] += next_char_2\n",
    "            sentence_list_2[j] = sentence_list_2[j][1:] + next_char_2\n",
    "            next_index_3 = sample(pred_list[j,:], temperature_3)\n",
    "            next_char_3 = indices_char[next_index_3]\n",
    "            generated_list_3[j] += next_char_3\n",
    "            sentence_list_3[j] = sentence_list_3[j][1:] + next_char_3\n",
    "    \n",
    "    sys.stdout.write(' - done\\n')\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    generated_list = generated_list_1 + generated_list_2 + generated_list_3\n",
    "    return generated_list\n",
    "\n",
    "def print_sentences(seeds, sentences):\n",
    "    for seed, sentence in zip(seeds, sentences):\n",
    "        print('-'*5)\n",
    "        sys.stdout.write('\\x1b[32m')\n",
    "        sys.stdout.write(sentence[0:len(seed)])\n",
    "        sys.stdout.write('\\x1b[34m')\n",
    "        sys.stdout.write(sentence[len(seed):-1])\n",
    "        sys.stdout.write('\\x1b[m')\n",
    "        sys.stdout.write('\\n')    \n",
    "        sys.stdout.flush()\n",
    "        \n",
    "def pick_sentences(n, maxlen):\n",
    "    global text    \n",
    "    start_index_list = np.random.randint(len(text) - maxlen - 1, size=(1, n)).flatten().tolist()\n",
    "    seed_list = [] \n",
    "    for start_index in start_index_list:\n",
    "        seed_list.append(text[start_index: start_index + maxlen])\n",
    "    return seed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 21s 129us/step - loss: 2.3163\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 17s 104us/step - loss: 1.8255\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 17s 108us/step - loss: 1.66692s - lo - ETA:\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 18s 113us/step - loss: 1.5843\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32my overcast sky of the commencing plebeia\u001b[34mnt and become\n",
      "conscience have coness and become constrative and dear has become constrative and and the\n",
      "comest and and and string of and have conesses of the carable and\n",
      "and moral the preciation and and the careary and are stand of the carable the cantay\n",
      "that it is and and himself and and become conscience of the preciation and the constracity and and\n",
      "and and and surd for the carable the cantay t\u001b[m\n",
      "-----\n",
      "\u001b[32monditions (in fact better than under\n",
      "fav\u001b[34mourance of the comest and become can and the comes of the cantained, and and the\n",
      "certains and and and and and and and history of a conscience of the carabiently and\n",
      "diverst and and become and and and our carable and interrope and and and the cantay the\n",
      "come the strength and and and have constrative and and strength and the\n",
      "comest and and the cantay the cantain the carear of the carnays the\n",
      "precia\u001b[m\n",
      "-----\n",
      "\u001b[32mgranite of spiritual fate, of predetermi\u001b[34mned and and the constractions, and\n",
      "and and and the consciousness and string and the carear of the conscience of a morality and\n",
      "decide its and one contrary and and and the\n",
      "cantain himself and and and the comest and and the cartained and and become can at a carable and and successiving of a conscience of\n",
      "instruction and and and himself and and and and and the constration and the\n",
      "cartay the deed and\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 17s 105us/step - loss: 1.53130s - los\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 18s 112us/step - loss: 1.4926\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 17s 107us/step - loss: 1.4656\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 17s 108us/step - loss: 1.4453\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32my overcast sky of the commencing plebeia\u001b[34mnce the further the comprehention, the freecom one seems the future the comprehention of the comprere the constingratics and the surd the comprere the general the destined the fines the longer the freedom of the conception therefore, the heart, the fully the could not therefore, the furding the consting the present therefore, the the freedom of the most interned the freedom therefore the futured,\u001b[m\n",
      "-----\n",
      "\u001b[32monditions (in fact better than under\n",
      "fav\u001b[34mered the comprehention of the freedom of the conscience therefore, the present therefore the compretent therefore the comprerst the consting the predest the comprere the free such and the comprehention of the comprehention of the senting therefore the sentic the comprehent of the comprehention of the constingrated therefore the present therefore, the comprerst the freedom of the constingricy in t\u001b[m\n",
      "-----\n",
      "\u001b[32mgranite of spiritual fate, of predetermi\u001b[34mnes the comprerst the finesther the falled the sentiment.\n",
      "\n",
      "285. the conception therefore the longer the comprere the only the comprerst interned the comprehention of the the could not therefore, the the comprere the consting the contrarder the freedom of the comprerst the fines the fully the longer the furding the sentially in the comprere the comprerst the love the fines the serious conceated th\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 18s 111us/step - loss: 1.4284\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 17s 108us/step - loss: 1.4149\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 18s 113us/step - loss: 1.4037\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 15s 96us/step - loss: 1.3939\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32my overcast sky of the commencing plebeia\u001b[34mn and propering and seems the proposited the\n",
      "could of presents of propous of perhaps all the sake of perhaps all the feelings of propouse of the same the proposition of perhaps in the properity, in the experience of the order and incernaine is all the sentiments and seems the sentemptines and sense of persuny of perhaps all the sente are all one of persupe of perhaps in the feelings of the enthel\u001b[m\n",
      "-----\n",
      "\u001b[32monditions (in fact better than under\n",
      "fav\u001b[34mourable formula not the end in the properity, and also perhaps and infects of all the free, and in the\n",
      "signify heard of perhaps all morals of present the engend and indisposed the precession of perhaps all the sentiments and propered the proper the sentiments of perhaps all the end the endernal sublemonses of perhaps all the sentiments has been sentiments when all the\n",
      "sentheness of precessions, a\u001b[m\n",
      "-----\n",
      "\u001b[32mgranite of spiritual fate, of predetermi\u001b[34mned and inficutation of all only the end the\n",
      "proper the own and perhaps all a man as a perhaps all the most experience of the\n",
      "contempouncess of presents of presents and experiences, the proper the sentiments and perhaps all the\n",
      "simplession of present they hear philosophers of propounden all men as a sentiments and sentiments and respectant and infects of propounden all the experience of propourd \u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 16s 100us/step - loss: 1.38571s -\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 16s 100us/step - loss: 1.3790\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 16s 103us/step - loss: 1.3696\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 17s 104us/step - loss: 1.3643\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32my overcast sky of the commencing plebeia\u001b[34mns, and the sake and an according and and in themselves themselves and a despreation of a sensities of themselves and an are from all the species and the sake and themselves themselves themselves themselves and the same themselves themselves themselves and a great strigglise and the same themselves in themselves themselves and a desires and an according and and and a desires and the sake the case\u001b[m\n",
      "-----\n",
      "\u001b[32monditions (in fact better than under\n",
      "fav\u001b[34mourable to a strong and freedom of themselves and a great strength, and a desperch, and themselves and an are themselves themselves themselves themselves themselves themselves of a great strength, and a great strength, and a desigeation of a desires of themselves themselves and themselves and that the sake and in a desires and a great strength, and themselves and a desires and a serve of themselv\u001b[m\n",
      "-----\n",
      "\u001b[32mgranite of spiritual fate, of predetermi\u001b[34mner and themselves themselves themselves and themselves themselves themselves and themselves themselves and an and spirituality in themselves themselves and themselves themselves themselves themselves themselves themselves themselves in themselves and themselves and spiritual\n",
      "themselves and a dangerous spiritual themselves and themselves and themselves themselves and in the most species\n",
      "themselve\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 17s 106us/step - loss: 1.3599\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 17s 108us/step - loss: 1.3553\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 17s 105us/step - loss: 1.3502\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 16s 102us/step - loss: 1.3457\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32my overcast sky of the commencing plebeia\u001b[34mn with there is no longer and trues of the same in its lows to always becomes and for the\n",
      "exceptions and and does not and his notion of the constituted and and power of their with an end there is always not of the constraint,\n",
      "and and such a strays of the partic sympathy, in all there is an anything and religions of\n",
      "constraint, and and do and for they deception of long, and and greater and\n",
      "religio\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "\u001b[32monditions (in fact better than under\n",
      "fav\u001b[34moure of the antive into the conclusions, and and there are no an\n",
      "into the forgetful of the profound suppriocial and\n",
      "profound there is always conscience, and and power, and and\n",
      "religion of life there is always notions, and\n",
      "as it world,\" and the constitution of long, and and do so forw and there is and\n",
      "and power of the conclusions and superiors, and there are to such and constitution of moral there\u001b[m\n",
      "-----\n",
      "\u001b[32mgranite of spiritual fate, of predetermi\u001b[34mnative\n",
      "into the end there is also which they law, in the forger and\n",
      "constitution of such a can be a constitution of the constitution of the possle: ye no longer and most decided there is any soul there is an end in the constitution of the facultion, and and posslsed, by himself, there are to such deciding\n",
      "of the conclusions and conscience, and possible, and and there always religions, and which w\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 16s 98us/step - loss: 1.3423\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 16s 102us/step - loss: 1.3401\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 16s 102us/step - loss: 1.33511s \n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 16s 103us/step - loss: 1.3316\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32my overcast sky of the commencing plebeia\u001b[34mn, strivente the most stronger more the only more the old most spiritualized the the old morality, and who short, and procebses that it is the most strivente of the old men and most strivente of the originally only only one of the expresiness, instinctly, when they were the most stronger and process of the originally of his proporred men of the most strive of something intellem, the propority, in\u001b[m\n",
      "-----\n",
      "\u001b[32monditions (in fact better than under\n",
      "fav\u001b[34meing interpreter of the originally of the most strivente and speciality, when they who has hitherto be it who here and the own spirit, when they who short, so the own when in the the ornate of the most strive and profound only the strong, instance, which what is the opinionself who short, of the originally of the most stronger of morals the of the most stronger of the originally of the most spiri\u001b[m\n",
      "-----\n",
      "\u001b[32mgranite of spiritual fate, of predetermi\u001b[34mness, which what is also desires of most stronger of the\n",
      "proporred intellectual may the only only the only and most stronger of the strong, of himselves and most strivente of the most stronger of the most strivenden has extent, of the originally of the most stronger of the most stronger of the most stronger of the obliggenting more of the originally and almost the of the own the of the ornally of\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 16s 103us/step - loss: 1.32940s - lo\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 16s 101us/step - loss: 1.3267\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 17s 107us/step - loss: 1.3229\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 18s 110us/step - loss: 1.3219\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32my overcast sky of the commencing plebeia\u001b[34mn to the good origin to the general inconsideral animals the general the general sense of the generally to the general to the general sense of the general sympathy of the general to the will to man will be\n",
      "of the end, in the world of the general the good of the general to the general to the greatest as a states of the general inconsideral sympathy\n",
      "in the count a grand of the generation of the gen\u001b[m\n",
      "-----\n",
      "\u001b[32monditions (in fact better than under\n",
      "fav\u001b[34mourities of the general state as a greates to the general the general to the general to the good of the general to be of the generally the good of the general soul in the good of the general sympathy of the general to the general the german and state of the general sympathy of something of the good of the entire\n",
      "end of the general man been the general to the general incoment and states and someth\u001b[m\n",
      "-----\n",
      "\u001b[32mgranite of spiritual fate, of predetermi\u001b[34mnes the general sense of the general incountance of the general to the general to the general the general sense of the gains of the general to the general sympathy\n",
      "of something of the general sympathy of the general the general terment of the general state of the good to the good only being one for experiences, an antiglougner of the world and been the general state of the general to the general \u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 16s 101us/step - loss: 1.3185\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 17s 104us/step - loss: 1.3193\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 17s 108us/step - loss: 1.3144\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 17s 105us/step - loss: 1.3109\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32my overcast sky of the commencing plebeia\u001b[34mnism of error of the world of the end have soul and soul and selection, in every one and end of one soul and could and end of one must of the existence of the end of the own of the end and in a possession of one soul itself in a believe of will be it a priousing of a single and end of the end of the expressed in the own enderious of the problems of the end of the end of the extent to the end of o\u001b[m\n",
      "-----\n",
      "\u001b[32monditions (in fact better than under\n",
      "fav\u001b[34mour of the contrary of the intellective in the greater every one what is a master of a great ear and a grame of our sense of the end of one and one and sense of one will deelf of expression of a sentiment of the own such a problems of the end, and in the end and is a properably in a the commonselves of the end and such a properated in the end of the end by the end and in the end of the end of the\u001b[m\n",
      "-----\n",
      "\u001b[32mgranite of spiritual fate, of predetermi\u001b[34mner in the end of the end of the sense of one must expresses of the expressed to be almost in a the end of one soul itself in a probably in the end of the own sense of a generation of the end of the entire and end of the expression of one some mate a sense of our sentiment of the old a properable and enough of the end to believe of the end of the good could and end of the end of the end of the en\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 16s 102us/step - loss: 1.3091\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 17s 105us/step - loss: 1.3065\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 18s 112us/step - loss: 1.3055\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 20s 124us/step - loss: 1.3053\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32my overcast sky of the commencing plebeia\u001b[34ml feeling themselves and the finally the fact themselves themselves and the fact themselves of the finally the fact that is the find the fact the find the fact themselves and the fact themselves and the former the fact in the fact themselves themselves themselves a man with a mind all the feeling themselves of the feeling themselves the fact that the learn the fact themselves and the fact themsel\u001b[m\n",
      "-----\n",
      "\u001b[32monditions (in fact better than under\n",
      "fav\u001b[34mourable the preterrance of the fact themselves and the fact that is a man themselves almost the find here at the fact themselves a man who the german the feeling themselves as a man with the find a man the feeling themselves of the feeling themselves and the feeling themselves themselves and the french; all the feeling themselves themselves and experiences and the feeling the former the great fac\u001b[m\n",
      "-----\n",
      "\u001b[32mgranite of spiritual fate, of predetermi\u001b[34mness and the fact themselves and all the finally the feeling themselves the find the first all the fact themselves and here as the fact themselves the finally the fact themselves the finally and the nearly the fact themselves the fact thereby in the feeling themselves the feeling themselves and the heart the feeling the fact that therefore the great fact themselves and all the fact the feeling th\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 16s 100us/step - loss: 1.3013\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 17s 106us/step - loss: 1.3012\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 17s 106us/step - loss: 1.2988\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 19s 119us/step - loss: 1.2984\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32my overcast sky of the commencing plebeia\u001b[34mn more originally antithere or the words of the originally and present originate of the more originate of the\n",
      "right to the more originate of the most spirits who world of the more originate of the more originally and conception of the words of the originated to the something of the words in the words in the most spirits who were the more originate of the most souls of the originate of the more or\u001b[m\n",
      "-----\n",
      "\u001b[32monditions (in fact better than under\n",
      "fav\u001b[34mourities of the words of the common of the more origing in the world of the more originate of the more originate of the more originate of the sould of the more originate originate of the words of the most something\n",
      "the problem of the sould or the will to the inclinementation of the words of the existence of the power, what is generality in the more originate of the one with the will to the more o\u001b[m\n",
      "-----\n",
      "\u001b[32mgranite of spiritual fate, of predetermi\u001b[34mne in the common in the form of the form of the more originated to the form of the more originate of the more originated to the words in its consident of the inclinementation of the originate origing in the form of the most something of the originate originate origing in the form of the form of the words of the words of the more originated to the more originate of the more originate of the one or\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 17s 104us/step - loss: 1.2980\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 17s 103us/step - loss: 1.2944\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 17s 104us/step - loss: 1.2951\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 17s 104us/step - loss: 1.2947\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32my overcast sky of the commencing plebeia\u001b[34mn than the senting the sentiment of the well and seems to the sense of the sentiment the for the experience of the same the sentiment of the selded to the sentiment the sentiment the sentiment the soul, the sentiment of the sense of the sentiment of the sentiment that seems the selded to are soulful has the sentiment the same experience and seems to say the sentiment of the serious than the soul,\u001b[m\n",
      "-----\n",
      "\u001b[32monditions (in fact better than under\n",
      "fav\u001b[34mourand and seems to the same experience and superficiate the senting the sentiment the same will to the sentiment the conditional of the senting the sentiment the philosophers of the sense of the sentiment the sentiment of the sentiment the sentiment the same who are seems the soul, and the same conditions and soul\n",
      "from the sentiment the sentiment of the sentiment the for the same the sentiment t\u001b[m\n",
      "-----\n",
      "\u001b[32mgranite of spiritual fate, of predetermi\u001b[34mngly the senting the sentiment and sorts of the sentiment of the sentiment of the stregut even in something the sense of the sentiment of the sense of the sentiment of the sentiment the strettous of the sentiment and soulfly and seems to the sense of the sentiments of the sentiment and seems to seems the soul the senting the sentiment the same conception of the selded and the same and sort of the\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 17s 109us/step - loss: 1.2920\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 18s 110us/step - loss: 1.2908\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 17s 106us/step - loss: 1.2918\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 18s 110us/step - loss: 1.2900\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32my overcast sky of the commencing plebeia\u001b[34mn to a many of the soul, and the most and all of the sensiterly and almost and in the entirs, and the most and perspective and as the same way to the slave another and always an\n",
      "immediate precisely and and and and and in all that it is always and in the sensity and even that they are the perspective and accord all of the anternal\n",
      "and individuality of all that is all an entings and any most things\u001b[m\n",
      "-----\n",
      "\u001b[32monditions (in fact better than under\n",
      "fav\u001b[34mourent and the sensiter and entires to the and and and of the soul, and in the same any of the perspective and any most all any objection of all that it is always an\n",
      "interpreted the soul and above all of the same manifested in the origin, which is always and in all the generally and any opinions and remain that the new and in the problem we nowadly of a\n",
      "passion of all the personal many personal m\u001b[m\n",
      "-----\n",
      "\u001b[32mgranite of spiritual fate, of predetermi\u001b[34mss, and and in the origin what is always and in the soul, and in the soul, which the same any colless and entired to all the man, the lassing and individuality, and and the most soul, and and a personal many of all that they are nowadays of the actually to the actually and all an enting and the many many of all the soul and\n",
      "individuality of all the soul, and and in the most many sould of the germ\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 16s 102us/step - loss: 1.2875\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 16s 101us/step - loss: 1.2861\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 16s 102us/step - loss: 1.2868\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 16s 102us/step - loss: 1.2848\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32my overcast sky of the commencing plebeia\u001b[34mnism of the part of the problems of the persptches and has been the passion of the conscious to the problems of the problems of the possible the pass of the present-to concealed and concernets of the problems of the world and feeling to the princess of the problems of the persptches and the possible, the stands the same the probable the world of the persptches to the problems of the problems of t\u001b[m\n",
      "-----\n",
      "\u001b[32monditions (in fact better than under\n",
      "fav\u001b[34mourible the problems of the problems of the persptcis is an entity of the present-to the problems of the problems of the world of the problems of the present, and and to the problems of the passionally the problems of the way to the probable the passion of the passionally and probably the problems of the possible, the possible, the problems of the possible the\n",
      "problems of the persptches the probl\u001b[m\n",
      "-----\n",
      "\u001b[32mgranite of spiritual fate, of predetermi\u001b[34mne and the persptcis in the problems of the problems of the problems of the problems of the problems of the problems of the present, and to the problems of the possible, and the possible, and the problems of the way to provost and taste and countrance to the problems of the persptcis and the possible, the passion of the sense of the sense of the problems of the problems of the problems of the pos\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 19s 117us/step - loss: 1.2819\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 20s 124us/step - loss: 1.28100s - loss: 1.28\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 18s 111us/step - loss: 1.2810\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 17s 106us/step - loss: 1.2791\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32my overcast sky of the commencing plebeia\u001b[34mn the fact the philosopher the philosopher the from the person that the problem the philosopher the formula the philosopher the fact that the philosophers that the heart of the fact, the morable the point that the philosopher the philosopher the philosopher the philosopher the formula not the higher and the person which the problem than the free spirit, the most and the belief in the free spirit,\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "\u001b[32monditions (in fact better than under\n",
      "fav\u001b[34mour the philosopher the problem the philosopher the problem the fortunate the philosopher, the philosopher, and the problem the philosopher the formula the free and actuation of the philosopher, the formula the philosopher the fact the philosopher the former conception to the fact the philosopher the philosopher the philosopher the free spirit, the philosopher the heart the problem the philosophe\u001b[m\n",
      "-----\n",
      "\u001b[32mgranite of spiritual fate, of predetermi\u001b[34ms that the philosopher the fortunate the fact that the philosopher the philosopher the fasted the philosopher the morable the philosopher the fortunate the problem the philosopher the fact, the free spirit to the philosopher, the politics, the philosopher, and the philosopher, the problem the philosopher to the philosopher, the philosopher the philosopher the feetion to the philosophers that the \u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 16s 100us/step - loss: 1.2786\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 14s 91us/step - loss: 1.2776\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 15s 91us/step - loss: 1.2794 0s - loss: 1\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 14s 88us/step - loss: 1.2742 0s - los\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32my overcast sky of the commencing plebeia\u001b[34mn constant and something and all matter and art and a man is an antithest and society and self-constant and such a masisty of all mankind and securious and a casis and most animals itself is a masisame it is an advantorical sirration of a man is an antization, and as it sees in the end of a make and and a masistiple so an and all most delicate and a constituted in a social sensation of a problem \u001b[m\n",
      "-----\n",
      "\u001b[32monditions (in fact better than under\n",
      "fav\u001b[34mour of a mass in such a man is a constant of all matter and social sensation of an and art in something of all matter and soul and a constituted in the sake of the iness, and a make and self-constant and all matter and most animals it is a masisting something in the sensation and every symonish and accord and a certain and interested and a constant and a man is an antization of all matter and sel\u001b[m\n",
      "-----\n",
      "\u001b[32mgranite of spiritual fate, of predetermi\u001b[34mnes and sacrifice and art in such a similar of all material existed and a finer and every one would have all seeks and self-constant and social sixuative and mension and artisted and art of an and sensation of a man is an and ask to our interested and and society and ask to a man is an antithest and self-conternals of all manifold and something and soul and a masistimate so are as a something and\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 14s 88us/step - loss: 1.2750 3s - l\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 14s 89us/step - loss: 1.2732\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 14s 88us/step - loss: 1.2720\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 14s 89us/step - loss: 1.2716\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32my overcast sky of the commencing plebeia\u001b[34mlise of the others to say thus outed to some contradicates in the other\n",
      "prove and and contradictionated and always the stretter and always the soul, and to the contradical\n",
      "contradical from the contradicredly to a good and to say to always the states of the soul, and to the contradical\n",
      "contradical struggle and always the contradical\n",
      "cannot and to the victentance of the contradical from the most co\u001b[m\n",
      "-----\n",
      "\u001b[32monditions (in fact better than under\n",
      "fav\u001b[34mourable and masters of the compresented to the soul, and as the stretting and always the strongly and the stranges of the soul, thus the good and most contradical\n",
      "contradical belief in the struggen to the soul than our strengers of the standards and to the stretting and to the opposite and always the victer and contempo, to the soul, thus\n",
      "conduct to the states, and to always the strangeless to th\u001b[m\n",
      "-----\n",
      "\u001b[32mgranite of spiritual fate, of predetermi\u001b[34mned that the strangelistic\n",
      "contradictions, and to the stage assurely manner, to the soul, and to the stretted, and to the strong to the struggen and the stronger of all to always the truth of the soul, and of the states, as it stuption, and to the strongly and to conversed of the forgotten to the\n",
      "contradictions, as it states of the soul, in the soul, which is and the soul, the stranges of the str\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 14s 89us/step - loss: 1.2706\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 14s 88us/step - loss: 1.2697\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 14s 90us/step - loss: 1.2704\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 14s 89us/step - loss: 1.2669\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32my overcast sky of the commencing plebeia\u001b[34mted is it is things of things. there is an intellectual and possible in things. the stray is loves and things. the individual.\n",
      "\n",
      "14gus of things. thing and in things. thing it is things?\n",
      "\n",
      "292ule: this possiblen in things. thing it is the individual.\n",
      "\n",
      "14. wild to say things? ye things soul things low there is no longer philosopher is still struggle to a stards in the like and things. the exceptions\u001b[m\n",
      "-----\n",
      "\u001b[32monditions (in fact better than under\n",
      "fav\u001b[34mour, in short, the inding things? shous\n",
      "things. the individual. things low is a strength of the struggle to distrust of loves and things (which is a statuse moral it is loves and in the strong, and is things low only the individual.\n",
      "\n",
      "14. thing of strength in things. there is an instinctly in the strive of it is things lost and the like succeedence of the strong, things low the disguised things lo\u001b[m\n",
      "-----\n",
      "\u001b[32mgranite of spiritual fate, of predetermi\u001b[34mned the constant indifferent in struggle things?) have is strong, the individual.\n",
      "\n",
      "14gus of things. there is no longer kepority of it is struggle for the destructions, the in it is a man is a strength is things be such a man disgust in things? ye the disgust of the inding to the disguised things low thereby is strong, the like struggle for the delight to the constant in the sense and in the most \u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 14s 89us/step - loss: 1.2686\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 14s 88us/step - loss: 1.2664\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 16s 98us/step - loss: 1.2676\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - ETA: 0s - loss: 1.266 - 15s 96us/step - loss: 1.2658\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32my overcast sky of the commencing plebeia\u001b[34mtion of the granded that they will the faire that the granded to the most the most more temperare the thing that it is that the most the philosophical things. the great far as the pain that the most strength what the most more the themselves the thing that the most disgunge that the granded to the sake the first the most strigg--that there that there is not the philosophy in the great the stated \u001b[m\n",
      "-----\n",
      "\u001b[32monditions (in fact better than under\n",
      "fav\u001b[34mourity to the granded to the most struggle that the great profound general that the most same entire the thing that the granded that the lightion of the granded the granded to the truth who that the most more the the the instinctly that the most the truth who has been that the most subtlety and the granded the granded that the truth is not that there is not the faire that the great the same\n",
      "thing\u001b[m\n",
      "-----\n",
      "\u001b[32mgranite of spiritual fate, of predetermi\u001b[34mne which they will the latter to the problems of the grangess and the most same experiences and passions of the fortunity--that the transition of the grangess and temptation and philosophers of the sake and the most the most the philosophical things. the granded thing that the most more to the same philosophy is almost the most far the thing that the most stated the faire that the most states the\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 14s 90us/step - loss: 1.2657\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 15s 91us/step - loss: 1.2660\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 14s 90us/step - loss: 1.2642\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 15s 94us/step - loss: 1.2645\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32my overcast sky of the commencing plebeia\u001b[34mn strungments to the most the most strung that the most man would be to the most social sympathy and the most spirit (as the most strung the most strung to the most strong the sensative man with the most strong the general with the most such a sholism of the most strength is a sort of the most strength is a sort of mankind. the most strung the most such a man with the most strength and the most s\u001b[m\n",
      "-----\n",
      "\u001b[32monditions (in fact better than under\n",
      "fav\u001b[34moly and the most strong and the most strong, to the most spirit, and the most society to the most strong the sensative to the most more to the most into the most strong the moventing and the most more to the most strong, to be truth of the most the most strong the most spirit, the most more stronges to the sensative and the most spirit (gently the most spirit, and the most man would not be true t\u001b[m\n",
      "-----\n",
      "\u001b[32mgranite of spiritual fate, of predetermi\u001b[34mne to the spirits with more to the most science and the general belief is the most strong, to the most science of mankind more soul, and the most intercert and the most spirit, and the most man would be the sensative man the most spirit (gently the most and the most stronget and the most spirit (gently the most shoon to the most strung to the same temptic long the most social soul and the most st\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 15s 94us/step - loss: 1.2648 4s - - ETA: 3s -  - ETA - ETA: 0s - loss\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 15s 94us/step - loss: 1.2627 0s - loss:\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 15s 92us/step - loss: 1.2621\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 15s 91us/step - loss: 1.2617\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32my overcast sky of the commencing plebeia\u001b[34mnce of all most intercolutions, and and intercolul will to as intercolves of mankind.\n",
      "\n",
      "[1]--dle in its intercolurity of the \"good and \"the most and \"sense\" as \"the \"something of mankind,\" as surbords and as mankind with \"modern \"good\" and \"instance in \"contennessions,\" as in a soul, with morals as impossible, as something of all most intercolved in itself as a something and most same the most des\u001b[m\n",
      "-----\n",
      "\u001b[32monditions (in fact better than under\n",
      "fav\u001b[34mourities of all same enough to be man is a condemne himself to as morals some of a man who has been most soul, as impossisated and who has been and the most sudden from an and most and soul, as a great enough of a man who has a something of the enough to as intercolves as its essent of a man and strong, and some everything in the experience, as the most and from the most and \"concequms, and \"inst\u001b[m\n",
      "-----\n",
      "\u001b[32mgranite of spiritual fate, of predetermi\u001b[34mned and the most as the most enough and misknown, and as in the most and most interpreters of a man in the common as its enight in itself as in the expense of mankind, as a mask to as morals to be the conditions of a man and something and desire, herd in the most sight of a bad and man in instruments of a proposingling of a man in a former fortunate and strongest soul, as a man as in itself as in\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# Generate 3 seeds which we will use to inspect the progress of our training:\n",
    "#preview_seeds = pick_sentences(3, maxlen=40)\n",
    "\n",
    "# Train the model, output generated text after each iteration\n",
    "for iteration in range(1, 10):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    generator_model.fit(x, y,\n",
    "                  batch_size=1024,\n",
    "                  epochs=4)\n",
    "\n",
    "    #generated_sentences = generate_sentence_list(preview_seeds)\n",
    "    #print_sentences(preview_seeds, generated_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32moint of\n",
      "view--a magic apprehension (in e\u001b[34mverything in morals to as man as in the\u001b[m\n",
      "-----\n",
      "\u001b[32mld understand what i was then doing. in\n",
      "\u001b[34mthe most shates of the most interpreter\u001b[m\n",
      "-----\n",
      "\u001b[32mugh everyone must\n",
      "go through\" in whom an\u001b[34md \"instance of \"themselves,\" as in musi\u001b[m\n",
      "-----\n",
      "\u001b[32m all these manifestations of power. fina\u001b[34ml deep out of a man in its intercolutin\u001b[m\n",
      "-----\n",
      "\u001b[32mtonomously evolving, but grow up in conn\u001b[34mection, and in morals in itself as in t\u001b[m\n",
      "-----\n",
      "\u001b[32mhis sense we hear of moral feelings, of \u001b[34mthe enough of all most interpreters in \u001b[m\n",
      "-----\n",
      "\u001b[32m brought into play through the medium of\u001b[34m all most interpreters as to be man in \u001b[m\n",
      "-----\n",
      "\u001b[32mf his virtues, and of super-abundance of\u001b[34m all most subjecte of a man and masters\u001b[m\n",
      "-----\n",
      "\u001b[32m that one should lend a\n",
      "fine and patient\u001b[34m and some to as morals in itself as a f\u001b[m\n",
      "-----\n",
      "\u001b[32my\n",
      "atavism, that the ordinary man, even a\u001b[34mnd as the most shado and as in music an\u001b[m\n",
      "-----\n",
      "\u001b[32mpticism despises\n",
      "and nevertheless grasps\u001b[34m, and in morals in music, and as interc\u001b[m\n",
      "-----\n",
      "\u001b[32m make an exception in the case of descar\u001b[34mistance of a man and sense of a man and\u001b[m\n",
      "-----\n",
      "\u001b[32mng on. a philosopher: alas, a being who \u001b[34mhas been and desires, and as in the mos\u001b[m\n",
      "-----\n",
      "\u001b[32mt give up their\n",
      "\"responsibility,\" their \u001b[34msoul, as in many and soul, as intercolv\u001b[m\n",
      "-----\n",
      "\u001b[32mhe master; small and great expediencies \u001b[34mof all most and most and deeperoms of t\u001b[m\n",
      "-----\n",
      "\u001b[32mn demonstrated by or through kant and sc\u001b[34mience, as intercolves of a man as its i\u001b[m\n",
      "-----\n",
      "\u001b[32ml world) and the world known to us: so t\u001b[34mhe most shate as in the most subjecte o\u001b[m\n",
      "-----\n",
      "\u001b[32mthe man of an age of dissolution which m\u001b[34mastering and more of the most and most \u001b[m\n",
      "-----\n",
      "\u001b[32m for instance, the after-effect of schop\u001b[34menhauer of all morality, as a masters o\u001b[m\n",
      "-----\n",
      "\u001b[32m and epochs it is the rule.\n",
      "\n",
      "157. the th\u001b[34mink, as a masters and most same \"instru\u001b[m\n",
      "-----\n",
      "\u001b[32msh; so that it is a perversion of the fa\u001b[34mith is a man as in the experience of al\u001b[m\n",
      "-----\n",
      "\u001b[32mner form of poisoning is\n",
      "in fact a step \u001b[34mof the most shates of the most subjecte\u001b[m\n",
      "-----\n",
      "\u001b[32mthat unscrupulous enthusiast for big, ha\u001b[34ms been and as the most shated and as in\u001b[m\n",
      "-----\n",
      "\u001b[32m, this english christianity\n",
      "itself has s\u001b[34mur as some and soul, as in music and mo\u001b[m\n",
      "-----\n",
      "\u001b[32m this law, which is here\n",
      "called \"primord\u001b[34mializations\" as in itself as in itself \u001b[m\n",
      "-----\n",
      "\u001b[32ms i have said, his whole workmanlike lab\u001b[34moriestinery in itself as a man as its i\u001b[m\n",
      "-----\n",
      "\u001b[32mst\n",
      "right, but without being obliged to d\u001b[34meed and some and desires, and in the ex\u001b[m\n",
      "-----\n",
      "\u001b[32mmake also the bad counter-reckoning agai\u001b[34mnst as morals in the most shated and as\u001b[m\n",
      "-----\n",
      "\u001b[32mank; there is a delight in the nuances\n",
      "o\u001b[34mf a man and senses and interpreters as \u001b[m\n",
      "-----\n",
      "\u001b[32minto play through the medium of exact th\u001b[34me most subjectements of a man and some \u001b[m\n",
      "-----\n",
      "\u001b[32mthe legitimate\n",
      "lord over all the other i\u001b[34mntercolured in the expense of the enoug\u001b[m\n",
      "-----\n",
      "\u001b[32mfine enough for it! it was precisely owi\u001b[34mng of a man in its intercoluting and mo\u001b[m\n",
      "-----\n",
      "\u001b[32mto continue such\n",
      "investigations? mankind\u001b[34m as interprome to as morals in itself a\u001b[m\n",
      "-----\n",
      "\u001b[32montempt. it belongs\n",
      "to the overshadowing\u001b[34m and as intercolous of a man and some m\u001b[m\n",
      "-----\n",
      "\u001b[32m he will suffer from such a view of thin\u001b[34mgs, and as intercolves as the most and \u001b[m\n",
      "-----\n",
      "\u001b[32mof eternal loss and eternal\n",
      "extravagant \u001b[34min itself as a man as in the most shado\u001b[m\n",
      "-----\n",
      "\u001b[32md of silence, of concealment. he who\n",
      "has\u001b[34m been and so much and masters of a man \u001b[m\n",
      "-----\n",
      "\u001b[32me-retailer, \"that i honour and respect a\u001b[34ms \"instructive,\" as in the enough of al\u001b[m\n",
      "-----\n",
      "\u001b[32mthe eyes\n",
      "are open and the senses awake, \u001b[34mas a masters of the enough of all most \u001b[m\n",
      "-----\n",
      "\u001b[32me's morality.\n",
      "\n",
      "96. one should part from \u001b[34mthe most shing of a man as intercolves \u001b[m\n",
      "-----\n",
      "\u001b[32mwill, can surely find satisfaction. the \u001b[34mmost soul and most sense of a man and s\u001b[m\n",
      "-----\n",
      "\u001b[32mfor metaphysical views inspire the\n",
      "belie\u001b[34mf in itself as a masters of the enough \u001b[m\n",
      "-----\n",
      "\u001b[32mask; nay, more,\n",
      "around every profound sp\u001b[34mirits, as a conscience of all the most \u001b[m\n",
      "-----\n",
      "\u001b[32m that woman must be preserved, cared for\u001b[34m the enough of all most interpround and\u001b[m\n",
      "-----\n",
      "\u001b[32mle in the \"nature of things.\"\n",
      "he, howeve\u001b[34mr, as in men of a man as in the experie\u001b[m\n",
      "-----\n",
      "\u001b[32mh have an eye only\n",
      "for the degenerating)\u001b[34m, in morals in itself as a man as in th\u001b[m\n",
      "-----\n",
      "\u001b[32mning thee! thy old fable might once more\u001b[34m as a man as in the most and most shado\u001b[m\n",
      "-----\n",
      "\u001b[32msoling, lightening,\n",
      "charming existence? \u001b[34mas in the enough of all most subjecte o\u001b[m\n",
      "-----\n",
      "\u001b[32mise, for a\n",
      "cloak, in short, for an outsi\u001b[34mde and sense of the most and desire, by\u001b[m\n",
      "-----\n",
      "\u001b[32munt of which we hold our grandfathers in\u001b[34m the most soul and some mannich in the \u001b[m\n",
      "-----\n",
      "\u001b[32mthe new\n",
      "generation, which has inherited \u001b[34min the \"good\" and \"the most \"free \"spir\u001b[m\n",
      "-----\n",
      "\u001b[32mions, in\n",
      "which everything still lies loc\u001b[34mk--the condemue of a man and masters of\u001b[m\n",
      "-----\n",
      "\u001b[32mn the good conscience of his tolerance, \u001b[34mand as in the most and most and desire,\u001b[m\n",
      "-----\n",
      "\u001b[32mo another,\n",
      "that the requirement of one m\u001b[34must be more most same \"instruments\" of \u001b[m\n",
      "-----\n",
      "\u001b[32mr family and\n",
      "origin, in view of such rep\u001b[34mlate a man as in the exception of all m\u001b[m\n",
      "-----\n",
      "\u001b[32mo singular a point of\n",
      "view--a magic appr\u001b[34momance of all sense of a man who has be\u001b[m\n",
      "-----\n",
      "\u001b[32mberant, and vivacious man, who has\n",
      "not o\u001b[34mf the most and sense of the enough of a\u001b[m\n",
      "-----\n",
      "\u001b[32m that inner world called \"man\"; as surve\u001b[34mrent of all most interpround and desire\u001b[m\n",
      "-----\n",
      "\u001b[32m; the next century will bring the strugg\u001b[34mle of a man as in itself as in itself a\u001b[m\n",
      "-----\n",
      "\u001b[32md[ness] is\n",
      "incorporated into the motive \u001b[34mand shated and as intercolves of the en\u001b[m\n",
      "-----\n",
      "\u001b[32ming sublime,\n",
      "up to the highest and most \u001b[34mstrong, as a conception of a man and so\u001b[m\n",
      "-----\n",
      "\u001b[32mt different with shakespeare, that marve\u001b[34mrstimes to as morals to as morality, as\u001b[m\n",
      "-----\n",
      "\u001b[32mong to the whole of\n",
      "this exuberant and e\u001b[34mverything of a man and some many and mo\u001b[m\n",
      "-----\n",
      "\u001b[32min its essence a thing unto itself, ther\u001b[34meby as the most and designated and as i\u001b[m\n",
      "-----\n",
      "\u001b[32muperiority, in the good conscience of hi\u001b[34ms own soul as the most and soul and som\u001b[m\n",
      "-----\n",
      "\u001b[32mncern is appearance and beauty. let us c\u001b[34monceques of a man is an another as to b\u001b[m\n",
      "-----\n",
      "\u001b[32mng.=--there are circumstances in which\n",
      "s\u001b[34mome to as masters and some to be man is\u001b[m\n",
      "-----\n",
      "\u001b[32mlet us not, however shrink from this pai\u001b[34mnters, and in the most sense of a man o\u001b[m\n",
      "-----\n",
      "\u001b[32ming from the outside, and not\n",
      "from the i\u001b[34mnterpretation, as a masters and most sa\u001b[m\n",
      "-----\n",
      "\u001b[32mlso who has power\n",
      "over himself, who know\u001b[34mn be a man as in the most and most and \u001b[m\n",
      "-----\n",
      "\u001b[32mloves\n",
      "error, because, as living itself, \u001b[34mas in all the most shated and as interc\u001b[m\n",
      "-----\n",
      "\u001b[32mose, in its mixture of\n",
      "stiffness and ele\u001b[34mments of all soul, as the most and most\u001b[m\n",
      "-----\n",
      "\u001b[32mience, for the preservation of all the s\u001b[34mame \"prosessions\" as in the most and mo\u001b[m\n",
      "-----\n",
      "\u001b[32m all to bow before the gradations of\n",
      "ran\u001b[34mk, as a masters and sense of a man and \u001b[m\n",
      "-----\n",
      "\u001b[32med; come into contact with the sick and \u001b[34mdeeperom of a man who has been and and \u001b[m\n",
      "-----\n",
      "\u001b[32modness, patience, and spirituality. one\n",
      "\u001b[34mshould be more in the most shate as in \u001b[m\n",
      "-----\n",
      "\u001b[32m\n",
      "conceived, it is a sort of logical viol\u001b[34mety and desigange of a man and masters \u001b[m\n",
      "-----\n",
      "\u001b[32msophie, c'est-a-dire\n",
      "pour voir clair dan\u001b[34mgerous in the most subjecte of a man an\u001b[m\n",
      "-----\n",
      "\u001b[32ms some slight admixture of satiety\n",
      "and s\u001b[34mome conceptions and standard as in itse\u001b[m\n",
      "-----\n",
      "\u001b[32mriacs, invalids, in\n",
      "part persons over-in\u001b[34m itself as a masters and most soul, as \u001b[m\n",
      "-----\n",
      "\u001b[32mality, has kept europe for a considerabl\u001b[34me of a man who has been and as its inte\u001b[m\n",
      "-----\n",
      "\u001b[32mible\n",
      "outbursts against those who refused\u001b[34m in itself as in the most shado and as \u001b[m\n",
      "-----\n",
      "\u001b[32mally, gives us to understand by his mora\u001b[34mlity, and as interestems that in the mo\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "\u001b[32men and painted thoughts! not\n",
      "long ago yo\u001b[34mus and soul as the most shated and as i\u001b[m\n",
      "-----\n",
      "\u001b[32manliness of that which is called \"sympat\u001b[34mhy of \"the \"good\" and \"free spirits,\" a\u001b[m\n",
      "-----\n",
      "\u001b[32mours, perhaps, many variegated\n",
      "softening\u001b[34m and senses and standard as a mask of a\u001b[m\n",
      "-----\n",
      "\u001b[32mward distrust which lies at the bottom o\u001b[34mf a man who has been and most same \"ins\u001b[m\n",
      "-----\n",
      "\u001b[32merely\n",
      "to perceive:--in effect, they have\u001b[34m as a masters of the enough of all mora\u001b[m\n",
      "-----\n",
      "\u001b[32mfirst impulse of rage\n",
      "on finding them, i\u001b[34mn many of the enough to as morals in mo\u001b[m\n",
      "-----\n",
      "\u001b[32mon whether, in respect to the\n",
      "valuation \u001b[34mof all masters and sense of a man and m\u001b[m\n",
      "-----\n",
      "\u001b[32mion in tolerance which\n",
      "the imperium roma\u001b[34mn of a man and standards and as the mos\u001b[m\n",
      "-----\n",
      "\u001b[32my\n",
      "bondages of life have fallen away to s\u001b[34may standary as its enough of all morali\u001b[m\n",
      "-----\n",
      "\u001b[32m things around him he never spoke explic\u001b[34mation of a man of a man as to be man in\u001b[m\n",
      "-----\n",
      "\u001b[32mbelieve in eternal life in order to...\n",
      "\n",
      "\u001b[34m225.. one can along so much in its inte\u001b[m\n",
      "-----\n",
      "\u001b[32mstances, which made him hesitate at firs\u001b[34mt and as the most subjecte of a man who\u001b[m\n",
      "-----\n",
      "\u001b[32m\n",
      "=number.=--the invention of the laws of\u001b[34m a man be more the most shated and as i\u001b[m\n",
      "-----\n",
      "\u001b[32mderstood:--it is an honour\n",
      "to germans th\u001b[34me most senses and sense of a man in the\u001b[m\n",
      "-----\n",
      "\u001b[32my festal\n",
      "discourse and my sprightly teut\u001b[34mh, as intercolves of a man in its own s\u001b[m\n",
      "-----\n",
      "\u001b[32mle strength and spirit had to be\n",
      "stifled\u001b[34m and does not be more into the most sha\u001b[m\n",
      "-----\n",
      "\u001b[32mwith a more suspicious and ambitious thi\u001b[34mng of all most subjecte of a man and se\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# For a more complete inspection, print out a load of sentences:\n",
    "#\n",
    "num_sentences = 100             # how many to generate\n",
    "sentence_length = 40            # 100--400 is good\n",
    "sample_temperature = 0.25       # see discussion of temperature up near the top\n",
    "#sample_temperature = 0.1\n",
    "\n",
    "start_index_list = np.random.randint(len(text) - maxlen - 1, size=(1, num_sentences)).flatten().tolist()\n",
    "preview_seeds = [] \n",
    "for start_index in start_index_list:\n",
    "    preview_seeds.append(text[start_index: start_index + maxlen])\n",
    "\n",
    "generated_sentences = generate_sentence_list(preview_seeds, length=sentence_length, temperature=sample_temperature); \n",
    "print_sentences(preview_seeds, generated_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just a checkpoint, which will let you download and re-upload (or add to git) this model.\n",
    "save_model(generator_model, './generator_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating sentences: [####################] 100.0% - done\n"
     ]
    }
   ],
   "source": [
    "# Generating the training fake sentences for the Discriminator network\n",
    "#\n",
    "# These are saved to the file 'fake.pkl' -- you could download this to your\n",
    "# user drive and re-upload it in a subsequent session, to save regenerating\n",
    "# it again (in which case you don't need to evaluate this cell).\n",
    "\n",
    "#training_seeds = pick_sentences(3000, maxlen=40)\n",
    "training_seeds = pick_sentences(5000, maxlen=40)\n",
    "training_generated_sentences = generate_sentence_list(training_seeds, length=40)\n",
    "# Strip out the initial 40 chars (the seed sequence, which is genuine data from the corpus).\n",
    "for i, sentence in enumerate(training_generated_sentences):\n",
    "    training_generated_sentences[i] = sentence[40:40+40]\n",
    "    \n",
    "output = open('fake.pkl', 'wb')\n",
    "pickle.dump(training_seeds, output)\n",
    "pickle.dump(training_generated_sentences, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training set from the file\n",
    "pkl_file = open('fake.pkl', 'rb')\n",
    "training_seeds = pickle.load(pkl_file)\n",
    "training_generated_sentences = pickle.load(pkl_file)\n",
    "pkl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num generated:  15000\n",
      "All training sequences:  30000\n"
     ]
    }
   ],
   "source": [
    "# Make a 50:50 set of 'fake' (generated) and genuine sentences:\n",
    "num_generated = len(training_generated_sentences)\n",
    "print('Num generated: ', num_generated)\n",
    "training_real_sentences = pick_sentences(num_generated, maxlen=40)\n",
    "\n",
    "all_training_sentences = training_generated_sentences + training_real_sentences\n",
    "\n",
    "n = len(all_training_sentences)\n",
    "x = np.zeros((n, 40, len(chars)))\n",
    "y = np.zeros((n, 1))\n",
    "print('All training sequences: ', n)\n",
    "\n",
    "for i, sentence in enumerate(all_training_sentences):\n",
    "    x[i, :, :] = onehot_encode(sentence, maxlen=40)\n",
    "y[num_generated:] = 1  # Encodes the fact that sentences with indexes larger than (num_generated) are real.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotLossAccuracy(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.acc = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.val_acc = []\n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(int(self.i))\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        \n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(16, 6))\n",
    "        plt.plot([1, 2])\n",
    "        plt.subplot(121) \n",
    "        plt.plot(self.x, self.losses, label=\"train loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"validation loss\")\n",
    "        plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.title('Model Loss')\n",
    "        plt.legend()\n",
    "        plt.subplot(122)         \n",
    "        plt.plot(self.x, self.acc, label=\"training accuracy\")\n",
    "        plt.plot(self.x, self.val_acc, label=\"validation accuracy\")\n",
    "        plt.legend()\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "compiled.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (None, 128)               95232     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 95,361\n",
      "Trainable params: 95,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "\n",
    "# Define some layers here..\n",
    "\n",
    "# Use your layers to create the model.\n",
    "discriminator_model = Sequential()\n",
    "#discriminator_model.add(LSTM(128, dropout=0.6, recurrent_dropout=0.7,\n",
    "#                            input_shape=(maxlen, len(chars))))\n",
    "#discriminator_model.add(LSTM(256, dropout=0.0, recurrent_dropout=0.01,\n",
    "#                             kernel_regularizer=l2(0.2),\n",
    "#                             input_shape=(maxlen, len(chars))))\n",
    "\n",
    "#inputs = Input(shape=(40, 59))\n",
    "#h = LSTM(256)(inputs)\n",
    "#h = Dropout(0.2)(h)\n",
    "#h = Dense(1024, activation='relu')(h)\n",
    "#h = LSTM(256, return_sequences=False)(h)\n",
    "#h = Dense(512, activation='tanh')(h)\n",
    "\n",
    "#output = Dense(1, activation='softmax')(h)\n",
    "\n",
    "discriminator_model = Sequential()\n",
    "#discriminator_model.add(Embedding(4020, 40, input_length=59))\n",
    "discriminator_model.add(LSTM(128, dropout = 0.2, return_sequences=False, \n",
    "                             recurrent_dropout = 0.2, input_shape=(maxlen, len(chars)), unit_forget_bias=True))\n",
    "#discriminator_model.add(LSTM(256, recurrent_dropout=0.0, return_sequences=False, input_shape=(maxlen, len(chars))))\n",
    "#discriminator_model.add(LSTM(128, return_sequences=True))\n",
    "#discriminator_model.add(Conv1D(64, 5, activation='relu', padding='valid', input_shape=(maxlen, len(chars))))\n",
    "#discriminator_model.add(Conv1D(32, 3, activation='tanh', padding='same'))\n",
    "#discriminator_model.add(Dropout(0.7))\n",
    "#discriminator_model.add(Dense(len(chars), activation='relu'))\n",
    "#discriminator_model.add(LSTM(128, return_sequences=False))\n",
    "#discriminator_model.add(Flatten())\n",
    "#discriminator_model.add(Dropout(0.7))\n",
    "#discriminator_model.add(LSTM(256, dropout = 0.5, return_sequences=True, recurrent_dropout = 0.2))\n",
    "#discriminator_model.add(GRU(64))\n",
    "#discriminator_model.add(Flatten())\n",
    "#discriminator_model.add(Dense(len(chars), activation='relu'))\n",
    "#discriminator_model.add(Dense(1, activation='sigmoid'))\n",
    "#discriminator_model.add(Dense(1024))\n",
    "#discriminator_model.add(LeakyReLU(0.2))\n",
    "#discriminator_model.add(Dense(512))\n",
    "#discriminator_model.add(LeakyReLU(0.2))\n",
    "discriminator_model.add(Dropout(0.7))\n",
    "#discriminator_model.add(Dense(1))\n",
    "\n",
    "discriminator_model.add(Dense(1, activation='sigmoid'))\n",
    "opt = RMSprop(lr=0.001)\n",
    "\n",
    "# Setup the optimisation strategy.\n",
    "discriminator_model.compile(optimizer=opt,\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "                             \n",
    "print('compiled.')\n",
    "discriminator_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22500 samples, validate on 7500 samples\n",
      "Epoch 1/2\n",
      "22500/22500 [==============================] - 34s 2ms/step - loss: 0.2915 - acc: 0.8899 - val_loss: 0.1879 - val_acc: 0.9404\n",
      "Epoch 2/2\n",
      "22500/22500 [==============================] - 33s 1ms/step - loss: 0.2612 - acc: 0.9018 - val_loss: 0.1454 - val_acc: 0.9476\n"
     ]
    }
   ],
   "source": [
    "[x_train, x_test, y_train, y_test] = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "discriminator_model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=2, batch_size=64)\n",
    "pltCallBack = PlotLossAccuracy()\n",
    "#discriminator_model.fit(x_train, y_train, \n",
    "#                        validation_data=(x_test, y_test), \n",
    "#                        epochs=3, batch_size=64,\n",
    "#                        callbacks=[pltCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.15\n",
      "Validation Accuracy: 94.76%\n"
     ]
    }
   ],
   "source": [
    "# Once you're happy with your discriminator model, evaluate this cell to save it:\n",
    "save_model(discriminator_model, './discriminator_model.h5')\n",
    "# Run these commands in the terminal to submit your model for assessment.\n",
    "# git add lab-07/discriminator_model.h5\n",
    "# git commit -m \"Add/update discriminator model.\"\n",
    "# git push\n",
    "# submit-lab 7\n",
    "\n",
    "score,acc = discriminator_model.evaluate(x_test, y_test, verbose = 2, batch_size = 64)\n",
    "print(\"Score: %.2f\" % (score))\n",
    "print(\"Validation Accuracy: %.2f%%\" % (acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
