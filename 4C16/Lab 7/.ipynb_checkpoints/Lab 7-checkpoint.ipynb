{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 7 - Text generation with LSTM\n",
    "#\n",
    "# Step 1 (not assessed): build and train a model to generate text in the style of a corpus.\n",
    "#\n",
    "# Based on the Keras text generation example (https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py)\n",
    "#\n",
    "# Step 2: build a model to distinguish genuine from fake sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential modules\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Activation, Conv1D, Dropout, Flatten\n",
    "from keras.layers import CuDNNGRU, CuDNNLSTM\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.optimizers import RMSprop, Adam, Nadam, SGD\n",
    "from keras.models import Model, Sequential\n",
    "from keras.models import save_model\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to sample an index from an array of predictions.\n",
    "#\n",
    "# The input array 'preds' should be the output of a text generation model.\n",
    "# The elements contain the values of the units in the final layer.\n",
    "# Each unit corresponds to a character in the text alphabet.\n",
    "# The final layer should have SoftMax activation, and thus the\n",
    "# value corresponds to the 'strength of prediction' of that character\n",
    "# as the next output value---so the maximum value indicates which character\n",
    "# is most strongly predicted (considerd most likely) as the next one.\n",
    "#\n",
    "def sample(preds, temperature=1.0):\n",
    "    # Convert to high-precision datatype (we are going to be manipulating some\n",
    "    # very small values in this function)\n",
    "    preds = np.asarray(preds).astype('float64')  \n",
    "    \n",
    "    # The next line has the effect of raising each prediction value to the power 1/T.\n",
    "    # It's done using logs to improve numerical precision.  This is a kind of value-dependent\n",
    "    # scaling: for T < 1.0 (1/T > 1.0), small values are made smaller (proportionally) than \n",
    "    # large values (unlike a linear scaling, such as multiplication by 0.9, which scales all values\n",
    "    # the same).\n",
    "    #\n",
    "    # Example: Consider that we have only two symbols (letters) in our alphabet, and our \n",
    "    # probabilities are [0.2, 0.8].  A temperature of 1.0 means 'do not adjust the\n",
    "    # probabilities at all', so in this case there will be a 20% chance that the \n",
    "    # function will return 'symbol 0' and an 80% chance  that it will return 'symbol 1'.\n",
    "    # Note that symbol 1 is 4x more likely than symbol 0.\n",
    "    #\n",
    "    # Now: if we supply a temperature of 0.5, our probabilites will be raised to the\n",
    "    # power 1/0.5 = 2, becoming [0.04, 0.64].  These will then be normalized to sum to 1,\n",
    "    # but anyway it is clear that symbol 1 is here 16x (the square of 4x) more likely than \n",
    "    # symbol 0.\n",
    "    #\n",
    "    # Conversely, for a temperature of 2, our probabilities will be raised to 0.5 (square-rooted),\n",
    "    # becoming [.4472, 0.8944] - and so here symbol 1 is only 2x (sqrt of 4x) more likely than\n",
    "    # symbol 0.\n",
    "    #\n",
    "    # So: low temperatures make the distribution peakier, exaggerating the difference between\n",
    "    # values.  High temperatures flatten the distribution, reducing the difference between values.\n",
    "    #\n",
    "    # As the return value is a sample of the manipulated distribution, manipulating it to\n",
    "    # be peakier (by supplying a low temperature) makes the sample more conservative, i.e.\n",
    "    # more likely to pick the highest-probability symbol.\n",
    "    #\n",
    "    # Making the distribution flatter (by suppyling a high temperature) causes the\n",
    "    # sample to be less conservative, i.e. more likely to pick some lower-likelihood\n",
    "    # symbol.\n",
    "    #\n",
    "    # Phew!\n",
    "    preds = np.exp(np.log(preds) / temperature)\n",
    "    \n",
    "    preds = preds / np.sum(preds)  # ensure that probs sum to 1\n",
    "    probas = np.random.multinomial(1, preds, 1)  # take 1 sample from the distribution\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original corpus length: 600901\n",
      "length for training: 480139\n"
     ]
    }
   ],
   "source": [
    "# Decide how much data to use for training.\n",
    "# You might want to reduce this to ~100k for faster experimentation, and then bring it back\n",
    "# to 600k when you're happy with your network architecture.\n",
    "# IMPORTANT: mke sure you end up with a 57-symbol alphabet after reducing the corpus size!\n",
    "# If the number of symbols (shown in the next cell) gets smaller than it was with the full\n",
    "# corpus, bring your sample size back up.  This is necessary because the encoding used for\n",
    "# training must match that used for assessment.\n",
    "#desired_num_chars = 600*1000  # Max: 600893\n",
    "desired_num_chars = 480139  # Max: 600893\n",
    "\n",
    "random.seed(43)  # Fix random seed for repeatable results.\n",
    "\n",
    "# Slurp down all of Nietzsche from Amazon.\n",
    "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path).read().lower()\n",
    "print('original corpus length:', len(text))\n",
    "\n",
    "start_index = random.randint(0, len(text) - desired_num_chars - 1)\n",
    "text = text[start_index:start_index + desired_num_chars]\n",
    "text\n",
    "print('length for training:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecause they must prevail, or else\n",
      "run the terrible danger of being exterminated. the favour, the\n",
      "super-abundance, the protection are there lacking under which variations\n",
      "are fostered; the species needs itself as species, as something which,\n",
      "precisely by virtue of its hardness, its uniformity, and simplicity of\n",
      "structure, can in general prevail and make itself permanent in\n",
      "constant struggle with its neighbours, or with rebellious or\n",
      "rebellion-threatening vassals. the most varied experience teaches it\n",
      "what are the qualities to which it principally owes the fact that\n",
      "it still exists, in spite of all gods and men, and has hitherto been\n",
      "victorious: these qualities it calls virtues, and these virtues alone\n",
      "it develops to maturity. it does so with severity, indeed it desires\n",
      "severity; every aristocratic morality is intolerant in the education\n",
      "of youth, in the control of women, in the marriage customs, in the\n",
      "relations of old and young, in the penal laws (which have an eye only\n",
      "for the degener\n"
     ]
    }
   ],
   "source": [
    "# Let's have a quick look at a random exceprt.\n",
    "#\n",
    "# Caution: Nietzsche might drive you mad: dare you behold more than 1000 of his terrible chars..? \n",
    "sample_length = 1000\n",
    "\n",
    "random.seed(None)  # Seeds random from current time (so re-eval this cell for a new sample).\n",
    "\n",
    "start_index = random.randint(0, len(text) - sample_length - 1)\n",
    "print(text[start_index:start_index+sample_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 57\n",
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¤', '¦', '«', 'ã']\n"
     ]
    }
   ],
   "source": [
    "# Establish the alphabet (set of symbols) we are going to use.\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "print(chars)\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))  # Map to look up index of a particular char (e.g. x['a'] = 0)\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))  # Map to look up char at an index (e.g. x[0] = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 160033\n"
     ]
    }
   ],
   "source": [
    "# Establish a training set of semi-redundant (i.e. overlapping) sequences of maxlen characters.\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []  # Not syntactic sentences, but just sequences of 40 chars pulled from the corpus.\n",
    "next_chars = [] # next_chars[n] stores the character which followed sentences[n]\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160033, 40, 57)\n",
      "(160033, 57)\n"
     ]
    }
   ],
   "source": [
    "# Convert the data to one-hot encoding.\n",
    "# 'x' will contain the one-hot encoding of the training 'sentences'.\n",
    "# 'y' will contain the one-hot encoding of the 'next char' for each sentence.\n",
    "#\n",
    "# \n",
    "# Let's consider that we have N sentences of length L:\n",
    "#\n",
    "# The 'native' encoding is an NxL matrix where element [n][l]\n",
    "# is the symbol index for character at index (l) of sentence (n)\n",
    "# (e.g., say, 5, corresponding to 'e').\n",
    "#\n",
    "# The one-hot encoding is an NxLxS matrix, where S is the \n",
    "# number of symbols in the alphabet, such that element [n][l][s]\n",
    "# is 1 if the character at index (l) in sentence (n) has the\n",
    "# symbol index (s), and 0 otherwise.\n",
    "def onehot_encode(sentence, maxlen):\n",
    "    x = np.zeros((maxlen, len(chars)), dtype=np.bool)\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[t, char_indices[char]] = 1\n",
    "    return x\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    x[i,:,:] = onehot_encode(sentence, maxlen)\n",
    "    y[i, :] = onehot_encode(next_chars[i], 1)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the generator model: a single GRU layer with 128 cells.\n",
    "generator_model = Sequential()\n",
    "generator_model.add(GRU(128, input_shape=(maxlen, len(chars))))\n",
    "generator_model.add(Dense(len(chars)))\n",
    "generator_model.add(Activation('softmax'))\n",
    "\n",
    "# You could experiment with NAdam instead of RMSProp.\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "generator_model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "trained_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence_list(seed_list, length=400, temperature=0.25):\n",
    "    sentence_list_1 = [];\n",
    "    sentence_list_2 = [];\n",
    "    sentence_list_3 = [];\n",
    "    generated_list_1 = [];\n",
    "    generated_list_2 = [];\n",
    "    generated_list_3 = [];\n",
    "    n = len(seed_list)\n",
    "    # copy lists\n",
    "    temperature_1 = temperature\n",
    "    temperature_2 = (temperature + 0.05)\n",
    "    temperature_3 = max(0.01, (temperature - 0.05))\n",
    "    for seed in seed_list:\n",
    "        sentence_list_1.append(seed[:])\n",
    "        sentence_list_2.append(seed[:])\n",
    "        sentence_list_3.append(seed[:])\n",
    "        generated_list_1.append(seed[:])\n",
    "        generated_list_2.append(seed[:]) \n",
    "        generated_list_3.append(seed[:]) \n",
    "    \n",
    "    for i in range(length):\n",
    "      \n",
    "        workdone = (i+1)*1.0 / length\n",
    "        sys.stdout.write(\"\\rgenerating sentences: [{0:20s}] {1:.1f}%\".format('#' * int(workdone * 20), workdone*100))\n",
    "        sys.stdout.flush()\n",
    "            \n",
    "        x_pred_list = np.zeros((n, maxlen, len(chars)))\n",
    "        for j, sentence in enumerate(sentence_list_1):\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred_list[j, t, char_indices[char]] = 1.\n",
    "\n",
    "        start = time.time()\n",
    "        pred_list = generator_model.predict(x_pred_list, verbose=0)\n",
    "        end = time.time()\n",
    "\n",
    "        for j in range(n):\n",
    "            next_index_1 = sample(pred_list[j,:], temperature_1)\n",
    "            next_char_1 = indices_char[next_index_1]\n",
    "            generated_list_1[j] += next_char_1\n",
    "            sentence_list_1[j] = sentence_list_1[j][1:] + next_char_1\n",
    "            next_index_2 = sample(pred_list[j,:], temperature_2)\n",
    "            next_char_2 = indices_char[next_index_2]\n",
    "            generated_list_2[j] += next_char_2\n",
    "            sentence_list_2[j] = sentence_list_2[j][1:] + next_char_2\n",
    "            next_index_3 = sample(pred_list[j,:], temperature_3)\n",
    "            next_char_3 = indices_char[next_index_3]\n",
    "            generated_list_3[j] += next_char_3\n",
    "            sentence_list_3[j] = sentence_list_3[j][1:] + next_char_3\n",
    "    \n",
    "    sys.stdout.write(' - done\\n')\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    generated_list = generated_list_1 + generated_list_2 + generated_list_3\n",
    "    return generated_list\n",
    "\n",
    "def print_sentences(seeds, sentences):\n",
    "    for seed, sentence in zip(seeds, sentences):\n",
    "        print('-'*5)\n",
    "        sys.stdout.write('\\x1b[32m')\n",
    "        sys.stdout.write(sentence[0:len(seed)])\n",
    "        sys.stdout.write('\\x1b[34m')\n",
    "        sys.stdout.write(sentence[len(seed):-1])\n",
    "        sys.stdout.write('\\x1b[m')\n",
    "        sys.stdout.write('\\n')    \n",
    "        sys.stdout.flush()\n",
    "        \n",
    "def pick_sentences(n, maxlen):\n",
    "    global text    \n",
    "    start_index_list = np.random.randint(len(text) - maxlen - 1, size=(1, n)).flatten().tolist()\n",
    "    seed_list = [] \n",
    "    for start_index in start_index_list:\n",
    "        seed_list.append(text[start_index: start_index + maxlen])\n",
    "    return seed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 18s 110us/step - loss: 2.3066\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 13s 82us/step - loss: 1.8230\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 14s 88us/step - loss: 1.6705\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 15s 95us/step - loss: 1.5859\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32mpproving, exuberant, and vivacious man, \u001b[34mthe most of themselves be the most of the most of the most of the most of the morals who the make of the make the made of the most of the most of the most there make and morals the most of the most of the most of the most of the\n",
      "foccound on the make and many of the most of the scholar even has the generous and make of the most of the make of the most of a many, and morals\n",
      "the most of the most of \u001b[m\n",
      "-----\n",
      "\u001b[32m; he passes the judgment: \"what is\n",
      "injur\u001b[34my, and make and make and make the make of the most of the most of the most of the cansed fact of the most of the make and make of the make themselves whather the make and make of themselves and make of the most of make on the most of the most of themselves be make of the most of the most of the most of the most of the good make themselves be the most of themselves be the most of the most of the f\u001b[m\n",
      "-----\n",
      "\u001b[32m they\n",
      "will not be merely free spirits, b\u001b[34me make and morals the most of have the most of themselves be the make of the most of the most of the most of the most of the most of the most of the most of the most of the sers of themselves be the make the most in the make and morals, the make and morals the\n",
      "german and morals the make the makes the made in the\n",
      "consciousness of the most of the most of the most of the most of the most of the most\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 13s 80us/step - loss: 1.5338 0s - loss\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 13s 83us/step - loss: 1.4952\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 13s 83us/step - loss: 1.4675\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 13s 82us/step - loss: 1.4468\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32mpproving, exuberant, and vivacious man, \u001b[34mand the same that the same that the same that the same that the same that the same that the same that the same that a lists to the sentically of the sentition of the sensity of the sensity of showness, and that it seall that that a passive all that the same to the same\n",
      "that the sensity of the sentialization of the sensity and the same that the same that the same that it something to the sentity t\u001b[m\n",
      "-----\n",
      "\u001b[32m; he passes the judgment: \"what is\n",
      "injur\u001b[34my of the sensity of the some trativism and the sensity of the sensity of the sensity of the sensity of the sensity of the sense. it seally the pares to say that the same that the same that the same and\n",
      "so and that the signification to the sensity of the senses to a martards that the same that the same that the protic same that the same\n",
      "that the sensity of the sensity or so and that the sensity of\u001b[m\n",
      "-----\n",
      "\u001b[32m they\n",
      "will not be merely free spirits, b\u001b[34mut a man of the same that the same that the same that it say the same that it is the sentity of the sentic same that the sentition of the same that the same that the same that the same that the same that it is the same that the same that it is the same that the same to a man and the sensity of the sentics and something to the same that the same that the same that it is all that the same that the \u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 14s 87us/step - loss: 1.4310\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 15s 91us/step - loss: 1.4148\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 13s 81us/step - loss: 1.4019\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 13s 80us/step - loss: 1.3929\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32mpproving, exuberant, and vivacious man, \u001b[34mthe moral may be too rank the most to the most of the most the most development of the most could not the most of the moral the moral may be moral may be modern in the most to the most to the most the most of the moral more man of the moral more the may be moral more too be means to the most to the most to the most to the moral may be true the primord of the most of the moral may be more of the m\u001b[m\n",
      "-----\n",
      "\u001b[32m; he passes the judgment: \"what is\n",
      "injur\u001b[34mes of the most could not the moral moral more the most of the moral same the moral may be the most of the most precisely the most to the most to the most of the most to the most the most of the most to the practing the most the most of the most of the most of the most of the most to the may be take the most could the most to the most to the moral may be mean in the most more the most of the most \u001b[m\n",
      "-----\n",
      "\u001b[32m they\n",
      "will not be merely free spirits, b\u001b[34mecause it is a moral may be mean and the moral may be too latter the most become to the most the most the most the most of the most to the most commonsions of the religion of the most the most the most to the moral may be most the most to the most to the expense of the moral may be most of the moral may be modern in the most of the most soul the moral the moral more the most to the most of the mo\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 13s 80us/step - loss: 1.3846\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 13s 81us/step - loss: 1.3741\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 13s 80us/step - loss: 1.3677\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 14s 86us/step - loss: 1.3605\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32mpproving, exuberant, and vivacious man, \u001b[34mand disguised and all the propositions of the precisely the propositions and does not to properated that the greater thoughts and actions and day for the deared and art and himself are as a finally in the contemporated and disgroping and actions and day first and and and disguised that a facured and dominions of the conditions of the propositions and dominions and degarded and day be actions and \u001b[m\n",
      "-----\n",
      "\u001b[32m; he passes the judgment: \"what is\n",
      "injur\u001b[34ming and are as the conduct and artist of the propositions of a great essention of all the dangerous for a greater and are and art and do be and all a fundamentally difficultifies and and are are and actions and depinions and dangerous as a propositions of all the does not long every of contence, and in a conditions and didgening and disgulses and dangerous for thoughts and actions and do not prec\u001b[m\n",
      "-----\n",
      "\u001b[32m they\n",
      "will not be merely free spirits, b\u001b[34mut a conditions of the dangerous for the consequently and every one agains that for a greater and contemporated that as a conditions of the controlder for disglimable of that of a facured that the dangerous and artists of the domands of the earth of the properated and disgrowing and artist for those are as a greater consere and and as a passe of a conditions of the conditions of the art and allor\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 13s 79us/step - loss: 1.3534\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 13s 82us/step - loss: 1.3505\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 15s 93us/step - loss: 1.3460\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 13s 83us/step - loss: 1.3389\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32mpproving, exuberant, and vivacious man, \u001b[34mand the states and experiences of the world and\n",
      "obliges to the states of the politics and an antimes to the will, the world and states of the states of the world and the states of the will be the completed and the\n",
      "completeness and states of the states of the world and the world and only an antimes to the will to be a more problem of the form of the will somethings of the same to the world and the\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "\u001b[32m; he passes the judgment: \"what is\n",
      "injur\u001b[34mesters and states of the will so the\n",
      "will of the world with the latestical states of the will, and the world when their tempt of the will and as the\n",
      "will somethings of the will not to a more\n",
      "more the states of the possible of the will and believe to the states of the possible to the most destiny of the states and only an an animals\n",
      "of the world and the will not be the states of the states of the \u001b[m\n",
      "-----\n",
      "\u001b[32m they\n",
      "will not be merely free spirits, b\u001b[34me the belief in the fact of the world with the states of the will, by somethings and a man of the will to the will of the favently the world and the states and an antical\n",
      "states of the problem of the world an intercipies and states of the states of the states of the will to the\n",
      "problem of the world we have to an an an an an antical states of the will and more more the other an an an an enternatel\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 15s 91us/step - loss: 1.3382\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 30s 190us/step - loss: 1.3336\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 14s 87us/step - loss: 1.3287\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 13s 82us/step - loss: 1.3244\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32mpproving, exuberant, and vivacious man, \u001b[34mand soul, and stronger as the same to be\n",
      "rear of the same of the same of the starts of the stronger and in order to in the same of the soul, as in the same to the stalling of the soul, as the same of the same of the sole of the strong of the stronger instinct of the stronger as the same to and also a soul, as a consequences of the stronger and something of the same to a distrust of its origin and\u001b[m\n",
      "-----\n",
      "\u001b[32m; he passes the judgment: \"what is\n",
      "injur\u001b[34meding of the starculation of the soul, as the same of the formity of the strong of the streation of the same to the stronger in the streates and so for the strained of the soul, as the stronger and so far as it is a desired and in the starcism of the strong of the same of the same to the strained of the same to the start of the same of the stronger as the straining of the soul, as in the strong o\u001b[m\n",
      "-----\n",
      "\u001b[32m they\n",
      "will not be merely free spirits, b\u001b[34mecomes as in the soul, as it is and so that it is as it is and as it is all the strong of the streations of the words in the same soul as the same and original of the stronger and something and stronger and stronger and soul, as a standing in the starting of the not a soul, as a stronger is and standing in the soul of the conscist--the words who has something and soul, as in a history of the stro\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 13s 81us/step - loss: 1.3232\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 13s 80us/step - loss: 1.3214\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 13s 81us/step - loss: 1.3184\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 13s 80us/step - loss: 1.3165\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32mpproving, exuberant, and vivacious man, \u001b[34mwho so many the resulted thereby respect there is all really discovered there all the freedous there is all the could no longer close there is all really although there is all\n",
      "rest there is all the respect to the following and responsible there all the form of the spirit to be necessary, and there are to be dangerous will to the soul, there is all the formed of the self-abound there is all happen\u001b[m\n",
      "-----\n",
      "\u001b[32m; he passes the judgment: \"what is\n",
      "injur\u001b[34ming there is all the form of the reason to the following there is all longer form of the gratification of the same pour and the form of the desired the propert for\n",
      "the profest the colder and respect and the same\n",
      "there is all real resperdation of the roling there all one of the form of the strainful and self-really there all the sacrificial of the itself come to the truth there there is all really\u001b[m\n",
      "-----\n",
      "\u001b[32m they\n",
      "will not be merely free spirits, b\u001b[34mut there is all the strainful and desired the strong the has to be nevertheless to be dangerous there there is all happen stranger the religionition of the religionition to the dest respect of the found there is all the dest really could no and there is all really desired the same to the foundation of the form of the strong and respect there is all the one and the folly there is all the spelight \u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 14s 85us/step - loss: 1.3153\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 13s 78us/step - loss: 1.3117\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 13s 79us/step - loss: 1.3088\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 13s 81us/step - loss: 1.3065\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32mpproving, exuberant, and vivacious man, \u001b[34mand are the the cale the more the condement and devilation of the exercise and seem to the most development and seem to the truths and refershed the profound the expression of the consequences of the common and moral spirits and seem to the devilumer and secret and see the deviluders and refines the most the most development and seems the most demais and demais and have does not and consequences \u001b[m\n",
      "-----\n",
      "\u001b[32m; he passes the judgment: \"what is\n",
      "injur\u001b[34my in the earther and are and demach and demach in the end and seems the more the suffinge of the prodition in the most discape and devilating and self-the man into deceived the called and devised and refersing and seem the more restance and sense of the expression in the existence and are the prodition of the higher moral seems the most the expression of the christian and demaid and seem to the g\u001b[m\n",
      "-----\n",
      "\u001b[32m they\n",
      "will not be merely free spirits, b\u001b[34my the will be moral sentiment the moral sense of the most the moral demais of the condept and seems the more the moral sense of the prodition and development and devilating and sense and development and refersing and are more moral something more the moral even the most demicate and seem to the has been are the most seems the more the expenter of the end the proditing the german seems the more de\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 13s 79us/step - loss: 1.3035\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 13s 79us/step - loss: 1.3024\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 12s 78us/step - loss: 1.3013\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 13s 79us/step - loss: 1.2991\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32mpproving, exuberant, and vivacious man, \u001b[34mand all the precisely and as the most and are men as a mistake and as a man and are men as the present and man and man with man wishes\n",
      "who the proporitical and a mind as a moral\n",
      "schopenhauer belief in the most concenceition and are man and all manner and are man and a soul as the play and manner and man and almost a man that there are men as the moral master and man who has the precentement of ma\u001b[m\n",
      "-----\n",
      "\u001b[32m; he passes the judgment: \"what is\n",
      "injur\u001b[34me man and are means of mankind the moral manner and man and are men and as the part as a man of the more thing the manniciously and sense of man from the moral manner and as a man and as a man what are means a man what account and man and man and are men as all the manner as a man wishes as the most any man who the dangerous man who the generate and are men a man and are means of the sense of man\u001b[m\n",
      "-----\n",
      "\u001b[32m they\n",
      "will not be merely free spirits, b\u001b[34mut a soul as the master of sufficience, and a moral\n",
      "sense of the moral mears in the most and as a man and almost any man in the moral\n",
      "strength and a man who the morality of mankind the moral sense of man and all the gration and a morality of man and as the most and moral master as a man and acknowledge of any man who thing the mann are mean as the misten can be are men and any man and are means o\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 10\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 12s 78us/step - loss: 1.2975\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 13s 78us/step - loss: 1.2950\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 12s 78us/step - loss: 1.2932\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 13s 81us/step - loss: 1.2901\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32mpproving, exuberant, and vivacious man, \u001b[34mand and will become conception of a much of this progress of the common and commanders and commences and becomes it is an enorgeness of the extent of his eye of this can become and with the extent of the commonal conscience of the same conception of the commonal the end of the standars to a progons of the sentiment of the commonal good and the commonal seems that the common and comes and heart, a\u001b[m\n",
      "-----\n",
      "\u001b[32m; he passes the judgment: \"what is\n",
      "injur\u001b[34my in the same that in the ready and the same than the commonal sense of the case of the common formerly any cases and deceived of the same persing of the commonal and comprehension and consideration of the commanded and the cruelty and the desined and persing and consequence of the commonal and who has the common and commanders and complieation of the property of the commonal seems to the sentime\u001b[m\n",
      "-----\n",
      "\u001b[32m they\n",
      "will not be merely free spirits, b\u001b[34mut a conscience of the commonal conscience of the commonal seems the most decided definion of the commonal seems the prestical serious who has the same that the same that the same that the forms of the commonal the common and complination of the commonal the problems and seems the case of the case of the greater in god and in it is an enorgening and incomprestiance of the commonal conscience of t\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 11\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 13s 82us/step - loss: 1.2910\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 13s 82us/step - loss: 1.2885\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 13s 79us/step - loss: 1.2853\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 13s 79us/step - loss: 1.2853\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32mpproving, exuberant, and vivacious man, \u001b[34mwhich is a consernation of the morality of the morality that the more morality of the same things (a the stronger many though the morality of the morality of the world (we will be the most too must be tentain to the will to be the morality of the subjugator, and the more thoughe the more interest of the most difficult to the morality of the same\n",
      "and its things of the world as if the most difficul\u001b[m\n",
      "-----\n",
      "\u001b[32m; he passes the judgment: \"what is\n",
      "injur\u001b[34mes is the most stranger is as a casses to the most difficult to the morality of the world, and the moralists of the morality of the most too must be mortions of the world and in the same that the morality of the incentions of the most too must not be that the morality of morality, the morality of the morality of the morality of the morality of the most decient to the morality of the most difficul\u001b[m\n",
      "-----\n",
      "\u001b[32m they\n",
      "will not be merely free spirits, b\u001b[34mut the more morality of the morality of the most interestonal thought the more moralists of the morality of the morality of the morality of the subjugator, the structing the morality of the morality of the noble and the sense of the most to the morality of the desires that the morality of the same things of the morality of the subjugations of the world as if the more the same the interestion of t\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 12\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 13s 80us/step - loss: 1.2840\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 13s 80us/step - loss: 1.2807\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 13s 80us/step - loss: 1.2810\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 13s 79us/step - loss: 1.2796\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32mpproving, exuberant, and vivacious man, \u001b[34mand the more the restroment of a moral the manning of the extent of the conscious in the restracces the the more the expentation of the expensating the experienced the end the fren age and strength and the expensating the expension in the end the the more the strength of the expensating the expensation of the greater the expensating the truth, and the expensating and the cantoming the expensation\u001b[m\n",
      "-----\n",
      "\u001b[32m; he passes the judgment: \"what is\n",
      "injur\u001b[34mes, and the expensating the experienced, the extent that is the extent the in the expensating the expensating in the conception of the expensation of the restruction that the restracces the truth, and the greater the expensation of the end the in the expension of the expension of the expension the destince of the expentation of the expensating the restroment and the general deed the strength the \u001b[m\n",
      "-----\n",
      "\u001b[32m they\n",
      "will not be merely free spirits, b\u001b[34me the expensating the struggle the experienced the expensating the expensating the expensating men and the individual the strict the externally the expension of the expension in the end the the expention of the expensation of an inner every and the destructibly the heart the the fact the exteriated the the expensating and the expension of the expensation of an inner every generation of the expens\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 13\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 13s 80us/step - loss: 1.2795\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 13s 80us/step - loss: 1.2768\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 13s 81us/step - loss: 1.2751\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 13s 82us/step - loss: 1.2750\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32mpproving, exuberant, and vivacious man, \u001b[34mwhatever will be to spirits as it will be as it will be to spirits as it will be to say, in the straing it be the strain to be that the straing it be the possible to be strong the strain more more to the strangered to the strangered and strangely that the straing manner of the strangered as the strain more to the strain to the strain manner posing the strain manner as its observed to be strong to\u001b[m\n",
      "-----\n",
      "\u001b[32m; he passes the judgment: \"what is\n",
      "injur\u001b[34mences of the strain to more to stands strong the straing manning of the strain to be strong to mannically the strain mann taste so much as strong to the most comparison to the strangely be to present manner, the species of the strong the strain more more to be more that the straing more than stands that the straing it be the straing manner of the strain manner of the strangered as the strangered \u001b[m\n",
      "-----\n",
      "\u001b[32m they\n",
      "will not be merely free spirits, b\u001b[34mut who this properated by more to say present this possible to be to stands the straing it betrays to strong paratow to say that the straing manner of the strain manner of the strangered as its of the straing it be the strong to present manness to be the strength of the strong to the most discovery mannlishment of the strain manner of the strain more stand as it will be a man with which is strong\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 14\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 13s 80us/step - loss: 1.2727\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 13s 80us/step - loss: 1.2709\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 13s 83us/step - loss: 1.2687\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 13s 81us/step - loss: 1.2707\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32mpproving, exuberant, and vivacious man, \u001b[34mand instinct in and and strangely and strangely the profound to the soul, and sound more and influence of the soul and something of their own for such and and and standing of the most species of their are something of the stronger and something of something of their free of some the\n",
      "sing of something of the soul, and infres instinct of the sounged and suffering instinctss, in the something and st\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "\u001b[32m; he passes the judgment: \"what is\n",
      "injur\u001b[34mes influence of something of the formerious torative are and strangely the more profound of the soul, and and same torations, and starces of the south of the something of the soul and strangely and strangely the most possible of the possible of the more possible of the soul, there is an\n",
      "enotions of the senses of the senses and sounce and something in the most profounded and profound to the exist \u001b[m\n",
      "-----\n",
      "\u001b[32m they\n",
      "will not be merely free spirits, b\u001b[34mut from the stray the moralists of the same to the free and for the free from their for the same\n",
      "the profound of the sounce and composition of the soul, and and strangely in the feelings of something of the free of the soul, and something and strong the most profoundest strost of their for their instinct of the soul for such manner of the stronger and standing and profound to their commonsed of t\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 15\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 12s 78us/step - loss: 1.2694\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 12s 78us/step - loss: 1.2661\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 12s 78us/step - loss: 1.2666\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 12s 78us/step - loss: 1.2666\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32mpproving, exuberant, and vivacious man, \u001b[34mis the spirit, it is an intellere the spirit (and with its interestic morality itself intellection, and stand it is also the same much and self-abunding of the most intellect of intellection, and all the most intellects in all himself of the end it is an intellere of the most intellects of the spirit, and has it is and more more more more\n",
      "masic from the false it is something in its original into \u001b[m\n",
      "-----\n",
      "\u001b[32m; he passes the judgment: \"what is\n",
      "injur\u001b[34me in all the strengthing in the sense of intellect it is an intellere its interestic morality, is the spirit, it is an intellere the most intellect in the end things (we as it is an intellere of the spirit, it is an intellect of the most intellect of its originally in the spirit (no long into in a proved in and strangely the end it is all soul, and self-abund it is a morality of it is a standand \u001b[m\n",
      "-----\n",
      "\u001b[32m they\n",
      "will not be merely free spirits, b\u001b[34me a consequence of the spirit, the sense of it, in all originally in the most intellect in the same still be has it is an intellere the spirit, and streng the sense of the spirit, it is a still in the sense of the most intellect in the sense of an enor-out and sich the spirit, it is an enory one of the senses of morality, is a consequence of it is a consequence of the same entious in all still in\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 16\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 13s 80us/step - loss: 1.2667\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 13s 80us/step - loss: 1.2647\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 13s 81us/step - loss: 1.2631\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 13s 79us/step - loss: 1.2617\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32mpproving, exuberant, and vivacious man, \u001b[34mwhich is something and the struggle the most manner, the most manness, and the more the most men of the sense of the struggle the more the more mannot enjoyitely the more more the more the straine and sense of the strained, the strength, love, and the superficially to the endight the more the more the more possible in the more process the more the most manness of the most manness of the more the \u001b[m\n",
      "-----\n",
      "\u001b[32m; he passes the judgment: \"what is\n",
      "injur\u001b[34mes and presence of the most to the most manness, the same therefore the most to the same the struggle to the more the more requirement, when the more the more the more mannot enjoyitely the individual to the more the more the more the signification of the more the more the more mannical to the subjection, the senses and possession of the more the more more manness, the succumst, the more the more\u001b[m\n",
      "-----\n",
      "\u001b[32m they\n",
      "will not be merely free spirits, b\u001b[34mut the most requires the most to the most disception and presence of the most to the superficially to the more the same the most conception of the more the most manness of the sense, the sensation of the most development, the science such an\n",
      "anitarial spirit, the more more the same the\n",
      "most subject of the most man in the most manner, the sense of the same the more to the more process the most dis\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 17\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 13s 81us/step - loss: 1.2619\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 13s 81us/step - loss: 1.2604\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 13s 80us/step - loss: 1.2590\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 13s 80us/step - loss: 1.2602\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32mpproving, exuberant, and vivacious man, \u001b[34mthey spirit, they have to be\n",
      "teacilly they all they superficiality of the most different\n",
      "music that they must be that they were they are better instinct\n",
      "that they has they spirit, they granged, they superficiality, but\n",
      "he clearly, they all the meant perhaps they are to the perspectively, but\n",
      "well be to the persulves to be to be to be\n",
      "collert themselves (were the present to be mortly they are bett\u001b[m\n",
      "-----\n",
      "\u001b[32m; he passes the judgment: \"what is\n",
      "injur\u001b[34mes that they were they spirits that they have has been nobleness there must they will be\n",
      "the present they must be the music to be that\n",
      "they spile of the perspectively of the music and beings of the most that they must say, but\n",
      "there is an interperting precisely they sure music, they speaking men and the present they superficial\n",
      "music to be to the most purpose of the subtimes of the\n",
      "property of th\u001b[m\n",
      "-----\n",
      "\u001b[32m they\n",
      "will not be merely free spirits, b\u001b[34mut they belong to be to be\n",
      "love to be understanding the people to be\n",
      "sure, they have not there must be that they were the most personal\n",
      "that they say they has been music and the most thensighted by the problem of the most that they spiritual\n",
      "constraintly they will be the music to be\n",
      "to the conception of the most believed there must\n",
      "perhappen?) that the present they must enthouse be that they has \u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 18\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 15s 96us/step - loss: 1.2590\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 13s 84us/step - loss: 1.2590\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 15s 91us/step - loss: 1.2546\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 13s 82us/step - loss: 1.2574\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32mpproving, exuberant, and vivacious man, \u001b[34mand a new a desire of the more the same a contence of the same a conterment and the sake of the interest and the same a new and superior in the same a superficial to the treat the more than the manner of the more than the same as a man where there are a man in the same a faith his regarded to the contrary of the same a great contrary to the same a serious inever of the contrary and the same a con\u001b[m\n",
      "-----\n",
      "\u001b[32m; he passes the judgment: \"what is\n",
      "injur\u001b[34me in the seriousness and resultes that the real the saint of the end through the same a so that the sake of the experiences of the examply in the contrary of the experiences of the truth also all the examply in the same\n",
      "as a sound and a new a the contence of the earth and him the resulted as a the same\n",
      "as it has the sentiment of the object and a chance and the reverence of the will and the sake o\u001b[m\n",
      "-----\n",
      "\u001b[32m they\n",
      "will not be merely free spirits, b\u001b[34mut a strong the sear of the read to the same\n",
      "as a servity and the same a contence that the same a conterment of the contrary and the soul of the soul and a noble that the most and the same and a caste of the same a contrary of the soul and the same a serious into the same a desire of the eye of the sense of the act and his all the same\n",
      "as a great and a man is not of the said to and the sake of th\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 19\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 13s 79us/step - loss: 1.2549\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 12s 78us/step - loss: 1.2537\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 13s 79us/step - loss: 1.2547\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 14s 89us/step - loss: 1.2546\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32mpproving, exuberant, and vivacious man, \u001b[34mand the world which is a common to the will to the intellect of a morality, and a granger--that which is a morality and the most and a man is a man and all the intentions of their into the intellect of the\n",
      "highly definition is a morality of the intellect and as a great and dangerousness, and the same things and into mannicus to their and into the intention of the intentions of the whole of the st\u001b[m\n",
      "-----\n",
      "\u001b[32m; he passes the judgment: \"what is\n",
      "injur\u001b[34me and intellect of the will to the whole of the will of their accomethants and a man is already self and a morality of the world and a man is a morality of the earth and all that is a morality of a man is a morality, and a man and a granger--and and a man and the most into the will to their actually into the highly definite morality, and into the will to their and a sort of the great and a morali\u001b[m\n",
      "-----\n",
      "\u001b[32m they\n",
      "will not be merely free spirits, b\u001b[34mut it is a morality and all the intentions of an intentious in the most into the will to the intention of their and a seriousness and all the and a morality in the will of the intention of the intellect of the will of the struggle and the highly definite in its out of the intention of the commonperfiction of the intention of the intellect of the intention of the will in the world of our promoment\u001b[m\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 20\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 14s 86us/step - loss: 1.2520\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 13s 79us/step - loss: 1.2518\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 13s 80us/step - loss: 1.2516\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 13s 79us/step - loss: 1.2488\n",
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32mpproving, exuberant, and vivacious man, \u001b[34mthey with the will to the the with a perhaps they are perhaps in the will to the interest of the the will of the will of the the the predessing of the the will to the the with it is a disting one which is a person which is a good of the will to be the\n",
      "incapes of the will to deceived to be the the the will to the will they a desired their interest of the with the will to the person which is a sure\u001b[m\n",
      "-----\n",
      "\u001b[32m; he passes the judgment: \"what is\n",
      "injur\u001b[34me and the possible the will to be the the interes of the person which is a person has been the interes of the interes of the will to the higher man of the will to the interest of the will in the interes of the will to the the will to the will to the will to the will to the with it is a the self-sudce at the self-sufficise, which is the part of the the the present and suffering they all the the fr\u001b[m\n",
      "-----\n",
      "\u001b[32m they\n",
      "will not be merely free spirits, b\u001b[34mut is the happened they they they all our feeling they the interes of the will to the will to the will to the will to they are there is\n",
      "reality they are as it with its own as it with the the will to the\n",
      "present the self-sight of the with utrust they all the interest and self-sufficise, and they while they are they are the heart in the interes of the will to their calcular they are they all the wi\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# Generate 3 seeds which we will use to inspect the progress of our training:\n",
    "preview_seeds = pick_sentences(3, maxlen=40)\n",
    "\n",
    "# Train the model, output generated text after each iteration\n",
    "for iteration in range(1, 21):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    generator_model.fit(x, y,\n",
    "                  batch_size=1024,\n",
    "                  epochs=4)\n",
    "\n",
    "    generated_sentences = generate_sentence_list(preview_seeds)\n",
    "    print_sentences(preview_seeds, generated_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32mnoisy,\n",
      "time-engrossing, conceited, fooli\u001b[34ms, the german the interes of the will t\u001b[m\n",
      "-----\n",
      "\u001b[32mhuman.--\n",
      "\n",
      "296. alas! what are you, after\u001b[34m as it is a person of the will to the w\u001b[m\n",
      "-----\n",
      "\u001b[32mting, and still less that they\n",
      "wait in v\u001b[34mieded to the will to the will to the wi\u001b[m\n",
      "-----\n",
      "\u001b[32mes. in jest, and in homeric language as \u001b[34mit with the will to been the interes of\u001b[m\n",
      "-----\n",
      "\u001b[32mempo (which overleaps and\n",
      "obviates all d\u001b[34mesired they all the with it is a person\u001b[m\n",
      "-----\n",
      "\u001b[32mjoke of this gloomy grimace and turn of\n",
      "\u001b[34mthe interest of the with it is a person\u001b[m\n",
      "-----\n",
      "\u001b[32m yet met a german who was favourably\n",
      "inc\u001b[34ment of the will to the will to the will\u001b[m\n",
      "-----\n",
      "\u001b[32mdo what it has always been doing? in all\u001b[34mow of the will to the will to the will \u001b[m\n",
      "-----\n",
      "\u001b[32mcholar, or with the religiously\n",
      "elevated\u001b[34m they all the with it is a person of th\u001b[m\n",
      "-----\n",
      "\u001b[32msolutely deny any connection between the\u001b[34m will to the will to the will to the wi\u001b[m\n",
      "-----\n",
      "\u001b[32mple of it--hours of national excitement,\u001b[34m they are they all the interest of the \u001b[m\n",
      "-----\n",
      "\u001b[32m,\n",
      "taste, and love, what finds us fundame\u001b[34mntal and the person of the will to the \u001b[m\n",
      "-----\n",
      "\u001b[32mnow something thereof already.\n",
      "\n",
      "56. whoe\u001b[34m i should been they are the the person \u001b[m\n",
      "-----\n",
      "\u001b[32mhat this very romanticism\n",
      "of schumann's \u001b[34ma person we does not been they are they\u001b[m\n",
      "-----\n",
      "\u001b[32mappened and been esteemed hitherto, cons\u001b[34mequently they all the will to the will \u001b[m\n",
      "-----\n",
      "\u001b[32mt a genuine disgust for all that is thus\u001b[34m and interes of the the person has been\u001b[m\n",
      "-----\n",
      "\u001b[32mlusions concerning the scientificness of\u001b[34m the will to the will to the will to th\u001b[m\n",
      "-----\n",
      "\u001b[32m any expanse. but all these are only\n",
      "pre\u001b[34msent they a higher they and incentive a\u001b[m\n",
      "-----\n",
      "\u001b[32mianity, it is much rather the faith of p\u001b[34mossible their powerful in the will to t\u001b[m\n",
      "-----\n",
      "\u001b[32meat things, looks upon every one whom\n",
      "he\u001b[34m we love the person has to been the int\u001b[m\n",
      "-----\n",
      "\u001b[32m give you, my friends, as far as i am al\u001b[34ml the will to the will to the will to t\u001b[m\n",
      "-----\n",
      "\u001b[32mndous remains of what man was formerly, \u001b[34mthey are the the interes of the will to\u001b[m\n",
      "-----\n",
      "\u001b[32mabove all give\n",
      "the finishing stroke to t\u001b[34mhe will to the will to the will to the \u001b[m\n",
      "-----\n",
      "\u001b[32muage, here as elsewhere, will not get ov\u001b[34mer the will to the will to the will to \u001b[m\n",
      "-----\n",
      "\u001b[32man invisible spell, they always revolve\n",
      "\u001b[34min the will to the will to the will to \u001b[m\n",
      "-----\n",
      "\u001b[32mand ocular evidence belonging to the per\u001b[34mson has been the the the person of the \u001b[m\n",
      "-----\n",
      "\u001b[32mtions, dominated and led to the\n",
      "goal by \u001b[34mthe the the person has been our arts th\u001b[m\n",
      "-----\n",
      "\u001b[32m thereby--and not they themselves. with \u001b[34mthe will to the will to the will to the\u001b[m\n",
      "-----\n",
      "\u001b[32m cannot even go\n",
      "back again to the sympat\u001b[34mhy the person has been they are to been\u001b[m\n",
      "-----\n",
      "\u001b[32mfixed\" about them in himself. occasional\u001b[34m they all the will to the will to the w\u001b[m\n",
      "-----\n",
      "\u001b[32mthinkers\" of diversified species and ori\u001b[34mgin of the will to the will to the will\u001b[m\n",
      "-----\n",
      "\u001b[32m be some motive or touch\n",
      "of allurement, \u001b[34mas it is a person has been the interes \u001b[m\n",
      "-----\n",
      "\u001b[32m historical sense is in necessary contra\u001b[34mrisous to the will to the will to the w\u001b[m\n",
      "-----\n",
      "\u001b[32me following rhymes:--\n",
      "\n",
      "    hail, ye wort\u001b[34mhere they are soul, is the will to the \u001b[m\n",
      "-----\n",
      "\u001b[32msome motive or touch\n",
      "of allurement, to w\u001b[34mhich is a person has to been they are t\u001b[m\n",
      "-----\n",
      "\u001b[32mnaivete in egoism,\n",
      "her untrainableness a\u001b[34mnd incape of the will to the will to th\u001b[m\n",
      "-----\n",
      "\u001b[32mother? strange am i to me?\n",
      "             \u001b[34m                                       \u001b[m\n",
      "-----\n",
      "\u001b[32mhe knows how to\n",
      "appear,--not as he is, b\u001b[34mut it is a sure they all the will to th\u001b[m\n",
      "-----\n",
      "\u001b[32mown strength and\n",
      "love of power, and knew\u001b[34m with which is a person of the will to \u001b[m\n",
      "-----\n",
      "\u001b[32mere the conception of the subject\n",
      "is lea\u001b[34mrn they all the will to the will to the\u001b[m\n",
      "-----\n",
      "\u001b[32mnd ennobling a race which seeks to rise \u001b[34mof the will to the will to the will to \u001b[m\n",
      "-----\n",
      "\u001b[32m\n",
      "sense), but as possessing the same degr\u001b[34mee of the interest of the will to the w\u001b[m\n",
      "-----\n",
      "\u001b[32mff, packed up, and above all studied--we\u001b[34m a such as it is a desired they all the\u001b[m\n",
      "-----\n",
      "\u001b[32morld--the compulsion to great politics.\n",
      "\u001b[34m\n",
      "264. it is a sure is a person has been\u001b[m\n",
      "-----\n",
      "\u001b[32mrsts against those who refused him their\u001b[34m powerful in the will to the interes of\u001b[m\n",
      "-----\n",
      "\u001b[32mand exuberance! \"to think\" and to take a\u001b[34m distinction of the with it is the poss\u001b[m\n",
      "-----\n",
      "\u001b[32meral welfare) wants to have\n",
      "any knowledg\u001b[34med to the will to be the person which i\u001b[m\n",
      "-----\n",
      "\u001b[32msness of woman is slowly evolving? oh eu\u001b[34mropean age of the will to the will to t\u001b[m\n",
      "-----\n",
      "\u001b[32mroughout their whole future, if they had\u001b[34m of the the will to the will to the wil\u001b[m\n",
      "-----\n",
      "\u001b[32me, creations of value, which have become\u001b[34m their possible they all the will to th\u001b[m\n",
      "-----\n",
      "\u001b[32md civilization (den\n",
      "alten cultur) vows t\u001b[34mhe present the possible their interest \u001b[m\n",
      "-----\n",
      "\u001b[32mpean taste. indeed, who could doubt that\u001b[34m it is a person which is a person which\u001b[m\n",
      "-----\n",
      "\u001b[32mnot have done it! it was mad perhaps to\n",
      "\u001b[34mgerman's perhaps they are the incentive\u001b[m\n",
      "-----\n",
      "\u001b[32m more laudable truthfulness in every lit\u001b[34mterise of the will to the will to the w\u001b[m\n",
      "-----\n",
      "\u001b[32my material part therein. the actual\n",
      "\"int\u001b[34merest person we will to be \"they are \"t\u001b[m\n",
      "-----\n",
      "\u001b[32mto be stars--the people\n",
      "then call them i\u001b[34mn the person has been our should been t\u001b[m\n",
      "-----\n",
      "\u001b[32m bentham, just as he had already stalked\u001b[34m the possible their possible their at t\u001b[m\n",
      "-----\n",
      "\u001b[32ms\n",
      "for frequently returning and concurrin\u001b[34mg they all the will to the will to the \u001b[m\n",
      "-----\n",
      "\u001b[32mnrich heine, who has\n",
      "long ago been re-in\u001b[34mcludence in the person which has there \u001b[m\n",
      "-----\n",
      "\u001b[32mrs,\n",
      "though they may dash and break their\u001b[34m interes of the will to the will to the\u001b[m\n",
      "-----\n",
      "\u001b[32ms variety of disguises, it enjoys\n",
      "also i\u001b[34mn the will to the will to the will to t\u001b[m\n",
      "-----\n",
      "\u001b[32m114. the immense expectation with regard\u001b[34m their powerful in the will to the will\u001b[m\n",
      "-----\n",
      "\u001b[32mrn, an unavoidable psychologist\n",
      "and soul\u001b[34m, as it is a person has been incern the\u001b[m\n",
      "-----\n",
      "\u001b[32mso it seems\n",
      "to me. every system of unego\u001b[34mist the will to the will to the will to\u001b[m\n",
      "-----\n",
      "\u001b[32m, finer, and rarer), or\n",
      "deteriorations a\u001b[34mnd the person has the person which is a\u001b[m\n",
      "-----\n",
      "\u001b[32m, with others\n",
      "he wishes to take revenge,\u001b[34m it is a person which is a person which\u001b[m\n",
      "-----\n",
      "\u001b[32mious human vanity, and that even under s\u001b[34mtill not the will be the the will to th\u001b[m\n",
      "-----\n",
      "\u001b[32mizing--and a still greater inability to \u001b[34mthe will to the will to the will to the\u001b[m\n",
      "-----\n",
      "\u001b[32mnot noble enough, was not musical enough\u001b[34m of the will to the will to the will to\u001b[m\n",
      "-----\n",
      "\u001b[32mhe blessing than to the banning of unive\u001b[34mrying the interes of the will to the wi\u001b[m\n",
      "-----\n",
      "\u001b[32mtitude to the soil from which we sprung,\u001b[34m and the will to the will to the will t\u001b[m\n",
      "-----\n",
      "\u001b[32m--\"laughing is a bad infirmity of human \u001b[34msense of the will to the will to the wi\u001b[m\n",
      "-----\n",
      "\u001b[32mciple that one has duties only to one's\n",
      "\u001b[34mgerman the person which is a person of \u001b[m\n",
      "-----\n",
      "\u001b[32mproblem in itself, this terrible note of\u001b[34m the will to the will to the will to th\u001b[m\n",
      "-----\n",
      "\u001b[32metermine what it is; on account of this \u001b[34mthe will to the will to the will to the\u001b[m\n",
      "-----\n",
      "\u001b[32mness\n",
      "and supreme significance require fo\u001b[34mr the the the will to be the interes of\u001b[m\n",
      "-----\n",
      "\u001b[32morative, intoxicating and perhaps beatif\u001b[34mically they all the will to the will to\u001b[m\n",
      "-----\n",
      "\u001b[32mproved customs. what!? everything is mer\u001b[34mely they are the possible their at they\u001b[m\n",
      "-----\n",
      "\u001b[32mances do not deceive. the fact thereby b\u001b[34meen they are the present to the will to\u001b[m\n",
      "-----\n",
      "\u001b[32mntire species, so\n",
      "that the scientific ma\u001b[34mn of the possible their attiming to the\u001b[m\n",
      "-----\n",
      "\u001b[32mll inexhausted, still unwearied\n",
      "corrupti\u001b[34mve in the person has been our eyes the \u001b[m\n",
      "-----\n",
      "\u001b[32mps. one must renounce the bad taste of w\u001b[34mhich is the person has been the person \u001b[m\n",
      "-----\n",
      "\u001b[32mconditioned. this process is generally l\u001b[34mong would have to been interest interes\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "\u001b[32mso that the long spun-out\n",
      "comedy of its \u001b[34mown existed to the will to the will to \u001b[m\n",
      "-----\n",
      "\u001b[32mnui flees, when a man comes to our knees\u001b[34mt the the will to the will to the will \u001b[m\n",
      "-----\n",
      "\u001b[32ms no conception (to say nothing of the t\u001b[34mhe will to the will to the will to the \u001b[m\n",
      "-----\n",
      "\u001b[32mssation of all gestures, by which it is \u001b[34ma person of the will to the will to the\u001b[m\n",
      "-----\n",
      "\u001b[32menough to make this objection?--well, so\u001b[34m a distinction of the will to the will \u001b[m\n",
      "-----\n",
      "\u001b[32mpirits, appear, who try to conjure back \u001b[34mand defend their philosophers of the th\u001b[m\n",
      "-----\n",
      "\u001b[32mards of worth, the conscious employment \u001b[34mof the will to the will to the will to \u001b[m\n",
      "-----\n",
      "\u001b[32mod, perhaps to warn friend or foe, or in\u001b[34m the will to the will to the will to th\u001b[m\n",
      "-----\n",
      "\u001b[32mrhaps obliged to be: men of the moment, \u001b[34mthey with the end into the will to the \u001b[m\n",
      "-----\n",
      "\u001b[32mn effect, that method ordains, which mus\u001b[34mt in the will to the will to the will t\u001b[m\n",
      "-----\n",
      "\u001b[32mof our neighbour which again creates new\u001b[34m for the will to the will to the will t\u001b[m\n",
      "-----\n",
      "\u001b[32m propensity--doubly dangerous among\n",
      "germ\u001b[34man is a person has been a sure is a we \u001b[m\n",
      "-----\n",
      "\u001b[32m on earth. one\n",
      "must, however, go still f\u001b[34mor the possible their eyes they all the\u001b[m\n",
      "-----\n",
      "\u001b[32mto definite figures,\n",
      "moving groups, land\u001b[34men with its own as it is a person which\u001b[m\n",
      "-----\n",
      "\u001b[32mrning one.\n",
      "\n",
      "72. it is not the strength, \u001b[34mthey are the person which is a person w\u001b[m\n",
      "-----\n",
      "\u001b[32m a smile, but a genuine disgust for all \u001b[34mthe with it is a desired their powerful\u001b[m\n",
      "-----\n",
      "\u001b[32moes on, which is ever\n",
      "extending the proc\u001b[34mess of the with it is a the will to the\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# For a more complete inspection, print out a load of sentences:\n",
    "#\n",
    "num_sentences = 100             # how many to generate\n",
    "sentence_length = 40            # 100--400 is good\n",
    "#sample_temperature = 0.25       # see discussion of temperature up near the top\n",
    "sample_temperature = 0.1\n",
    "\n",
    "start_index_list = np.random.randint(len(text) - maxlen - 1, size=(1, num_sentences)).flatten().tolist()\n",
    "preview_seeds = [] \n",
    "for start_index in start_index_list:\n",
    "    preview_seeds.append(text[start_index: start_index + maxlen])\n",
    "\n",
    "generated_sentences = generate_sentence_list(preview_seeds, length=sentence_length, temperature=sample_temperature); \n",
    "print_sentences(preview_seeds, generated_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just a checkpoint, which will let you download and re-upload (or add to git) this model.\n",
    "save_model(generator_model, './generator_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating sentences: [####################] 100.0% - done\n"
     ]
    }
   ],
   "source": [
    "# Generating the training fake sentences for the Discriminator network\n",
    "#\n",
    "# These are saved to the file 'fake.pkl' -- you could download this to your\n",
    "# user drive and re-upload it in a subsequent session, to save regenerating\n",
    "# it again (in which case you don't need to evaluate this cell).\n",
    "\n",
    "training_seeds = pick_sentences(3000, maxlen=40)\n",
    "training_generated_sentences = generate_sentence_list(training_seeds, length=40)\n",
    "# Strip out the initial 40 chars (the seed sequence, which is genuine data from the corpus).\n",
    "for i, sentence in enumerate(training_generated_sentences):\n",
    "    training_generated_sentences[i] = sentence[40:40+40]\n",
    "    \n",
    "output = open('fake.pkl', 'wb')\n",
    "pickle.dump(training_seeds, output)\n",
    "pickle.dump(training_generated_sentences, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training set from the file\n",
    "pkl_file = open('fake.pkl', 'rb')\n",
    "training_seeds = pickle.load(pkl_file)\n",
    "training_generated_sentences = pickle.load(pkl_file)\n",
    "pkl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num generated:  9000\n",
      "All training sequences:  18000\n"
     ]
    }
   ],
   "source": [
    "# Make a 50:50 set of 'fake' (generated) and genuine sentences:\n",
    "num_generated = len(training_generated_sentences)\n",
    "print('Num generated: ', num_generated)\n",
    "training_real_sentences = pick_sentences(num_generated, maxlen=40)\n",
    "\n",
    "all_training_sentences = training_generated_sentences + training_real_sentences\n",
    "\n",
    "n = len(all_training_sentences)\n",
    "x = np.zeros((n, 40, len(chars)))\n",
    "y = np.zeros((n, 1))\n",
    "print('All training sequences: ', n)\n",
    "\n",
    "for i, sentence in enumerate(all_training_sentences):\n",
    "    x[i, :, :] = onehot_encode(sentence, maxlen=40)\n",
    "y[num_generated:] = 1  # Encodes the fact that sentences with indexes larger than (num_generated) are real.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "compiled.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_57 (LSTM)               (None, 40, 128)           95232     \n",
      "_________________________________________________________________\n",
      "lstm_58 (LSTM)               (None, 40, 256)           394240    \n",
      "_________________________________________________________________\n",
      "gru_14 (GRU)                 (None, 64)                61632     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 551,169\n",
      "Trainable params: 551,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "\n",
    "# Define some layers here..\n",
    "\n",
    "# Use your layers to create the model.\n",
    "discriminator_model = Sequential()\n",
    "#discriminator_model.add(LSTM(128, dropout=0.6, recurrent_dropout=0.7,\n",
    "#                            input_shape=(maxlen, len(chars))))\n",
    "#discriminator_model.add(LSTM(256, dropout=0.0, recurrent_dropout=0.01,\n",
    "#                             kernel_regularizer=l2(0.2),\n",
    "#                             input_shape=(maxlen, len(chars))))\n",
    "\n",
    "#inputs = Input(shape=(40, 59))\n",
    "#h = LSTM(256)(inputs)\n",
    "#h = Dropout(0.2)(h)\n",
    "#h = Dense(1024, activation='relu')(h)\n",
    "#h = LSTM(256, return_sequences=False)(h)\n",
    "#h = Dense(512, activation='tanh')(h)\n",
    "\n",
    "#output = Dense(1, activation='softmax')(h)\n",
    "\n",
    "discriminator_model = Sequential()\n",
    "#discriminator_model.add(Embedding(4020, 40, input_length=59))\n",
    "discriminator_model.add(LSTM(128, dropout = 0.2, return_sequences=True, \n",
    "                             recurrent_dropout = 0.2, input_shape=(maxlen, len(chars)), unit_forget_bias=True))\n",
    "#discriminator_model.add(LSTM(256, recurrent_dropout=0.0, return_sequences=False, input_shape=(maxlen, len(chars))))\n",
    "#discriminator_model.add(LSTM(128, return_sequences=True))\n",
    "#discriminator_model.add(Conv1D(64, 5, activation='relu', padding='valid', input_shape=(maxlen, len(chars))))\n",
    "#discriminator_model.add(Conv1D(32, 3, activation='tanh', padding='same'))\n",
    "#discriminator_model.add(Dropout(0.7))\n",
    "#discriminator_model.add(Dense(len(chars), activation='relu'))\n",
    "#discriminator_model.add(LSTM(128, return_sequences=False))\n",
    "#discriminator_model.add(Flatten())\n",
    "#discriminator_model.add(Dropout(0.7))\n",
    "discriminator_model.add(LSTM(256, dropout = 0.7, return_sequences=True, recurrent_dropout = 0.1))\n",
    "discriminator_model.add(GRU(64))\n",
    "#discriminator_model.add(Flatten())\n",
    "#discriminator_model.add(Dense(len(chars), activation='relu'))\n",
    "#discriminator_model.add(Dense(1, activation='sigmoid'))\n",
    "#discriminator_model.add(Dense(1024))\n",
    "#discriminator_model.add(LeakyReLU(0.2))\n",
    "#discriminator_model.add(Dense(512))\n",
    "#discriminator_model.add(LeakyReLU(0.2))\n",
    "discriminator_model.add(Dropout(0.3))\n",
    "#discriminator_model.add(Dense(1))\n",
    "\n",
    "discriminator_model.add(Dense(1, activation='sigmoid'))\n",
    "opt = RMSprop(lr=0.01)\n",
    "\n",
    "# Setup the optimisation strategy.\n",
    "discriminator_model.compile(optimizer=opt,\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "                             \n",
    "print('compiled.')\n",
    "discriminator_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13500 samples, validate on 4500 samples\n",
      "Epoch 1/10\n",
      "13500/13500 [==============================] - 63s 5ms/step - loss: 0.7339 - acc: 0.5199 - val_loss: 0.6890 - val_acc: 0.5549\n",
      "Epoch 2/10\n",
      "13500/13500 [==============================] - 55s 4ms/step - loss: 0.7007 - acc: 0.5281 - val_loss: 0.6900 - val_acc: 0.5116\n",
      "Epoch 3/10\n",
      "13500/13500 [==============================] - 55s 4ms/step - loss: 0.6923 - acc: 0.5500 - val_loss: 0.6739 - val_acc: 0.6084\n",
      "Epoch 4/10\n",
      "13500/13500 [==============================] - 55s 4ms/step - loss: 0.6830 - acc: 0.5696 - val_loss: 0.6429 - val_acc: 0.6516\n",
      "Epoch 5/10\n",
      "13500/13500 [==============================] - 55s 4ms/step - loss: 0.6742 - acc: 0.5907 - val_loss: 0.6497 - val_acc: 0.6231\n",
      "Epoch 6/10\n",
      "13500/13500 [==============================] - 55s 4ms/step - loss: 0.6611 - acc: 0.6130 - val_loss: 0.6816 - val_acc: 0.5458\n",
      "Epoch 7/10\n",
      "13500/13500 [==============================] - 55s 4ms/step - loss: 0.5761 - acc: 0.6981 - val_loss: 0.3334 - val_acc: 0.8589\n",
      "Epoch 8/10\n",
      "13500/13500 [==============================] - 55s 4ms/step - loss: 0.4314 - acc: 0.8139 - val_loss: 0.2589 - val_acc: 0.8920\n",
      "Epoch 9/10\n",
      "13500/13500 [==============================] - 55s 4ms/step - loss: 0.3481 - acc: 0.8544 - val_loss: 0.2521 - val_acc: 0.9080\n",
      "Epoch 10/10\n",
      "13500/13500 [==============================] - 56s 4ms/step - loss: 0.3068 - acc: 0.8754 - val_loss: 0.2376 - val_acc: 0.9113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d38439e048>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x_train, x_test, y_train, y_test] = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "discriminator_model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.24\n",
      "Validation Accuracy: 91.13%\n"
     ]
    }
   ],
   "source": [
    "# Once you're happy with your discriminator model, evaluate this cell to save it:\n",
    "save_model(discriminator_model, './discriminator_model.h5')\n",
    "# Run these commands in the terminal to submit your model for assessment.\n",
    "# git add lab-07/discriminator_model.h5\n",
    "# git commit -m \"Add/update discriminator model.\"\n",
    "# git push\n",
    "# submit-lab 7\n",
    "\n",
    "score,acc = discriminator_model.evaluate(x_test, y_test, verbose = 2, batch_size = 64)\n",
    "print(\"Score: %.2f\" % (score))\n",
    "print(\"Validation Accuracy: %.2f%%\" % (acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
