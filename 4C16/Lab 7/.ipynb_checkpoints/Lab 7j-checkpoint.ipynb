{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 7 - Text generation with LSTM\n",
    "#\n",
    "# Step 1 (not assessed): build and train a model to generate text in the style of a corpus.\n",
    "#\n",
    "# Based on the Keras text generation example (https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py)\n",
    "#\n",
    "# Step 2: build a model to distinguish genuine from fake sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import essential modules\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Activation, Conv1D, Dropout, Flatten\n",
    "from keras.layers import CuDNNGRU, CuDNNLSTM, GaussianNoise, BatchNormalization\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.optimizers import RMSprop, Adam, Nadam, SGD\n",
    "from keras.models import Model, Sequential\n",
    "from keras.models import save_model, load_model\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras import initializers\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to sample an index from an array of predictions.\n",
    "#\n",
    "# The input array 'preds' should be the output of a text generation model.\n",
    "# The elements contain the values of the units in the final layer.\n",
    "# Each unit corresponds to a character in the text alphabet.\n",
    "# The final layer should have SoftMax activation, and thus the\n",
    "# value corresponds to the 'strength of prediction' of that character\n",
    "# as the next output value---so the maximum value indicates which character\n",
    "# is most strongly predicted (considerd most likely) as the next one.\n",
    "#\n",
    "def sample(preds, temperature=1.0):\n",
    "    # Convert to high-precision datatype (we are going to be manipulating some\n",
    "    # very small values in this function)\n",
    "    preds = np.asarray(preds).astype('float64')  \n",
    "    \n",
    "    # The next line has the effect of raising each prediction value to the power 1/T.\n",
    "    # It's done using logs to improve numerical precision.  This is a kind of value-dependent\n",
    "    # scaling: for T < 1.0 (1/T > 1.0), small values are made smaller (proportionally) than \n",
    "    # large values (unlike a linear scaling, such as multiplication by 0.9, which scales all values\n",
    "    # the same).\n",
    "    #\n",
    "    # Example: Consider that we have only two symbols (letters) in our alphabet, and our \n",
    "    # probabilities are [0.2, 0.8].  A temperature of 1.0 means 'do not adjust the\n",
    "    # probabilities at all', so in this case there will be a 20% chance that the \n",
    "    # function will return 'symbol 0' and an 80% chance  that it will return 'symbol 1'.\n",
    "    # Note that symbol 1 is 4x more likely than symbol 0.\n",
    "    #\n",
    "    # Now: if we supply a temperature of 0.5, our probabilites will be raised to the\n",
    "    # power 1/0.5 = 2, becoming [0.04, 0.64].  These will then be normalized to sum to 1,\n",
    "    # but anyway it is clear that symbol 1 is here 16x (the square of 4x) more likely than \n",
    "    # symbol 0.\n",
    "    #\n",
    "    # Conversely, for a temperature of 2, our probabilities will be raised to 0.5 (square-rooted),\n",
    "    # becoming [.4472, 0.8944] - and so here symbol 1 is only 2x (sqrt of 4x) more likely than\n",
    "    # symbol 0.\n",
    "    #\n",
    "    # So: low temperatures make the distribution peakier, exaggerating the difference between\n",
    "    # values.  High temperatures flatten the distribution, reducing the difference between values.\n",
    "    #\n",
    "    # As the return value is a sample of the manipulated distribution, manipulating it to\n",
    "    # be peakier (by supplying a low temperature) makes the sample more conservative, i.e.\n",
    "    # more likely to pick the highest-probability symbol.\n",
    "    #\n",
    "    # Making the distribution flatter (by suppyling a high temperature) causes the\n",
    "    # sample to be less conservative, i.e. more likely to pick some lower-likelihood\n",
    "    # symbol.\n",
    "    #\n",
    "    # Phew!\n",
    "    preds = np.exp(np.log(preds) / temperature)\n",
    "    \n",
    "    preds = preds / np.sum(preds)  # ensure that probs sum to 1\n",
    "    probas = np.random.multinomial(1, preds, 1)  # take 1 sample from the distribution\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original corpus length: 600901\n",
      "length for training: 480139\n",
      "char count 57\n"
     ]
    }
   ],
   "source": [
    "# Decide how much data to use for training.\n",
    "# You might want to reduce this to ~100k for faster experimentation, and then bring it back\n",
    "# to 600k when you're happy with your network architecture.\n",
    "# IMPORTANT: mke sure you end up with a 57-symbol alphabet after reducing the corpus size!\n",
    "# If the number of symbols (shown in the next cell) gets smaller than it was with the full\n",
    "# corpus, bring your sample size back up.  This is necessary because the encoding used for\n",
    "# training must match that used for assessment.\n",
    "#desired_num_chars = 600*1000  # Max: 600893\n",
    "desired_num_chars = 480139  # Max: 600893\n",
    "\n",
    "random.seed(43)  # Fix random seed for repeatable results.\n",
    "\n",
    "# Slurp down all of Nietzsche from Amazon.\n",
    "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path).read().lower()\n",
    "print('original corpus length:', len(text))\n",
    "\n",
    "start_index = random.randint(0, len(text) - desired_num_chars - 1)\n",
    "text = text[start_index:start_index + desired_num_chars]\n",
    "text\n",
    "print('length for training:', len(text))\n",
    "num_chars = len(sorted(list(set(text))))\n",
    "print('char count', num_chars)\n",
    "\n",
    "#for i in range (-100000, 100000):\n",
    "#    random.seed(i)\n",
    "#    path_i = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "#    text_i = open(path_i).read().lower()\n",
    "#    start_index_i = random.randint(0, len(text_i) - desired_num_chars - 1)\n",
    "#    text_i = text_i[start_index_i:start_index_i + desired_num_chars]\n",
    "#    num_chars_i = len(sorted(list(set(text_i))))\n",
    "#    if num_chars_i == 57: break\n",
    "\n",
    "#print('i', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n himself, and hence\n",
      "affords a clue to the understanding of the universe in general. the\n",
      "whole teleology is so planned that man during the last four thousand\n",
      "years shall be spoken of as a being existing from all eternity, and\n",
      "with reference to whom everything in the cosmos from its very inception\n",
      "is naturally ordered. yet everything evolved: there are no eternal facts\n",
      "as there are no absolute truths. accordingly, historical philosophising\n",
      "is henceforth indispensable, and with it honesty of judgment.\n",
      "\n",
      "[4] geworden.\n",
      "\n",
      "\n",
      "3\n",
      "\n",
      "=appreciation of simple truths.=--it is the characteristic of an\n",
      "advanced civilization to set a higher value upon little, simple truths,\n",
      "ascertained by scientific method, than upon the pleasing and magnificent\n",
      "errors originating in metaphysical and ã¦sthetical epochs and peoples. to\n",
      "begin with, the former are spoken of with contempt as if there could be\n",
      "no question of comparison respecting them, so rigid, homely, prosaic and\n",
      "even discouraging is the aspect of the first, \n"
     ]
    }
   ],
   "source": [
    "# Let's have a quick look at a random exceprt.\n",
    "#\n",
    "# Caution: Nietzsche might drive you mad: dare you behold more than 1000 of his terrible chars..? \n",
    "sample_length = 1000\n",
    "\n",
    "random.seed(None)  # Seeds random from current time (so re-eval this cell for a new sample).\n",
    "\n",
    "start_index = random.randint(0, len(text) - sample_length - 1)\n",
    "print(text[start_index:start_index+sample_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 57\n",
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¤', '¦', '«', 'ã']\n"
     ]
    }
   ],
   "source": [
    "# Establish the alphabet (set of symbols) we are going to use.\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "print(chars)\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))  # Map to look up index of a particular char (e.g. x['a'] = 0)\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))  # Map to look up char at an index (e.g. x[0] = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 160033\n"
     ]
    }
   ],
   "source": [
    "# Establish a training set of semi-redundant (i.e. overlapping) sequences of maxlen characters.\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []  # Not syntactic sentences, but just sequences of 40 chars pulled from the corpus.\n",
    "next_chars = [] # next_chars[n] stores the character which followed sentences[n]\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160033, 40, 57)\n",
      "(160033, 57)\n"
     ]
    }
   ],
   "source": [
    "# Convert the data to one-hot encoding.\n",
    "# 'x' will contain the one-hot encoding of the training 'sentences'.\n",
    "# 'y' will contain the one-hot encoding of the 'next char' for each sentence.\n",
    "#\n",
    "# \n",
    "# Let's consider that we have N sentences of length L:\n",
    "#\n",
    "# The 'native' encoding is an NxL matrix where element [n][l]\n",
    "# is the symbol index for character at index (l) of sentence (n)\n",
    "# (e.g., say, 5, corresponding to 'e').\n",
    "#\n",
    "# The one-hot encoding is an NxLxS matrix, where S is the \n",
    "# number of symbols in the alphabet, such that element [n][l][s]\n",
    "# is 1 if the character at index (l) in sentence (n) has the\n",
    "# symbol index (s), and 0 otherwise.\n",
    "def onehot_encode(sentence, maxlen):\n",
    "    x = np.zeros((maxlen, len(chars)), dtype=np.bool)\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[t, char_indices[char]] = 1\n",
    "    return x\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    x[i,:,:] = onehot_encode(sentence, maxlen)\n",
    "    y[i, :] = onehot_encode(next_chars[i], 1)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the generator model: a single GRU layer with 128 cells.\n",
    "#generator_model = Sequential()\n",
    "#generator_model.add(GRU(128, input_shape=(maxlen, len(chars))))\n",
    "#generator_model.add(Dense(len(chars)))\n",
    "#generator_model.add(Activation('softmax'))\n",
    "\n",
    "# You could experiment with NAdam instead of RMSProp.\n",
    "#optimizer = RMSprop(lr=0.01)\n",
    "#generator_model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "#trained_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnngru_1 (CuDNNGRU)       (None, 40, 64)            23616     \n",
      "_________________________________________________________________\n",
      "gaussian_noise_1 (GaussianNo (None, 40, 64)            0         \n",
      "_________________________________________________________________\n",
      "cu_dnngru_2 (CuDNNGRU)       (None, 128)               74496     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 57)                7353      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 57)                0         \n",
      "=================================================================\n",
      "Total params: 105,465\n",
      "Trainable params: 105,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#GRU generator\n",
    "gru_generator_model = Sequential()\n",
    "gru_generator_model.add(CuDNNGRU(64, return_sequences=True, input_shape=(maxlen, len(chars))))\n",
    "gru_generator_model.add(GaussianNoise(1))\n",
    "gru_generator_model.add(CuDNNGRU(128, return_sequences=False, input_shape=(maxlen, len(chars))))\n",
    "gru_generator_model.add(Dense(len(chars)))\n",
    "gru_generator_model.add(Activation('softmax'))\n",
    "\n",
    "# You could experiment with NAdam instead of RMSProp.\n",
    "gru_generator_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "gru_trained_epochs = 0\n",
    "gru_generator_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 128)               95744     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 57)                7353      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 57)                0         \n",
      "=================================================================\n",
      "Total params: 103,097\n",
      "Trainable params: 103,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LSTM generator\n",
    "lstm_generator_model = Sequential()\n",
    "lstm_generator_model.add(CuDNNLSTM(128, return_sequences=False, input_shape=(maxlen, len(chars))))\n",
    "lstm_generator_model.add(Dense(len(chars)))\n",
    "lstm_generator_model.add(Activation('softmax'))\n",
    "\n",
    "# You could experiment with NdaAm instead of RMSProp.\n",
    "#optimizer = Nadam(lr=0.005)\n",
    "lstm_generator_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "lstm_trained_epochs = 0\n",
    "lstm_generator_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               95232     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 57)                7353      \n",
      "=================================================================\n",
      "Total params: 102,585\n",
      "Trainable params: 102,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Keras Model\n",
    "keras_model = Sequential()\n",
    "keras_model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "keras_model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "opt = RMSprop(lr=0.01)\n",
    "keras_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnnlstm_2 (CuDNNLSTM)     (None, 40, 256)           322560    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40, 256)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_3 (CuDNNLSTM)     (None, 256)               526336    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 57)                14649     \n",
      "=================================================================\n",
      "Total params: 863,545\n",
      "Trainable params: 863,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#ML Model\n",
    "ml_model = Sequential()\n",
    "#ml_model.add(CuDNNLSTM(256, input_shape=(maxlen, len(chars))))\n",
    "#ml_model.add(Dropout(0.2))\n",
    "#ml_model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "ml_model.add(CuDNNLSTM(256, input_shape=(maxlen, len(chars)), return_sequences=True))\n",
    "ml_model.add(Dropout(0.2))\n",
    "ml_model.add(CuDNNLSTM(256))\n",
    "ml_model.add(Dropout(0.2))\n",
    "ml_model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "ml_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "ml_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence_list(seed_list, length=400, temperature=0.25, model_type='gru'):\n",
    "    sentence_list_1 = [];\n",
    "    generated_list_1 = [];\n",
    "    n = len(seed_list)\n",
    "    # copy lists\n",
    "    temperature_1 = temperature\n",
    "    for seed in seed_list:\n",
    "        sentence_list_1.append(seed[:])\n",
    "        generated_list_1.append(seed[:])\n",
    "    \n",
    "    for i in range(length):\n",
    "      \n",
    "        workdone = (i+1)*1.0 / length\n",
    "        sys.stdout.write(\"\\rgenerating {0:} sentences: [{1:20s}] {2:.1f}%\".format(model_type,\n",
    "                                                                                  '#' * int(workdone * 20), workdone*100))\n",
    "        sys.stdout.flush()\n",
    "            \n",
    "        x_pred_list = np.zeros((n, maxlen, len(chars)))\n",
    "        for j, sentence in enumerate(sentence_list_1):\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred_list[j, t, char_indices[char]] = 1.\n",
    "\n",
    "        start = time.time()\n",
    "        if model_type == 'lstm':\n",
    "            pred_list = lstm_generator_model.predict(x_pred_list, verbose=0)\n",
    "        elif model_type == 'keras':\n",
    "            pred_list = keras_generator_model.predict(x_pred_list, verbose=0)\n",
    "        elif model_type == 'ml':\n",
    "            pred_list = ml_model.predict(x_pred_list, verbose=0)\n",
    "        else:\n",
    "            pred_list = gru_generator_model.predict(x_pred_list, verbose=0)\n",
    "        end = time.time()\n",
    "\n",
    "        for j in range(n):\n",
    "            next_index_1 = sample(pred_list[j,:], temperature_1)\n",
    "            next_char_1 = indices_char[next_index_1]\n",
    "            generated_list_1[j] += next_char_1\n",
    "            sentence_list_1[j] = sentence_list_1[j][1:] + next_char_1\n",
    "    \n",
    "    sys.stdout.write(' - done\\n')\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    generated_list = generated_list_1\n",
    "    return generated_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence_list_n(seed_list, length=400, temperature=0.25, model_type='gru'):\n",
    "    sentence_list_1 = [];\n",
    "    sentence_list_2 = [];\n",
    "    sentence_list_3 = [];\n",
    "    generated_list_1 = [];\n",
    "    generated_list_2 = [];\n",
    "    generated_list_3 = [];\n",
    "    n = len(seed_list)\n",
    "    # copy lists\n",
    "    temperature_1 = temperature\n",
    "    temperature_2 = (temperature + 0.08)\n",
    "    #temperature_3 = max(0.01, (temperature - 0.15))\n",
    "    temperature_3 = (temperature + 0.15)\n",
    "    for seed in seed_list:\n",
    "        sentence_list_1.append(seed[:])\n",
    "        sentence_list_2.append(seed[:])\n",
    "        sentence_list_3.append(seed[:])\n",
    "        generated_list_1.append(seed[:])\n",
    "        generated_list_2.append(seed[:]) \n",
    "        generated_list_3.append(seed[:]) \n",
    "    \n",
    "    for i in range(length):\n",
    "      \n",
    "        workdone = (i+1)*1.0 / length\n",
    "        sys.stdout.write(\"\\rgenerating {0:} sentences: [{1:20s}] {2:.1f}%\"\n",
    "                         .format(model_type, '#' * int(workdone * 20), workdone*100))\n",
    "        sys.stdout.flush()\n",
    "            \n",
    "        x_pred_list = np.zeros((n, maxlen, len(chars)))\n",
    "        for j, sentence in enumerate(sentence_list_1):\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred_list[j, t, char_indices[char]] = 1.\n",
    "\n",
    "        start = time.time()\n",
    "        if model_type == 'lstm':\n",
    "            pred_list = lstm_generator_model.predict(x_pred_list, verbose=0)\n",
    "        elif model_type == 'keras':\n",
    "            pred_list = keras_generator_model.predict(x_pred_list, verbose=0)\n",
    "        elif model_type == 'ml':\n",
    "            pred_list = ml_model.predict(x_pred_list, verbose=0)\n",
    "        else:\n",
    "            pred_list = gru_generator_model.predict(x_pred_list, verbose=0)\n",
    "        end = time.time()\n",
    "\n",
    "        for j in range(n):\n",
    "            next_index_1 = sample(pred_list[j,:], temperature_1)\n",
    "            next_char_1 = indices_char[next_index_1]\n",
    "            generated_list_1[j] += next_char_1\n",
    "            sentence_list_1[j] = sentence_list_1[j][1:] + next_char_1\n",
    "            next_index_2 = sample(pred_list[j,:], temperature_2)\n",
    "            next_char_2 = indices_char[next_index_2]\n",
    "            generated_list_2[j] += next_char_2\n",
    "            sentence_list_2[j] = sentence_list_2[j][1:] + next_char_2\n",
    "            next_index_3 = sample(pred_list[j,:], temperature_3)\n",
    "            next_char_3 = indices_char[next_index_3]\n",
    "            generated_list_3[j] += next_char_3\n",
    "            sentence_list_3[j] = sentence_list_3[j][1:] + next_char_3\n",
    "    \n",
    "    sys.stdout.write(' - done\\n')\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    generated_list = generated_list_1 + generated_list_2 + generated_list_3\n",
    "    return generated_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sentences(seeds, sentences):\n",
    "    for seed, sentence in zip(seeds, sentences):\n",
    "        print('-'*5)\n",
    "        sys.stdout.write('\\x1b[32m')\n",
    "        sys.stdout.write(sentence[0:len(seed)])\n",
    "        sys.stdout.write('\\x1b[34m')\n",
    "        sys.stdout.write(sentence[len(seed):-1])\n",
    "        sys.stdout.write('\\x1b[m')\n",
    "        sys.stdout.write('\\n')    \n",
    "        sys.stdout.flush()\n",
    "        \n",
    "def pick_sentences(n, maxlen):\n",
    "    global text    \n",
    "    start_index_list = np.random.randint(len(text) - maxlen - 1, size=(1, n)).flatten().tolist()\n",
    "    seed_list = [] \n",
    "    for start_index in start_index_list:\n",
    "        seed_list.append(text[start_index: start_index + maxlen])\n",
    "    return seed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 0\n",
      "GRU\n",
      "Epoch 1/60\n",
      "160033/160033 [==============================] - 6s 35us/step - loss: 3.0204 - acc: 0.1500\n",
      "Epoch 2/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 2.8557 - acc: 0.1993\n",
      "Epoch 3/60\n",
      "160033/160033 [==============================] - 5s 30us/step - loss: 2.6119 - acc: 0.2590\n",
      "Epoch 4/60\n",
      "160033/160033 [==============================] - 5s 32us/step - loss: 2.4794 - acc: 0.2850\n",
      "Epoch 5/60\n",
      "160033/160033 [==============================] - 5s 30us/step - loss: 2.3898 - acc: 0.3056\n",
      "Epoch 6/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 2.3153 - acc: 0.3244\n",
      "Epoch 7/60\n",
      "160033/160033 [==============================] - 5s 31us/step - loss: 2.2567 - acc: 0.3378\n",
      "Epoch 8/60\n",
      "160033/160033 [==============================] - 5s 30us/step - loss: 2.2058 - acc: 0.3504\n",
      "Epoch 9/60\n",
      "160033/160033 [==============================] - 5s 32us/step - loss: 2.1636 - acc: 0.3607: 2s -  - ETA: 0s - loss: 2.1667 - a\n",
      "Epoch 10/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 2.1218 - acc: 0.3727\n",
      "Epoch 11/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 2.0874 - acc: 0.3841\n",
      "Epoch 12/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 2.0549 - acc: 0.3929\n",
      "Epoch 13/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 2.0261 - acc: 0.4015\n",
      "Epoch 14/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 2.0011 - acc: 0.4083\n",
      "Epoch 15/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.9772 - acc: 0.4155\n",
      "Epoch 16/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.9567 - acc: 0.4195\n",
      "Epoch 17/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.9341 - acc: 0.4249\n",
      "Epoch 18/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.9172 - acc: 0.4307\n",
      "Epoch 19/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.8990 - acc: 0.4350\n",
      "Epoch 20/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.8836 - acc: 0.4389\n",
      "Epoch 21/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.8699 - acc: 0.4433: 0s - loss: 1.87\n",
      "Epoch 22/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.8530 - acc: 0.4476\n",
      "Epoch 23/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.8423 - acc: 0.4522\n",
      "Epoch 24/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.8296 - acc: 0.4550\n",
      "Epoch 25/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.8192 - acc: 0.4575\n",
      "Epoch 26/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.8067 - acc: 0.4616\n",
      "Epoch 27/60\n",
      "160033/160033 [==============================] - 5s 30us/step - loss: 1.7985 - acc: 0.4637\n",
      "Epoch 28/60\n",
      "160033/160033 [==============================] - 5s 28us/step - loss: 1.7878 - acc: 0.4661\n",
      "Epoch 29/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.7795 - acc: 0.4687\n",
      "Epoch 30/60\n",
      "160033/160033 [==============================] - 5s 28us/step - loss: 1.7693 - acc: 0.4720\n",
      "Epoch 31/60\n",
      "160033/160033 [==============================] - 5s 28us/step - loss: 1.7609 - acc: 0.4738\n",
      "Epoch 32/60\n",
      "160033/160033 [==============================] - 5s 28us/step - loss: 1.7537 - acc: 0.4758\n",
      "Epoch 33/60\n",
      "160033/160033 [==============================] - 5s 28us/step - loss: 1.7462 - acc: 0.4772: 1s - los\n",
      "Epoch 34/60\n",
      "160033/160033 [==============================] - 5s 30us/step - loss: 1.7372 - acc: 0.4804\n",
      "Epoch 35/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.7333 - acc: 0.4821\n",
      "Epoch 36/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.7252 - acc: 0.4848\n",
      "Epoch 37/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.7172 - acc: 0.4864\n",
      "Epoch 38/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.7140 - acc: 0.4873\n",
      "Epoch 39/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.7071 - acc: 0.4889\n",
      "Epoch 40/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.7019 - acc: 0.4910\n",
      "Epoch 41/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.6989 - acc: 0.4916\n",
      "Epoch 42/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.6929 - acc: 0.4930\n",
      "Epoch 43/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.6889 - acc: 0.4945\n",
      "Epoch 44/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.6840 - acc: 0.4955\n",
      "Epoch 45/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.6771 - acc: 0.4973\n",
      "Epoch 46/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.6726 - acc: 0.5012\n",
      "Epoch 47/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.6695 - acc: 0.5005\n",
      "Epoch 48/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.6640 - acc: 0.5014\n",
      "Epoch 49/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.6615 - acc: 0.5022\n",
      "Epoch 50/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.6575 - acc: 0.5034\n",
      "Epoch 51/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.6536 - acc: 0.5044\n",
      "Epoch 52/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.6511 - acc: 0.5056\n",
      "Epoch 53/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.6469 - acc: 0.5068\n",
      "Epoch 54/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.6437 - acc: 0.5079\n",
      "Epoch 55/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.6416 - acc: 0.5080: 1s - loss:\n",
      "Epoch 56/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.6383 - acc: 0.5091\n",
      "Epoch 57/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.6365 - acc: 0.5092\n",
      "Epoch 58/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.6309 - acc: 0.5113\n",
      "Epoch 59/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.6295 - acc: 0.5110\n",
      "Epoch 60/60\n",
      "160033/160033 [==============================] - 5s 29us/step - loss: 1.6275 - acc: 0.5122\n",
      "LSTM\n",
      "Epoch 1/60\n",
      "160033/160033 [==============================] - 7s 44us/step - loss: 3.0625 - acc: 0.1571\n",
      "Epoch 2/60\n",
      "160033/160033 [==============================] - 4s 26us/step - loss: 2.7125 - acc: 0.2525\n",
      "Epoch 3/60\n",
      "160033/160033 [==============================] - 4s 26us/step - loss: 2.4711 - acc: 0.2996\n",
      "Epoch 4/60\n",
      "160033/160033 [==============================] - 4s 26us/step - loss: 2.3615 - acc: 0.3256\n",
      "Epoch 5/60\n",
      "160033/160033 [==============================] - 4s 26us/step - loss: 2.2914 - acc: 0.3380\n",
      "Epoch 6/60\n",
      "160033/160033 [==============================] - 4s 26us/step - loss: 2.2413 - acc: 0.3498\n",
      "Epoch 7/60\n",
      "160033/160033 [==============================] - 4s 26us/step - loss: 2.2009 - acc: 0.3608\n",
      "Epoch 8/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 2.1674 - acc: 0.3686\n",
      "Epoch 9/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 2.1373 - acc: 0.3771\n",
      "Epoch 10/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 2.1107 - acc: 0.3835: 3s - lo\n",
      "Epoch 11/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 2.0869 - acc: 0.3901\n",
      "Epoch 12/60\n",
      "160033/160033 [==============================] - 4s 26us/step - loss: 2.0620 - acc: 0.3956\n",
      "Epoch 13/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 2.0397 - acc: 0.4015\n",
      "Epoch 14/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 2.0177 - acc: 0.4075\n",
      "Epoch 15/60\n",
      "160033/160033 [==============================] - 4s 26us/step - loss: 1.9992 - acc: 0.4127\n",
      "Epoch 16/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.9808 - acc: 0.4174\n",
      "Epoch 17/60\n",
      "160033/160033 [==============================] - 4s 26us/step - loss: 1.9618 - acc: 0.4239\n",
      "Epoch 18/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.9452 - acc: 0.4275\n",
      "Epoch 19/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.9291 - acc: 0.4317\n",
      "Epoch 20/60\n",
      "160033/160033 [==============================] - 4s 24us/step - loss: 1.9120 - acc: 0.4369: 0s - loss: 1.9134 - acc:\n",
      "Epoch 21/60\n",
      "160033/160033 [==============================] - 4s 24us/step - loss: 1.8977 - acc: 0.4399\n",
      "Epoch 22/60\n",
      "160033/160033 [==============================] - 4s 24us/step - loss: 1.8847 - acc: 0.4428\n",
      "Epoch 23/60\n",
      "160033/160033 [==============================] - 4s 24us/step - loss: 1.8697 - acc: 0.4474\n",
      "Epoch 24/60\n",
      "160033/160033 [==============================] - 4s 24us/step - loss: 1.8575 - acc: 0.4503\n",
      "Epoch 25/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.8458 - acc: 0.4533\n",
      "Epoch 26/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.8331 - acc: 0.4575\n",
      "Epoch 27/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.8216 - acc: 0.4599\n",
      "Epoch 28/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.8099 - acc: 0.4630\n",
      "Epoch 29/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.7987 - acc: 0.4662\n",
      "Epoch 30/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.7881 - acc: 0.4693\n",
      "Epoch 31/60\n",
      "160033/160033 [==============================] - 4s 26us/step - loss: 1.7785 - acc: 0.4720\n",
      "Epoch 32/60\n",
      "160033/160033 [==============================] - 4s 26us/step - loss: 1.7671 - acc: 0.4750\n",
      "Epoch 33/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.7577 - acc: 0.4787\n",
      "Epoch 34/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.7489 - acc: 0.4801\n",
      "Epoch 35/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.7389 - acc: 0.4829\n",
      "Epoch 36/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.7310 - acc: 0.4855\n",
      "Epoch 37/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.7221 - acc: 0.4878\n",
      "Epoch 38/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.7125 - acc: 0.4911\n",
      "Epoch 39/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.7051 - acc: 0.4926\n",
      "Epoch 40/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.6964 - acc: 0.4953\n",
      "Epoch 41/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.6897 - acc: 0.4973: 2s -  - ETA: 1s - loss: 1.\n",
      "Epoch 42/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.6809 - acc: 0.5004\n",
      "Epoch 43/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.6736 - acc: 0.5018\n",
      "Epoch 44/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.6666 - acc: 0.5038\n",
      "Epoch 45/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.6600 - acc: 0.5068\n",
      "Epoch 46/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.6534 - acc: 0.5082\n",
      "Epoch 47/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.6466 - acc: 0.5101\n",
      "Epoch 48/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.6400 - acc: 0.5119\n",
      "Epoch 49/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.6332 - acc: 0.5139\n",
      "Epoch 50/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.6274 - acc: 0.5157\n",
      "Epoch 51/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.6209 - acc: 0.5180\n",
      "Epoch 52/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.6159 - acc: 0.5185\n",
      "Epoch 53/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.6091 - acc: 0.5209\n",
      "Epoch 54/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.6031 - acc: 0.5226\n",
      "Epoch 55/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.5977 - acc: 0.5247\n",
      "Epoch 56/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.5917 - acc: 0.5270\n",
      "Epoch 57/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.5880 - acc: 0.5280\n",
      "Epoch 58/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.5802 - acc: 0.5305\n",
      "Epoch 59/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.5761 - acc: 0.5315\n",
      "Epoch 60/60\n",
      "160033/160033 [==============================] - 4s 25us/step - loss: 1.5697 - acc: 0.5332\n",
      "Keras\n",
      "Epoch 1/60\n",
      "160033/160033 [==============================] - 102s 636us/step - loss: 2.0390 - acc: 0.4056\n",
      "Epoch 2/60\n",
      "160033/160033 [==============================] - 100s 624us/step - loss: 1.6682 - acc: 0.5067\n",
      "Epoch 3/60\n",
      "160033/160033 [==============================] - 99s 619us/step - loss: 1.5653 - acc: 0.5341\n",
      "Epoch 4/60\n",
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.5107 - acc: 0.5488\n",
      "Epoch 5/60\n",
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.4756 - acc: 0.5589\n",
      "Epoch 6/60\n",
      "160033/160033 [==============================] - 99s 619us/step - loss: 1.4502 - acc: 0.5654\n",
      "Epoch 7/60\n",
      "160033/160033 [==============================] - 99s 619us/step - loss: 1.4284 - acc: 0.5703\n",
      "Epoch 8/60\n",
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.4120 - acc: 0.5753\n",
      "Epoch 9/60\n",
      "160033/160033 [==============================] - 99s 619us/step - loss: 1.3994 - acc: 0.5776\n",
      "Epoch 10/60\n",
      "160033/160033 [==============================] - 100s 625us/step - loss: 1.3869 - acc: 0.5806\n",
      "Epoch 11/60\n",
      "160033/160033 [==============================] - 100s 624us/step - loss: 1.3754 - acc: 0.5845\n",
      "Epoch 12/60\n",
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.3662 - acc: 0.5862\n",
      "Epoch 13/60\n",
      "160033/160033 [==============================] - 99s 619us/step - loss: 1.3587 - acc: 0.5869\n",
      "Epoch 14/60\n",
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.3509 - acc: 0.5897\n",
      "Epoch 15/60\n",
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.3445 - acc: 0.5922\n",
      "Epoch 16/60\n",
      "160033/160033 [==============================] - 100s 624us/step - loss: 1.3399 - acc: 0.5926\n",
      "Epoch 17/60\n",
      "160033/160033 [==============================] - 99s 621us/step - loss: 1.3343 - acc: 0.5946\n",
      "Epoch 18/60\n",
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.3277 - acc: 0.5967\n",
      "Epoch 19/60\n",
      "160033/160033 [==============================] - 99s 619us/step - loss: 1.3219 - acc: 0.5982\n",
      "Epoch 20/60\n",
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.3192 - acc: 0.5963\n",
      "Epoch 21/60\n",
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.3141 - acc: 0.5999\n",
      "Epoch 22/60\n",
      "160033/160033 [==============================] - 99s 619us/step - loss: 1.3116 - acc: 0.5999\n",
      "Epoch 23/60\n",
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.3064 - acc: 0.6008\n",
      "Epoch 24/60\n",
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.3048 - acc: 0.6018\n",
      "Epoch 25/60\n",
      "160033/160033 [==============================] - 99s 619us/step - loss: 1.2995 - acc: 0.6038\n",
      "Epoch 26/60\n",
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.2959 - acc: 0.6034\n",
      "Epoch 27/60\n",
      "160033/160033 [==============================] - 99s 619us/step - loss: 1.2942 - acc: 0.6047\n",
      "Epoch 28/60\n",
      "160033/160033 [==============================] - 99s 619us/step - loss: 1.2910 - acc: 0.6051\n",
      "Epoch 29/60\n",
      "160033/160033 [==============================] - 99s 621us/step - loss: 1.2900 - acc: 0.6061\n",
      "Epoch 30/60\n",
      "160033/160033 [==============================] - 99s 619us/step - loss: 1.2868 - acc: 0.6063\n",
      "Epoch 31/60\n",
      "160033/160033 [==============================] - 100s 623us/step - loss: 1.2843 - acc: 0.6076\n",
      "Epoch 32/60\n",
      "160033/160033 [==============================] - 100s 626us/step - loss: 1.2835 - acc: 0.6079\n",
      "Epoch 33/60\n",
      "160033/160033 [==============================] - 100s 624us/step - loss: 1.2814 - acc: 0.6080\n",
      "Epoch 34/60\n",
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.2789 - acc: 0.6077\n",
      "Epoch 35/60\n",
      "160033/160033 [==============================] - 99s 621us/step - loss: 1.2774 - acc: 0.6081\n",
      "Epoch 36/60\n",
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.2747 - acc: 0.6085\n",
      "Epoch 37/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.2736 - acc: 0.6093\n",
      "Epoch 38/60\n",
      "160033/160033 [==============================] - 99s 621us/step - loss: 1.2725 - acc: 0.6093\n",
      "Epoch 39/60\n",
      "160033/160033 [==============================] - 99s 621us/step - loss: 1.2721 - acc: 0.6103\n",
      "Epoch 40/60\n",
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.2686 - acc: 0.6106\n",
      "Epoch 41/60\n",
      "160033/160033 [==============================] - 99s 621us/step - loss: 1.2658 - acc: 0.6115\n",
      "Epoch 42/60\n",
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.2653 - acc: 0.6115\n",
      "Epoch 43/60\n",
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.2650 - acc: 0.6115\n",
      "Epoch 44/60\n",
      "160033/160033 [==============================] - 99s 621us/step - loss: 1.2647 - acc: 0.6119\n",
      "Epoch 45/60\n",
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.2629 - acc: 0.6127\n",
      "Epoch 46/60\n",
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.2602 - acc: 0.6124\n",
      "Epoch 47/60\n",
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.2604 - acc: 0.6132\n",
      "Epoch 48/60\n",
      "160033/160033 [==============================] - 99s 621us/step - loss: 1.2600 - acc: 0.6136\n",
      "Epoch 49/60\n",
      "160033/160033 [==============================] - 99s 621us/step - loss: 1.2584 - acc: 0.6131\n",
      "Epoch 50/60\n",
      "160033/160033 [==============================] - 99s 621us/step - loss: 1.2581 - acc: 0.6127\n",
      "Epoch 51/60\n",
      "160033/160033 [==============================] - 99s 621us/step - loss: 1.2580 - acc: 0.6142\n",
      "Epoch 52/60\n",
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.2570 - acc: 0.6134\n",
      "Epoch 53/60\n",
      "160033/160033 [==============================] - 100s 623us/step - loss: 1.2546 - acc: 0.6148\n",
      "Epoch 54/60\n",
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.2528 - acc: 0.6152\n",
      "Epoch 55/60\n",
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.2540 - acc: 0.6135\n",
      "Epoch 56/60\n",
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.2512 - acc: 0.6154\n",
      "Epoch 57/60\n",
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.2515 - acc: 0.6154\n",
      "Epoch 58/60\n",
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.2498 - acc: 0.6164\n",
      "Epoch 59/60\n",
      "160033/160033 [==============================] - 99s 621us/step - loss: 1.2531 - acc: 0.6163\n",
      "Epoch 60/60\n",
      "160033/160033 [==============================] - 99s 620us/step - loss: 1.2523 - acc: 0.6152\n",
      "ML\n",
      "Epoch 1/100\n",
      "160033/160033 [==============================] - 35s 222us/step - loss: 2.3327 - acc: 0.3287\n",
      "Epoch 2/100\n",
      "160033/160033 [==============================] - 31s 197us/step - loss: 1.8594 - acc: 0.4515\n",
      "Epoch 3/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 1.6861 - acc: 0.4981\n",
      "Epoch 4/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 1.5785 - acc: 0.5270\n",
      "Epoch 5/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 1.5023 - acc: 0.5462\n",
      "Epoch 6/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 1.4445 - acc: 0.5626\n",
      "Epoch 7/100\n",
      "160033/160033 [==============================] - 32s 197us/step - loss: 1.3956 - acc: 0.5753\n",
      "Epoch 8/100\n",
      "160033/160033 [==============================] - 32s 197us/step - loss: 1.3511 - acc: 0.5864\n",
      "Epoch 9/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 1.3119 - acc: 0.5971\n",
      "Epoch 10/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 1.2743 - acc: 0.6062\n",
      "Epoch 11/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 1.2420 - acc: 0.6154\n",
      "Epoch 12/100\n",
      "160033/160033 [==============================] - 31s 197us/step - loss: 1.2102 - acc: 0.6227\n",
      "Epoch 13/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 1.1821 - acc: 0.6317\n",
      "Epoch 14/100\n",
      "160033/160033 [==============================] - 31s 197us/step - loss: 1.1561 - acc: 0.6374\n",
      "Epoch 15/100\n",
      "160033/160033 [==============================] - 32s 197us/step - loss: 1.1320 - acc: 0.6434\n",
      "Epoch 16/100\n",
      "160033/160033 [==============================] - 31s 197us/step - loss: 1.1086 - acc: 0.6512\n",
      "Epoch 17/100\n",
      "160033/160033 [==============================] - 31s 197us/step - loss: 1.0903 - acc: 0.6551\n",
      "Epoch 18/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 1.0670 - acc: 0.6623\n",
      "Epoch 19/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 1.0517 - acc: 0.6665\n",
      "Epoch 20/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 1.0333 - acc: 0.6703\n",
      "Epoch 21/100\n",
      "160033/160033 [==============================] - 31s 197us/step - loss: 1.0199 - acc: 0.6748\n",
      "Epoch 22/100\n",
      "160033/160033 [==============================] - 32s 198us/step - loss: 1.0025 - acc: 0.6806\n",
      "Epoch 23/100\n",
      "160033/160033 [==============================] - 31s 197us/step - loss: 0.9909 - acc: 0.6823\n",
      "Epoch 24/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.9792 - acc: 0.6857\n",
      "Epoch 25/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.9653 - acc: 0.6901\n",
      "Epoch 26/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.9561 - acc: 0.6920\n",
      "Epoch 27/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.9421 - acc: 0.6959\n",
      "Epoch 28/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.9343 - acc: 0.6983\n",
      "Epoch 29/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.9247 - acc: 0.7019\n",
      "Epoch 30/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.9149 - acc: 0.7040\n",
      "Epoch 31/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.9050 - acc: 0.7068\n",
      "Epoch 32/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.8975 - acc: 0.7094\n",
      "Epoch 33/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.8883 - acc: 0.7112\n",
      "Epoch 34/100\n",
      "160033/160033 [==============================] - 31s 197us/step - loss: 0.8847 - acc: 0.7126\n",
      "Epoch 35/100\n",
      "160033/160033 [==============================] - 31s 197us/step - loss: 0.8722 - acc: 0.7161\n",
      "Epoch 36/100\n",
      "160033/160033 [==============================] - 31s 197us/step - loss: 0.8669 - acc: 0.7173\n",
      "Epoch 37/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.8633 - acc: 0.7193\n",
      "Epoch 38/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.8553 - acc: 0.7210\n",
      "Epoch 39/100\n",
      "160033/160033 [==============================] - 31s 197us/step - loss: 0.8465 - acc: 0.7234\n",
      "Epoch 40/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.8432 - acc: 0.7240\n",
      "Epoch 41/100\n",
      "160033/160033 [==============================] - 31s 197us/step - loss: 0.8365 - acc: 0.7250\n",
      "Epoch 42/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.8328 - acc: 0.72753s - loss:\n",
      "Epoch 43/100\n",
      "160033/160033 [==============================] - 31s 197us/step - loss: 0.8250 - acc: 0.7293\n",
      "Epoch 44/100\n",
      "160033/160033 [==============================] - 32s 197us/step - loss: 0.8186 - acc: 0.7315\n",
      "Epoch 45/100\n",
      "160033/160033 [==============================] - 31s 197us/step - loss: 0.8159 - acc: 0.7317\n",
      "Epoch 46/100\n",
      "160033/160033 [==============================] - 32s 197us/step - loss: 0.8083 - acc: 0.7344\n",
      "Epoch 47/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.8052 - acc: 0.7354\n",
      "Epoch 48/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.7965 - acc: 0.7375\n",
      "Epoch 49/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.7944 - acc: 0.7393\n",
      "Epoch 50/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.7883 - acc: 0.7403\n",
      "Epoch 51/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.7822 - acc: 0.7427\n",
      "Epoch 52/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.7801 - acc: 0.7426\n",
      "Epoch 53/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.7741 - acc: 0.7443\n",
      "Epoch 54/100\n",
      "160033/160033 [==============================] - 32s 198us/step - loss: 0.7724 - acc: 0.7450\n",
      "Epoch 55/100\n",
      "160033/160033 [==============================] - 32s 197us/step - loss: 0.7637 - acc: 0.74741s - l\n",
      "Epoch 56/100\n",
      "160033/160033 [==============================] - 32s 198us/step - loss: 0.7635 - acc: 0.7483\n",
      "Epoch 57/100\n",
      "160033/160033 [==============================] - 32s 197us/step - loss: 0.7559 - acc: 0.7497\n",
      "Epoch 58/100\n",
      "160033/160033 [==============================] - 32s 198us/step - loss: 0.7545 - acc: 0.7503\n",
      "Epoch 59/100\n",
      "160033/160033 [==============================] - 32s 197us/step - loss: 0.7487 - acc: 0.7528\n",
      "Epoch 60/100\n",
      "160033/160033 [==============================] - 32s 198us/step - loss: 0.7419 - acc: 0.7532\n",
      "Epoch 61/100\n",
      "160033/160033 [==============================] - 32s 198us/step - loss: 0.7412 - acc: 0.75470s - loss: 0.7407 - acc: 0\n",
      "Epoch 62/100\n",
      "160033/160033 [==============================] - 32s 197us/step - loss: 0.7339 - acc: 0.7579\n",
      "Epoch 63/100\n",
      "160033/160033 [==============================] - 32s 198us/step - loss: 0.7282 - acc: 0.7574\n",
      "Epoch 64/100\n",
      "160033/160033 [==============================] - 32s 197us/step - loss: 0.7234 - acc: 0.7600\n",
      "Epoch 65/100\n",
      "160033/160033 [==============================] - 32s 197us/step - loss: 0.7239 - acc: 0.7605\n",
      "Epoch 66/100\n",
      "160033/160033 [==============================] - 32s 197us/step - loss: 0.7225 - acc: 0.7602\n",
      "Epoch 67/100\n",
      "160033/160033 [==============================] - 31s 197us/step - loss: 0.7139 - acc: 0.7629\n",
      "Epoch 68/100\n",
      "160033/160033 [==============================] - 32s 197us/step - loss: 0.7119 - acc: 0.7635\n",
      "Epoch 69/100\n",
      "160033/160033 [==============================] - 32s 197us/step - loss: 0.7059 - acc: 0.7653\n",
      "Epoch 70/100\n",
      "160033/160033 [==============================] - 31s 197us/step - loss: 0.7011 - acc: 0.7661\n",
      "Epoch 71/100\n",
      "160033/160033 [==============================] - 32s 197us/step - loss: 0.7014 - acc: 0.7670\n",
      "Epoch 72/100\n",
      "160033/160033 [==============================] - 32s 197us/step - loss: 0.6946 - acc: 0.7696\n",
      "Epoch 73/100\n",
      "160033/160033 [==============================] - 32s 197us/step - loss: 0.6934 - acc: 0.7692\n",
      "Epoch 74/100\n",
      "160033/160033 [==============================] - 31s 197us/step - loss: 0.6882 - acc: 0.7697\n",
      "Epoch 75/100\n",
      "160033/160033 [==============================] - 31s 197us/step - loss: 0.6864 - acc: 0.7706\n",
      "Epoch 76/100\n",
      "160033/160033 [==============================] - 32s 197us/step - loss: 0.6829 - acc: 0.7724\n",
      "Epoch 77/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.6758 - acc: 0.7741\n",
      "Epoch 78/100\n",
      "160033/160033 [==============================] - 31s 197us/step - loss: 0.6730 - acc: 0.7754\n",
      "Epoch 79/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.6709 - acc: 0.77653s\n",
      "Epoch 80/100\n",
      "160033/160033 [==============================] - 32s 197us/step - loss: 0.6698 - acc: 0.7761\n",
      "Epoch 81/100\n",
      "160033/160033 [==============================] - 31s 197us/step - loss: 0.6632 - acc: 0.7777\n",
      "Epoch 82/100\n",
      "160033/160033 [==============================] - 32s 197us/step - loss: 0.6590 - acc: 0.7784\n",
      "Epoch 83/100\n",
      "160033/160033 [==============================] - 32s 197us/step - loss: 0.6583 - acc: 0.7797\n",
      "Epoch 84/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.6527 - acc: 0.7822\n",
      "Epoch 85/100\n",
      "160033/160033 [==============================] - 31s 197us/step - loss: 0.6475 - acc: 0.7827\n",
      "Epoch 86/100\n",
      "160033/160033 [==============================] - 31s 197us/step - loss: 0.6487 - acc: 0.7830\n",
      "Epoch 87/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.6464 - acc: 0.7838\n",
      "Epoch 88/100\n",
      "160033/160033 [==============================] - 32s 197us/step - loss: 0.6418 - acc: 0.7852\n",
      "Epoch 89/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.6355 - acc: 0.7873\n",
      "Epoch 90/100\n",
      "160033/160033 [==============================] - 31s 197us/step - loss: 0.6355 - acc: 0.7861\n",
      "Epoch 91/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.6312 - acc: 0.7877\n",
      "Epoch 92/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.6283 - acc: 0.7895\n",
      "Epoch 93/100\n",
      "160033/160033 [==============================] - 31s 197us/step - loss: 0.6239 - acc: 0.7909\n",
      "Epoch 94/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.6259 - acc: 0.7899\n",
      "Epoch 95/100\n",
      "160033/160033 [==============================] - 31s 197us/step - loss: 0.6168 - acc: 0.7928\n",
      "Epoch 96/100\n",
      "160033/160033 [==============================] - 32s 197us/step - loss: 0.6123 - acc: 0.7947\n",
      "Epoch 97/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.6103 - acc: 0.7961\n",
      "Epoch 98/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.6088 - acc: 0.7961\n",
      "Epoch 99/100\n",
      "160033/160033 [==============================] - 31s 197us/step - loss: 0.6029 - acc: 0.7971\n",
      "Epoch 100/100\n",
      "160033/160033 [==============================] - 31s 196us/step - loss: 0.6013 - acc: 0.7972\n"
     ]
    }
   ],
   "source": [
    "# Generate 3 seeds which we will use to inspect the progress of our training:\n",
    "#preview_seeds = pick_sentences(3, maxlen=40)\n",
    "\n",
    "# Train the model, output generated text after each iteration\n",
    "for iteration in range(0, 1):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    print('GRU')\n",
    "    gru_generator_model.fit(x, y,\n",
    "                  batch_size=1024,\n",
    "                  epochs=60)\n",
    "    print('LSTM')\n",
    "    lstm_generator_model.fit(x, y,\n",
    "                  batch_size=1024,\n",
    "                  epochs=60)\n",
    "    print('Keras')\n",
    "    keras_model.fit(x, y, batch_size=128,\n",
    "                   epochs=60)\n",
    "    print('ML')\n",
    "    ml_model.fit(x, y, batch_size=64, epochs=100)\n",
    "    #generated_sentences = generate_sentence_list(preview_seeds)\n",
    "    #print_sentences(preview_seeds, generated_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ml sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32m to which sense and heart prompt them--a\u001b[34mnd who developed in the great spirit kn\u001b[m\n",
      "-----\n",
      "\u001b[32m complaisant and wanton surrender to the\u001b[34m suffering man indestingly was for the \u001b[m\n",
      "-----\n",
      "\u001b[32ma prejudice, perhaps a\n",
      "prematureness or \u001b[34mexperiences, the great reasons of some\n",
      "\u001b[m\n",
      "-----\n",
      "\u001b[32m our\n",
      "knowledge can permit only pleasure \u001b[34min something desires to spirituality an\u001b[m\n",
      "-----\n",
      "\u001b[32mery seductive atmosphere--of the moral\n",
      "m\u001b[34maxurs of the world, phologically discov\u001b[m\n",
      "-----\n",
      "\u001b[32mined to command, in whom the\n",
      "judgment an\u001b[34md scholar, when in dream in the most en\u001b[m\n",
      "-----\n",
      "\u001b[32m been a long tragedy in its origin.\n",
      "\n",
      "26.\u001b[34m what they all werragle of the world, p\u001b[m\n",
      "-----\n",
      "\u001b[32mon of many kinds of morality. in every \"\u001b[34mnew for the post concernated in the pos\u001b[m\n",
      "-----\n",
      "\u001b[32mif we please, become sensible, even in o\u001b[34mur grammatical from the posters of his \u001b[m\n",
      "-----\n",
      "\u001b[32mand again and again,\n",
      "the one of whom i h\u001b[34mave seen faith in his countroment, and \u001b[m\n",
      "-----\n",
      "\u001b[32mtions--as preparation for a theory of\n",
      "ty\u001b[34me morality, which they will be the prov\u001b[m\n",
      "-----\n",
      "\u001b[32mhen\n",
      "discovers almost repeatedly througho\u001b[34mut and self-control and\n",
      "distrust of the\u001b[m\n",
      "-----\n",
      "\u001b[32mluence, as regards the after-effect of k\u001b[34mnowledge of a defend that the \"freedom \u001b[m\n",
      "-----\n",
      "\u001b[32mho calls\n",
      "out to women today: mulier tace\u001b[34m a \"nation\" to which they will not dece\u001b[m\n",
      "-----\n",
      "\u001b[32mives herself about him, when\n",
      "she loves h\u001b[34mim fasts all good and its reason which \u001b[m\n",
      "-----\n",
      "\u001b[32mnion:\n",
      "another person has not easily a ri\u001b[34mght for the find of life and even in th\u001b[m\n",
      "-----\n",
      "\u001b[32mthe sight of the suffering of others: th\u001b[34mere is no doubt that the most standards\u001b[m\n",
      "-----\n",
      "\u001b[32mesent--i call it the moral hypocrisy of\n",
      "\u001b[34mthe most enthiess, and the anstarting s\u001b[m\n",
      "-----\n",
      "\u001b[32m contempt for that which is called their\u001b[34m countreshed and lation of the will, in\u001b[m\n",
      "-----\n",
      "\u001b[32mhe constraints and fasten the knots whic\u001b[34mh we find the nature of the soul, where\u001b[m\n",
      "-----\n",
      "\u001b[32mnd also literally): he has neither rhyth\u001b[34mer--fon the passionality of incenture, \u001b[m\n",
      "-----\n",
      "\u001b[32mect; in a word, he who\n",
      "wills believes wi\u001b[34mth an an action, namely, impessible, an\u001b[m\n",
      "-----\n",
      "\u001b[32mhen i analyze the process that is expres\u001b[34mslated to the soul and word, \"not and m\u001b[m\n",
      "-----\n",
      "\u001b[32mspirit which is, in an equal\n",
      "degree, sel\u001b[34mf power--they will be a greated to them\u001b[m\n",
      "-----\n",
      "\u001b[32m in the value of its intention.\n",
      "the inte\u001b[34mllectual world, philosophers?--more cha\u001b[m\n",
      "-----\n",
      "\u001b[32miving us most cruelly. not\n",
      "the world as \u001b[34mthe most sufficions of the past; all th\u001b[m\n",
      "-----\n",
      "\u001b[32mially the art of deceiving--deceiving wi\u001b[34mth subjected to account of a \"thing in \u001b[m\n",
      "-----\n",
      "\u001b[32mwas\n",
      "only giving names to things. on the \u001b[34mother hand who wanton his most refined,\u001b[m\n",
      "-----\n",
      "\u001b[32mhas hitherto played its game in\n",
      "respect \u001b[34mthe contrary!\n",
      "\n",
      "12. \"the dangerous torma\u001b[m\n",
      "-----\n",
      "\u001b[32mss, patience, and spirituality. one\n",
      "man \u001b[34mfor example, sto instinct for ranger, a\u001b[m\n",
      "-----\n",
      "\u001b[32m\n",
      "and self-ridicule. the spectacle of the\u001b[34m same as to his basis and all the world\u001b[m\n",
      "-----\n",
      "\u001b[32mr \"family duties\"; it seems that they ha\u001b[34mve have to say \"meriously and already r\u001b[m\n",
      "-----\n",
      "\u001b[32mmething to himself, and in a loud voice;\u001b[34m and thereby the entire lation of the c\u001b[m\n",
      "-----\n",
      "\u001b[32merence to the seriousness of the faith,\n",
      "\u001b[34mof which an evolution when in an enerit\u001b[m\n",
      "-----\n",
      "\u001b[32mso near to us, can be complete--so\n",
      "that \u001b[34mwhich has the art of desirable and with\u001b[m\n",
      "-----\n",
      "\u001b[32m, and not infrequently\n",
      "achieved in the m\u001b[34most condition of the problems of man, t\u001b[m\n",
      "-----\n",
      "\u001b[32maving been got rid of--the\n",
      "result being \u001b[34mno attain of a philosopher, that laws b\u001b[m\n",
      "-----\n",
      "\u001b[32mems of pleasure and pain and sympathy; a\u001b[34mnd who want now take unfour and in gene\u001b[m\n",
      "-----\n",
      "\u001b[32mwise) to first\n",
      "ask oneself: \"what morali\u001b[34mty dare the most difficult to which the\u001b[m\n",
      "-----\n",
      "\u001b[32mngs to the tendency and\n",
      "fundamental tast\u001b[34me and strength which is no longer perha\u001b[m\n",
      "-----\n",
      "\u001b[32mattracted by the riddles which the confl\u001b[34mict discovered, and the \"freedom of the\u001b[m\n",
      "-----\n",
      "\u001b[32ml the meanness, all\n",
      "the semi-animal pove\u001b[34ms, the type of man man from all the ins\u001b[m\n",
      "-----\n",
      "\u001b[32mnomy in the use of blessings is the drea\u001b[34mm of the individual.\n",
      "\n",
      "133. it cause thi\u001b[m\n",
      "-----\n",
      "\u001b[32mnally mingled a slight disdain for the \"\u001b[34mhow marking \"how such as a condition of\u001b[m\n",
      "-----\n",
      "\u001b[32m must take his stand in this matter upon\u001b[34m have always to be offence and being th\u001b[m\n",
      "-----\n",
      "\u001b[32m been a recluse--ever expressed his actu\u001b[34mal soul, and also makes himself such a \u001b[m\n",
      "-----\n",
      "\u001b[32med\n",
      "inexorably and frantically to be love\u001b[34m affecter to as something that is and t\u001b[m\n",
      "-----\n",
      "\u001b[32mmself in them, and in the rights which h\u001b[34mas been a noble of the strength of hims\u001b[m\n",
      "-----\n",
      "\u001b[32mhristo-european\n",
      "morality--suffers from a\u001b[34m great reasons of society and necessity\u001b[m\n",
      "-----\n",
      "\u001b[32m them, and him who enjoys their fruit, a\u001b[34mnd also the most standpoint, for which \u001b[m\n",
      "-----\n",
      "\u001b[32mthe basis\n",
      "of perspective estimates and s\u001b[34mubtlety, which is now life and great ri\u001b[m\n",
      "-----\n",
      "\u001b[32mo basis for this depression at hand if a\u001b[34m noble of the straintal order is only a\u001b[m\n",
      "-----\n",
      "\u001b[32mor even with \"modern parliamentarism\" (t\u001b[34mhis man and more production of the worl\u001b[m\n",
      "-----\n",
      "\u001b[32mconcealed, the most divergent, the man b\u001b[34meyond the assumed it believe that in ev\u001b[m\n",
      "-----\n",
      "\u001b[32m which he refuses to conceal, his\n",
      "astoni\u001b[34mshment, the great enough of the possibl\u001b[m\n",
      "-----\n",
      "\u001b[32ms its way like a living touchstone,\n",
      "undi\u001b[34mrstand it were desires to presumption, \u001b[m\n",
      "-----\n",
      "\u001b[32my,\" as well as \"absolute knowledge\" and \u001b[34mthe most delicate sagetful conscience: \u001b[m\n",
      "-----\n",
      "\u001b[32mure-seeking; and the\n",
      "original home atmos\u001b[34mpology of moral thensions, which they l\u001b[m\n",
      "-----\n",
      "\u001b[32mmense scale, that greek and indian\n",
      "liter\u001b[34mated the senses, the strength of his ow\u001b[m\n",
      "-----\n",
      "\u001b[32mn attempt at\n",
      "self-destruction--of his \"g\u001b[34mood conscience--\"\n",
      "a strange english, th\u001b[m\n",
      "-----\n",
      "\u001b[32mtially fundamental\n",
      "tendency in latter-da\u001b[34my contrount to see in this art and subt\u001b[m\n",
      "-----\n",
      "\u001b[32munscrupulous enthusiast for big, handsom\u001b[34med, the majority of the most different \u001b[m\n",
      "-----\n",
      "\u001b[32mre, should any one speak of it in their\n",
      "\u001b[34mrealise which has been so far from the \u001b[m\n",
      "-----\n",
      "\u001b[32ming public events and personages; above \u001b[34mall the most extentive and taste and st\u001b[m\n",
      "-----\n",
      "\u001b[32mociety believing in\n",
      "a long scale of grad\u001b[34mations of rank of the individual (and a\u001b[m\n",
      "-----\n",
      "\u001b[32mm, is secretly or openly anti-christian,\u001b[34m however, the strength of his instance,\u001b[m\n",
      "-----\n",
      "\u001b[32m\n",
      "must, therefore, be further developed i\u001b[34mn prof continuently the majority of lat\u001b[m\n",
      "-----\n",
      "\u001b[32mrience, as it seems to me, always\n",
      "implie\u001b[34md, certain the most conscience with the\u001b[m\n",
      "-----\n",
      "\u001b[32mdering psychology of\n",
      "former times, which\u001b[34m know have to say \"the most spiritualit\u001b[m\n",
      "-----\n",
      "\u001b[32mnal and arbitrarily manifested in relati\u001b[34mon to the post concernate them to infle\u001b[m\n",
      "-----\n",
      "\u001b[32mother, perhaps, kant\n",
      "especially, gives u\u001b[34ms to be the end of the most sense of th\u001b[m\n",
      "-----\n",
      "\u001b[32m a god.\n",
      "\n",
      "142. the chastest utterance i e\u001b[34mver the end, light, and the will, indee\u001b[m\n",
      "-----\n",
      "\u001b[32mgs and doctrines\n",
      "are called \"equality of\u001b[34m bad sacrificed, he is self-divined of \u001b[m\n",
      "-----\n",
      "\u001b[32mse rarer and rarely gratified men, who a\u001b[34mre not conscience, in the same will has\u001b[m\n",
      "-----\n",
      "\u001b[32m-wishing[21] must be reckoned; i mean th\u001b[34me most enthiess of his soul, as a case \u001b[m\n",
      "-----\n",
      "\u001b[32malways\n",
      "implies unfortunate experience?--\u001b[34mto has the most distrust of the soul, w\u001b[m\n",
      "-----\n",
      "\u001b[32mamped,\n",
      "and falsified. but there is no do\u001b[34mubt that the most discovery of the most\u001b[m\n",
      "-----\n",
      "\u001b[32mur neighbour's\n",
      "neighbour\":--so thinks ev\u001b[34mery soul and without desires and master\u001b[m\n",
      "-----\n",
      "\u001b[32m which modestly and unconsciously longs\n",
      "\u001b[34mto one as such a philosopher are someth\u001b[m\n",
      "-----\n",
      "\u001b[32mess!\n",
      "\n",
      "young, a flower-decked cavern home\u001b[34m, and the difference of man, which is n\u001b[m\n",
      "-----\n",
      "\u001b[32mmpers. they are by no means enemies of r\u001b[34mank and not be to one will\n",
      "be believing\u001b[m\n",
      "-----\n",
      "\u001b[32m to one's own\n",
      "liberation, to the voluptu\u001b[34mous and colfring the problems of man, t\u001b[m\n",
      "-----\n",
      "\u001b[32muman nature, which every\n",
      "thinking mind w\u001b[34mithout is of their\n",
      "eyes, it is the comp\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "\u001b[32m he overturns whatever he\n",
      "finds veiled o\u001b[34mf a god, and in a conduct concerns the \u001b[m\n",
      "-----\n",
      "\u001b[32malk\n",
      "and laugh, and whom one may send to \u001b[34madvact the same advancement and of some\u001b[m\n",
      "-----\n",
      "\u001b[32m gives up everything for him, does not p\u001b[34mresent the most different from the posi\u001b[m\n",
      "-----\n",
      "\u001b[32m\n",
      "conclusions with the artificial, as do \u001b[34mnot believe that in its own science.\n",
      "\n",
      "\n",
      "\u001b[m\n",
      "-----\n",
      "\u001b[32mman has allowed himself to be\n",
      "persuaded \u001b[34mthe distrustful and artists of mankind,\u001b[m\n",
      "-----\n",
      "\u001b[32mly have?) that which i always stood most\u001b[34m indifeetence, for the sake of latest g\u001b[m\n",
      "-----\n",
      "\u001b[32mnsters should be careful lest he thereby\u001b[34m alone who have done as a man of lates \u001b[m\n",
      "-----\n",
      "\u001b[32myoung, in the penal laws (which have an \u001b[34meldient and possestion of the powerful \u001b[m\n",
      "-----\n",
      "\u001b[32m, and because scientificness leads to\n",
      "th\u001b[34me whole or all has the position of the \u001b[m\n",
      "-----\n",
      "\u001b[32mg similarities, yet in the same\n",
      "mental c\u001b[34monscience to express in the promach of \u001b[m\n",
      "-----\n",
      "\u001b[32mhat is why so many people crave social i\u001b[34mntellectual instance, subject in the pr\u001b[m\n",
      "-----\n",
      "\u001b[32mit that egoism\n",
      "belongs to the essence of\u001b[34m the great\n",
      "could have to say that is al\u001b[m\n",
      "-----\n",
      "\u001b[32mnd self deception: the worst systems of \u001b[34mmorals as the finds and self-control of\u001b[m\n",
      "-----\n",
      "\u001b[32mfection. about the jews, for instance, l\u001b[34mive, which the agtitner than and\n",
      "distru\u001b[m\n",
      "-----\n",
      "\u001b[32m refined, is defended by them with\n",
      "argum\u001b[34ment of his self-and mastery of all kind\u001b[m\n",
      "-----\n",
      "\u001b[32mlly brings requital, (that is, is gratef\u001b[34mul and all the individual (and the slae\u001b[m\n",
      "-----\n",
      "\u001b[32mdious age in puncto of \"costumes,\" i mea\u001b[34mn, and stretts of the forth self-contro\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# For a more complete inspection, print out a load of sentences:\n",
    "#\n",
    "num_sentences = 100             # how many to generate\n",
    "sentence_length = 40            # 100--400 is good\n",
    "sample_temperature = 0.25       # see discussion of temperature up near the top\n",
    "#sample_temperature = 0.1\n",
    "\n",
    "start_index_list = np.random.randint(len(text) - maxlen - 1, size=(1, num_sentences)).flatten().tolist()\n",
    "preview_seeds = [] \n",
    "for start_index in start_index_list:\n",
    "    preview_seeds.append(text[start_index: start_index + maxlen])\n",
    "\n",
    "#gru_generated_sentences = generate_sentence_list(preview_seeds, length=sentence_length, temperature=sample_temperature); \n",
    "#print_sentences(preview_seeds, gru_generated_sentences)\n",
    "\n",
    "#lstm_generated_sentences = generate_sentence_list(preview_seeds, length=sentence_length, temperature=sample_temperature, \n",
    "#                                                 model_type='lstm'); \n",
    "#print_sentences(preview_seeds, lstm_generated_sentences)\n",
    "\n",
    "#keras_generated_sentences = generate_sentence_list(preview_seeds, length=sentence_length, temperature=sample_temperature,\n",
    "#                                                  model_type='keras'); \n",
    "#print_sentences(preview_seeds, keras_generated_sentences)\n",
    "\n",
    "ml_generated_sentences = generate_sentence_list(preview_seeds, length=sentence_length, temperature=sample_temperature,\n",
    "                                               model_type='ml'); \n",
    "print_sentences(preview_seeds, ml_generated_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just a checkpoint, which will let you download and re-upload (or add to git) this model.\n",
    "save_model(gru_generator_model, './gru_generator_model.h5')\n",
    "save_model(lstm_generator_model, './lstm_generator_model.h5')\n",
    "save_model(keras_model, './keras_generator_model.h5')\n",
    "save_model(ml_model, './ml_generator_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_generator_model = load_model('./gru_generator_model.h5')\n",
    "lstm_generator_model = load_model('./lstm_generator_model.h5')\n",
    "keras_model = load_model('./keras_generator_model.h5')\n",
    "ml_model = load_model('./ml_generator_model.h5')\n",
    "#ml_model = load_model('./cluster_generator_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "generating ml sentences: [                    ] 2.5%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\trewm\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:49: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ml sentences: [####################] 100.0% - done\n"
     ]
    }
   ],
   "source": [
    "# Generating the training fake sentences for the Discriminator network\n",
    "#\n",
    "# These are saved to the file 'fake.pkl' -- you could download this to your\n",
    "# user drive and re-upload it in a subsequent session, to save regenerating\n",
    "# it again (in which case you don't need to evaluate this cell).\n",
    "\n",
    "#training_seeds = pick_sentences(3000, maxlen=40)\n",
    "training_seeds = pick_sentences(5000, maxlen=40)\n",
    "#training_generated_sentences = (generate_sentence_list_n(training_seeds, length=40) \n",
    "#                                + generate_sentence_list_n(training_seeds, length=40, model_type='lstm'))\n",
    "#training_generated_sentences = generate_sentence_list(training_seeds, length=40, temperature=0.1, model_type='lstm')\n",
    "training_generated_sentences = generate_sentence_list_n(training_seeds, length=40, temperature=0.25, model_type='ml')\n",
    "\n",
    "# Strip out the initial 40 chars (the seed sequence, which is genuine data from the corpus).\n",
    "for i, sentence in enumerate(training_generated_sentences):\n",
    "    training_generated_sentences[i] = sentence[40:40+40]\n",
    "    \n",
    "output = open('fake.pkl', 'wb')\n",
    "pickle.dump(training_seeds, output)\n",
    "pickle.dump(training_generated_sentences, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training set from the file\n",
    "pkl_file = open('fake.pkl', 'rb')\n",
    "training_seeds = pickle.load(pkl_file)\n",
    "training_generated_sentences = pickle.load(pkl_file)\n",
    "pkl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num generated:  15000\n",
      "All training sequences:  30000\n"
     ]
    }
   ],
   "source": [
    "# Make a 50:50 set of 'fake' (generated) and genuine sentences:\n",
    "num_generated = len(training_generated_sentences)\n",
    "print('Num generated: ', num_generated)\n",
    "training_real_sentences = pick_sentences(num_generated, maxlen=40)\n",
    "\n",
    "all_training_sentences = training_generated_sentences + training_real_sentences\n",
    "\n",
    "n = len(all_training_sentences)\n",
    "x = np.zeros((n, 40, len(chars)))\n",
    "y = np.zeros((n, 1))\n",
    "print('All training sequences: ', n)\n",
    "\n",
    "for i, sentence in enumerate(all_training_sentences):\n",
    "    x[i, :, :] = onehot_encode(sentence, maxlen=40)\n",
    "y[num_generated:] = 1  # Encodes the fact that sentences with indexes larger than (num_generated) are real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotLossAccuracy(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.acc = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.val_acc = []\n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(int(self.i))\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        \n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(16, 6))\n",
    "        plt.plot([1, 2])\n",
    "        plt.subplot(121) \n",
    "        plt.plot(self.x, self.losses, label=\"train loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"validation loss\")\n",
    "        plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.title('Model Loss')\n",
    "        plt.legend()\n",
    "        plt.subplot(122)         \n",
    "        plt.plot(self.x, self.acc, label=\"training accuracy\")\n",
    "        plt.plot(self.x, self.val_acc, label=\"validation accuracy\")\n",
    "        plt.legend()\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "compiled.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_9 (GRU)                  (None, 64)                23424     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 23,489\n",
      "Trainable params: 23,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "\n",
    "# Define some layers here..\n",
    "\n",
    "# Use your layers to create the model.\n",
    "discriminator_model = Sequential()\n",
    "#discriminator_model.add(LSTM(128, dropout=0.6, recurrent_dropout=0.7,\n",
    "#                            input_shape=(maxlen, len(chars))))\n",
    "#discriminator_model.add(LSTM(256, dropout=0.0, recurrent_dropout=0.01,\n",
    "#                             kernel_regularizer=l2(0.2),\n",
    "#                             input_shape=(maxlen, len(chars))))\n",
    "\n",
    "#inputs = Input(shape=(40, 59))\n",
    "#h = LSTM(256)(inputs)\n",
    "#h = Dropout(0.2)(h)\n",
    "#h = Dense(1024, activation='relu')(h)\n",
    "#h = LSTM(256, return_sequences=False)(h)\n",
    "#h = Dense(512, activation='tanh')(h)\n",
    "\n",
    "#output = Dense(1, activation='softmax')(h)\n",
    "\n",
    "discriminator_model = Sequential()\n",
    "#discriminator_model.add(Embedding(4020, 40, input_length=59))\n",
    "#discriminator_model.add(LSTM(256, dropout = 0.2, return_sequences=True, \n",
    "#                             recurrent_dropout = 0.2, input_shape=(maxlen, len(chars))))\n",
    "#                             unit_forget_bias=True, kernel_regularizer=l1(0.01), recurrent_regularizer=l2(0.01)))\n",
    "#discriminator_model.add(GRU(128, input_shape=(maxlen, len(chars))))\n",
    "#discriminator_model.add(BatchNormalization())\n",
    "#discriminator_model.add(LSTM(256, recurrent_dropout=0.0, return_sequences=False, input_shape=(maxlen, len(chars))))\n",
    "#discriminator_model.add(LSTM(128))\n",
    "#discriminator_model.add(Conv1D(64, 5, activation='relu', padding='valid', input_shape=(maxlen, len(chars))))\n",
    "#discriminator_model.add(Conv1D(32, 3, activation='tanh', padding='same'))\n",
    "#discriminator_model.add(Dropout(0.7))\n",
    "#discriminator_model.add(Dense(len(chars), activation='relu'))\n",
    "#discriminator_model.add(LSTM(128, return_sequences=False))\n",
    "#discriminator_model.add(Flatten())\n",
    "#discriminator_model.add(Dropout(0.7))\n",
    "#discriminator_model.add(LSTM(256, dropout = 0.5, return_sequences=True, recurrent_dropout = 0.2))\n",
    "#discriminator_model.add(GRU(64))\n",
    "#discriminator_model.add(Flatten())\n",
    "#discriminator_model.add(Dense(len(chars), activation='softmax'))\n",
    "#discriminator_model.add(Dense(1, activation='sigmoid'))\n",
    "#discriminator_model.add(Dense(1024))\n",
    "#discriminator_model.add(LeakyReLU(0.2))\n",
    "#discriminator_model.add(Dense(512))\n",
    "#discriminator_model.add(LeakyReLU(0.2))\n",
    "#discriminator_model.add(Dropout(0.4))\n",
    "#discriminator_model.add(LSTM(256))\n",
    "#discriminator_model.add(Dropout(0.1))\n",
    "#discriminator_model.add(Dense(1))\n",
    "\n",
    "discriminator_model.add(GRU(64, use_bias=True, dropout=0.2, recurrent_dropout=0.2,\n",
    "                            input_shape=(maxlen, len(chars))))\n",
    "\n",
    "discriminator_model.add(Dense(1, activation='sigmoid'))\n",
    "#opt = RMSprop(lr=0.001)\n",
    "opt = Nadam(lr=0.001)\n",
    "# Setup the optimisation strategy.\n",
    "discriminator_model.compile(optimizer=opt,\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "                             \n",
    "print('compiled.')\n",
    "discriminator_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19500 samples, validate on 10500 samples\n",
      "Epoch 1/10\n",
      "19500/19500 [==============================] - 382s 20ms/step - loss: 0.6028 - acc: 0.6842 - val_loss: 0.5339 - val_acc: 0.7538\n",
      "Epoch 2/10\n",
      "19500/19500 [==============================] - 373s 19ms/step - loss: 0.5539 - acc: 0.7287 - val_loss: 0.4897 - val_acc: 0.7816\n",
      "Epoch 3/10\n",
      "19500/19500 [==============================] - 374s 19ms/step - loss: 0.5117 - acc: 0.7495 - val_loss: 0.4364 - val_acc: 0.8032\n",
      "Epoch 4/10\n",
      "19500/19500 [==============================] - 374s 19ms/step - loss: 0.4739 - acc: 0.7743 - val_loss: 0.4203 - val_acc: 0.8181\n",
      "Epoch 5/10\n",
      "19500/19500 [==============================] - 374s 19ms/step - loss: 0.4467 - acc: 0.7926 - val_loss: 0.3901 - val_acc: 0.8294\n",
      "Epoch 6/10\n",
      "19500/19500 [==============================] - 373s 19ms/step - loss: 0.4268 - acc: 0.8029 - val_loss: 0.3577 - val_acc: 0.8426\n",
      "Epoch 7/10\n",
      "19500/19500 [==============================] - 374s 19ms/step - loss: 0.4070 - acc: 0.8170 - val_loss: 0.3410 - val_acc: 0.8488\n",
      "Epoch 8/10\n",
      "19500/19500 [==============================] - 382s 20ms/step - loss: 0.3951 - acc: 0.8189 - val_loss: 0.3631 - val_acc: 0.8350\n",
      "Epoch 9/10\n",
      "19500/19500 [==============================] - 385s 20ms/step - loss: 0.3771 - acc: 0.8295 - val_loss: 0.3351 - val_acc: 0.8513\n",
      "Epoch 10/10\n",
      "19500/19500 [==============================] - 380s 19ms/step - loss: 0.3673 - acc: 0.8359 - val_loss: 0.3042 - val_acc: 0.8653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x266eafc3208>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x_train, x_test, y_train, y_test] = train_test_split(x, y, test_size=0.35, random_state=42)\n",
    "discriminator_model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, batch_size=4)\n",
    "#pltCallBack = PlotLossAccuracy()\n",
    "#discriminator_model.fit(x_train, y_train, \n",
    "#                        validation_data=(x_test, y_test), \n",
    "#                        epochs=3, batch_size=64,\n",
    "#                        callbacks=[pltCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.30\n",
      "Training Accuracy: 89.44%\n",
      "Validation Accuracy: 86.53%\n"
     ]
    }
   ],
   "source": [
    "# Once you're happy with your discriminator model, evaluate this cell to save it:\n",
    "save_model(discriminator_model, './discriminator_model.h5')\n",
    "# Run these commands in the terminal to submit your model for assessment.\n",
    "# git add lab-07/discriminator_model.h5\n",
    "# git commit -m \"Add/update discriminator model.\"\n",
    "# git push\n",
    "# submit-lab 7\n",
    "\n",
    "score,train = discriminator_model.evaluate(x_train, y_train, batch_size = 64, verbose=0)\n",
    "score,acc = discriminator_model.evaluate(x_test, y_test, batch_size = 64, verbose=0)\n",
    "print(\"Score: %.2f\" % (score))\n",
    "print(\"Training Accuracy: %.2f%%\" % (train*100))\n",
    "print(\"Validation Accuracy: %.2f%%\" % (acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
