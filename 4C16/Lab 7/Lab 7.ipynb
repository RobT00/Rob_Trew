{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 7 - Text generation with LSTM\n",
    "#\n",
    "# Step 1 (not assessed): build and train a model to generate text in the style of a corpus.\n",
    "#\n",
    "# Based on the Keras text generation example (https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py)\n",
    "#\n",
    "# Step 2: build a model to distinguish genuine from fake sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import essential modules\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Activation, Conv1D, Dropout, Flatten\n",
    "from keras.layers import CuDNNGRU, CuDNNLSTM\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.optimizers import RMSprop, Adam, Nadam, SGD\n",
    "from keras.models import Model, Sequential\n",
    "from keras.models import save_model\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras import initializers\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to sample an index from an array of predictions.\n",
    "#\n",
    "# The input array 'preds' should be the output of a text generation model.\n",
    "# The elements contain the values of the units in the final layer.\n",
    "# Each unit corresponds to a character in the text alphabet.\n",
    "# The final layer should have SoftMax activation, and thus the\n",
    "# value corresponds to the 'strength of prediction' of that character\n",
    "# as the next output value---so the maximum value indicates which character\n",
    "# is most strongly predicted (considerd most likely) as the next one.\n",
    "#\n",
    "def sample(preds, temperature=1.0):\n",
    "    # Convert to high-precision datatype (we are going to be manipulating some\n",
    "    # very small values in this function)\n",
    "    preds = np.asarray(preds).astype('float64')  \n",
    "    \n",
    "    # The next line has the effect of raising each prediction value to the power 1/T.\n",
    "    # It's done using logs to improve numerical precision.  This is a kind of value-dependent\n",
    "    # scaling: for T < 1.0 (1/T > 1.0), small values are made smaller (proportionally) than \n",
    "    # large values (unlike a linear scaling, such as multiplication by 0.9, which scales all values\n",
    "    # the same).\n",
    "    #\n",
    "    # Example: Consider that we have only two symbols (letters) in our alphabet, and our \n",
    "    # probabilities are [0.2, 0.8].  A temperature of 1.0 means 'do not adjust the\n",
    "    # probabilities at all', so in this case there will be a 20% chance that the \n",
    "    # function will return 'symbol 0' and an 80% chance  that it will return 'symbol 1'.\n",
    "    # Note that symbol 1 is 4x more likely than symbol 0.\n",
    "    #\n",
    "    # Now: if we supply a temperature of 0.5, our probabilites will be raised to the\n",
    "    # power 1/0.5 = 2, becoming [0.04, 0.64].  These will then be normalized to sum to 1,\n",
    "    # but anyway it is clear that symbol 1 is here 16x (the square of 4x) more likely than \n",
    "    # symbol 0.\n",
    "    #\n",
    "    # Conversely, for a temperature of 2, our probabilities will be raised to 0.5 (square-rooted),\n",
    "    # becoming [.4472, 0.8944] - and so here symbol 1 is only 2x (sqrt of 4x) more likely than\n",
    "    # symbol 0.\n",
    "    #\n",
    "    # So: low temperatures make the distribution peakier, exaggerating the difference between\n",
    "    # values.  High temperatures flatten the distribution, reducing the difference between values.\n",
    "    #\n",
    "    # As the return value is a sample of the manipulated distribution, manipulating it to\n",
    "    # be peakier (by supplying a low temperature) makes the sample more conservative, i.e.\n",
    "    # more likely to pick the highest-probability symbol.\n",
    "    #\n",
    "    # Making the distribution flatter (by suppyling a high temperature) causes the\n",
    "    # sample to be less conservative, i.e. more likely to pick some lower-likelihood\n",
    "    # symbol.\n",
    "    #\n",
    "    # Phew!\n",
    "    preds = np.exp(np.log(preds) / temperature)\n",
    "    \n",
    "    preds = preds / np.sum(preds)  # ensure that probs sum to 1\n",
    "    probas = np.random.multinomial(1, preds, 1)  # take 1 sample from the distribution\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original corpus length: 600901\n",
      "length for training: 480139\n"
     ]
    }
   ],
   "source": [
    "# Decide how much data to use for training.\n",
    "# You might want to reduce this to ~100k for faster experimentation, and then bring it back\n",
    "# to 600k when you're happy with your network architecture.\n",
    "# IMPORTANT: mke sure you end up with a 57-symbol alphabet after reducing the corpus size!\n",
    "# If the number of symbols (shown in the next cell) gets smaller than it was with the full\n",
    "# corpus, bring your sample size back up.  This is necessary because the encoding used for\n",
    "# training must match that used for assessment.\n",
    "#desired_num_chars = 600*1000  # Max: 600893\n",
    "desired_num_chars = 480139  # Max: 600893\n",
    "\n",
    "random.seed(43)  # Fix random seed for repeatable results.\n",
    "\n",
    "# Slurp down all of Nietzsche from Amazon.\n",
    "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path).read().lower()\n",
    "print('original corpus length:', len(text))\n",
    "\n",
    "start_index = random.randint(0, len(text) - desired_num_chars - 1)\n",
    "text = text[start_index:start_index + desired_num_chars]\n",
    "text\n",
    "print('length for training:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tle stone; all the greater need is there of\n",
      "a courage that is not ashamed of such humble labor and that will oppose\n",
      "persistence, to all contempt. it is, finally, also true that countless\n",
      "single observations concerning the human, all-too-human, have been\n",
      "first made and uttered in circles accustomed, not to furnish matter for\n",
      "scientific knowledge, but for intellectual pleasure-seeking; and the\n",
      "original home atmosphere--a very seductive atmosphere--of the moral\n",
      "maxim has almost inextricably interpenetrated the entire species, so\n",
      "that the scientific man involuntarily manifests a sort of mistrust of\n",
      "this species and of its seriousness. but it is sufficient to point to\n",
      "the consequences: for already it is becoming evident that events of the\n",
      "most portentous nature are developing in the domain of psychological\n",
      "observation. what is the leading conclusion arrived at by one of the\n",
      "subtlest and calmest of thinkers, the author of the work \"concerning the\n",
      "origin of the moral feelings\", as a result of\n"
     ]
    }
   ],
   "source": [
    "# Let's have a quick look at a random exceprt.\n",
    "#\n",
    "# Caution: Nietzsche might drive you mad: dare you behold more than 1000 of his terrible chars..? \n",
    "sample_length = 1000\n",
    "\n",
    "random.seed(None)  # Seeds random from current time (so re-eval this cell for a new sample).\n",
    "\n",
    "start_index = random.randint(0, len(text) - sample_length - 1)\n",
    "print(text[start_index:start_index+sample_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 57\n",
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¤', '¦', '«', 'ã']\n"
     ]
    }
   ],
   "source": [
    "# Establish the alphabet (set of symbols) we are going to use.\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "print(chars)\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))  # Map to look up index of a particular char (e.g. x['a'] = 0)\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))  # Map to look up char at an index (e.g. x[0] = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 160033\n"
     ]
    }
   ],
   "source": [
    "# Establish a training set of semi-redundant (i.e. overlapping) sequences of maxlen characters.\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []  # Not syntactic sentences, but just sequences of 40 chars pulled from the corpus.\n",
    "next_chars = [] # next_chars[n] stores the character which followed sentences[n]\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160033, 40, 57)\n",
      "(160033, 57)\n"
     ]
    }
   ],
   "source": [
    "# Convert the data to one-hot encoding.\n",
    "# 'x' will contain the one-hot encoding of the training 'sentences'.\n",
    "# 'y' will contain the one-hot encoding of the 'next char' for each sentence.\n",
    "#\n",
    "# \n",
    "# Let's consider that we have N sentences of length L:\n",
    "#\n",
    "# The 'native' encoding is an NxL matrix where element [n][l]\n",
    "# is the symbol index for character at index (l) of sentence (n)\n",
    "# (e.g., say, 5, corresponding to 'e').\n",
    "#\n",
    "# The one-hot encoding is an NxLxS matrix, where S is the \n",
    "# number of symbols in the alphabet, such that element [n][l][s]\n",
    "# is 1 if the character at index (l) in sentence (n) has the\n",
    "# symbol index (s), and 0 otherwise.\n",
    "def onehot_encode(sentence, maxlen):\n",
    "    x = np.zeros((maxlen, len(chars)), dtype=np.bool)\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[t, char_indices[char]] = 1\n",
    "    return x\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    x[i,:,:] = onehot_encode(sentence, maxlen)\n",
    "    y[i, :] = onehot_encode(next_chars[i], 1)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the generator model: a single GRU layer with 128 cells.\n",
    "generator_model = Sequential()\n",
    "generator_model.add(GRU(128, input_shape=(maxlen, len(chars))))\n",
    "generator_model.add(Dense(len(chars)))\n",
    "generator_model.add(Activation('softmax'))\n",
    "\n",
    "# You could experiment with NAdam instead of RMSProp.\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "generator_model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "trained_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence_list(seed_list, length=400, temperature=0.25):\n",
    "    sentence_list_1 = [];\n",
    "    sentence_list_2 = [];\n",
    "    sentence_list_3 = [];\n",
    "    generated_list_1 = [];\n",
    "    generated_list_2 = [];\n",
    "    generated_list_3 = [];\n",
    "    n = len(seed_list)\n",
    "    # copy lists\n",
    "    temperature_1 = temperature\n",
    "    temperature_2 = (temperature + 0.005)\n",
    "    temperature_3 = max(0.01, (temperature - 0.005))\n",
    "    for seed in seed_list:\n",
    "        sentence_list_1.append(seed[:])\n",
    "        sentence_list_2.append(seed[:])\n",
    "        sentence_list_3.append(seed[:])\n",
    "        generated_list_1.append(seed[:])\n",
    "        generated_list_2.append(seed[:]) \n",
    "        generated_list_3.append(seed[:]) \n",
    "    \n",
    "    for i in range(length):\n",
    "      \n",
    "        workdone = (i+1)*1.0 / length\n",
    "        sys.stdout.write(\"\\rgenerating sentences: [{0:20s}] {1:.1f}%\".format('#' * int(workdone * 20), workdone*100))\n",
    "        sys.stdout.flush()\n",
    "            \n",
    "        x_pred_list = np.zeros((n, maxlen, len(chars)))\n",
    "        for j, sentence in enumerate(sentence_list_1):\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred_list[j, t, char_indices[char]] = 1.\n",
    "\n",
    "        start = time.time()\n",
    "        pred_list = generator_model.predict(x_pred_list, verbose=0)\n",
    "        end = time.time()\n",
    "\n",
    "        for j in range(n):\n",
    "            next_index_1 = sample(pred_list[j,:], temperature_1)\n",
    "            next_char_1 = indices_char[next_index_1]\n",
    "            generated_list_1[j] += next_char_1\n",
    "            sentence_list_1[j] = sentence_list_1[j][1:] + next_char_1\n",
    "            next_index_2 = sample(pred_list[j,:], temperature_2)\n",
    "            next_char_2 = indices_char[next_index_2]\n",
    "            generated_list_2[j] += next_char_2\n",
    "            sentence_list_2[j] = sentence_list_2[j][1:] + next_char_2\n",
    "            next_index_3 = sample(pred_list[j,:], temperature_3)\n",
    "            next_char_3 = indices_char[next_index_3]\n",
    "            generated_list_3[j] += next_char_3\n",
    "            sentence_list_3[j] = sentence_list_3[j][1:] + next_char_3\n",
    "    \n",
    "    sys.stdout.write(' - done\\n')\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    generated_list = generated_list_1 + generated_list_2 + generated_list_3\n",
    "    return generated_list\n",
    "\n",
    "def print_sentences(seeds, sentences):\n",
    "    for seed, sentence in zip(seeds, sentences):\n",
    "        print('-'*5)\n",
    "        sys.stdout.write('\\x1b[32m')\n",
    "        sys.stdout.write(sentence[0:len(seed)])\n",
    "        sys.stdout.write('\\x1b[34m')\n",
    "        sys.stdout.write(sentence[len(seed):-1])\n",
    "        sys.stdout.write('\\x1b[m')\n",
    "        sys.stdout.write('\\n')    \n",
    "        sys.stdout.flush()\n",
    "        \n",
    "def pick_sentences(n, maxlen):\n",
    "    global text    \n",
    "    start_index_list = np.random.randint(len(text) - maxlen - 1, size=(1, n)).flatten().tolist()\n",
    "    seed_list = [] \n",
    "    for start_index in start_index_list:\n",
    "        seed_list.append(text[start_index: start_index + maxlen])\n",
    "    return seed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 45s 284us/step - loss: 2.28190s - loss: 2.2\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 15s 91us/step - loss: 1.8151: 0s - loss: 1.81\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 14s 88us/step - loss: 1.6689\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 14s 90us/step - loss: 1.5860\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 15s 92us/step - loss: 1.5336\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 19s 121us/step - loss: 1.4971\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 18s 110us/step - loss: 1.4689\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 15s 94us/step - loss: 1.4466\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 3\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 17s 103us/step - loss: 1.4298\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 16s 101us/step - loss: 1.4154\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 15s 91us/step - loss: 1.4036\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 14s 90us/step - loss: 1.3925\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 4\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 15s 97us/step - loss: 1.3853\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 16s 101us/step - loss: 1.37690s - loss\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 16s 99us/step - loss: 1.3696\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 14s 88us/step - loss: 1.3660\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 5\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 14s 88us/step - loss: 1.3584\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 15s 91us/step - loss: 1.3569\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 16s 101us/step - loss: 1.3526\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 17s 104us/step - loss: 1.3471\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 6\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 17s 105us/step - loss: 1.3451\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 15s 92us/step - loss: 1.3437\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 14s 89us/step - loss: 1.3413\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 15s 92us/step - loss: 1.3378\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 7\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 22s 138us/step - loss: 1.3321\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 15s 96us/step - loss: 1.3290\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 16s 98us/step - loss: 1.3257 1s -\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 16s 99us/step - loss: 1.3238\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 8\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 17s 106us/step - loss: 1.3207\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - 17s 106us/step - loss: 1.3186\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 17s 109us/step - loss: 1.3163\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 16s 101us/step - loss: 1.3127\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 9\n",
      "Epoch 1/4\n",
      "160033/160033 [==============================] - 18s 113us/step - loss: 1.31158s - l\n",
      "Epoch 2/4\n",
      "160033/160033 [==============================] - ETA: 0s - loss: 1.310 - 18s 113us/step - loss: 1.3103\n",
      "Epoch 3/4\n",
      "160033/160033 [==============================] - 16s 97us/step - loss: 1.3064\n",
      "Epoch 4/4\n",
      "160033/160033 [==============================] - 15s 91us/step - loss: 1.3056\n"
     ]
    }
   ],
   "source": [
    "# Generate 3 seeds which we will use to inspect the progress of our training:\n",
    "#preview_seeds = pick_sentences(3, maxlen=40)\n",
    "\n",
    "# Train the model, output generated text after each iteration\n",
    "for iteration in range(1, 10):\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print('Iteration', iteration)\n",
    "    generator_model.fit(x, y,\n",
    "                  batch_size=1024,\n",
    "                  epochs=4)\n",
    "\n",
    "    #generated_sentences = generate_sentence_list(preview_seeds)\n",
    "    #print_sentences(preview_seeds, generated_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating sentences: [####################] 100.0% - done\n",
      "-----\n",
      "\u001b[32med\n",
      "to place the greatness of man, the co\u001b[34mmmonism of the species of the soul, whi\u001b[m\n",
      "-----\n",
      "\u001b[32md, the\n",
      "genius of the race overflowing fr\u001b[34mom the desires, and in all the stronger\u001b[m\n",
      "-----\n",
      "\u001b[32med at, it is always well (and wise) to f\u001b[34minest and profound the will to be under\u001b[m\n",
      "-----\n",
      "\u001b[32m marksmen who again and again hit the bl\u001b[34mindicists and speaking that is a desire\u001b[m\n",
      "-----\n",
      "\u001b[32mexceptional cases of\n",
      "wise old codgers an\u001b[34md spirit, as a master, or the sense of \u001b[m\n",
      "-----\n",
      "\u001b[32mhilosophers on the old\n",
      "conception of the\u001b[34m astiminal spirit, as a master and astu\u001b[m\n",
      "-----\n",
      "\u001b[32m defined and designated according to\n",
      "its\u001b[34m of the species of a caster and asturin\u001b[m\n",
      "-----\n",
      "\u001b[32m to presuppose two centuries of music\n",
      "as\u001b[34mcestations, as a kindistic preservite a\u001b[m\n",
      "-----\n",
      "\u001b[32mentional and as a charm, that one should\u001b[34m be involonce about the fastionours of \u001b[m\n",
      "-----\n",
      "\u001b[32m the knowledge but the welfare of human \u001b[34mhimself, and with stronger and invent a\u001b[m\n",
      "-----\n",
      "\u001b[32mysiokolax was a popular\n",
      "name for an acto\u001b[34mrs and species, as a master as a morali\u001b[m\n",
      "-----\n",
      "\u001b[32mrwinists and anti-teleologists among the\u001b[34m the passion of the sighineswition, whi\u001b[m\n",
      "-----\n",
      "\u001b[32m own inclination, and often enough again\u001b[34mst the species of the extent and deeper\u001b[m\n",
      "-----\n",
      "\u001b[32mnstrosities\n",
      "are called in, until finally\u001b[34m as in the same and species, and as it \u001b[m\n",
      "-----\n",
      "\u001b[32m of continuing and propagating themselve\u001b[34ms and and perspace in all of the highes\u001b[m\n",
      "-----\n",
      "\u001b[32mxteenth and seventeenth centuries, its p\u001b[34mrocess and asturing of the species, as \u001b[m\n",
      "-----\n",
      "\u001b[32mtions, not the knowledge but the welfare\u001b[34mfourde of the speaking to be individual\u001b[m\n",
      "-----\n",
      "\u001b[32m\n",
      "myself, as is sufficiently agreeable to\u001b[34mo partience, and as in all one of the s\u001b[m\n",
      "-----\n",
      "\u001b[32mon that is as a door and vestibule to\n",
      "dr\u001b[34meady and spirit, and in all spirit, as \u001b[m\n",
      "-----\n",
      "\u001b[32m descent; the ancestors, the\n",
      "\"blood,\" de\u001b[34msiress and assurary, as a man of at a p\u001b[m\n",
      "-----\n",
      "\u001b[32motent new\n",
      "motives can not, usually, pres\u001b[34merve of all spirit, as it is a discours\u001b[m\n",
      "-----\n",
      "\u001b[32mto hate in proportion as she--forgets ho\u001b[34mnour with still in the sense of the ind\u001b[m\n",
      "-----\n",
      "\u001b[32mn, therefore it is false. the free spiri\u001b[34mtable asking morality as a morality as \u001b[m\n",
      "-----\n",
      "\u001b[32mtion upon\n",
      "exceptional cases, i mean upon\u001b[34m the formerly, as a creater the individ\u001b[m\n",
      "-----\n",
      "\u001b[32ms\" to be noble, to wish to be\n",
      "apart, to \u001b[34mbe incomparising and spirit, as it is a\u001b[m\n",
      "-----\n",
      "\u001b[32m silence, and\n",
      "of solitude. asceticism an\u001b[34md development of a meaning of the indiv\u001b[m\n",
      "-----\n",
      "\u001b[32mhat forces us in general to the supposit\u001b[34mion of the stronger astiminal, in all t\u001b[m\n",
      "-----\n",
      "\u001b[32mear them, without being predestined for \u001b[34mall suffering to as a master and assure\u001b[m\n",
      "-----\n",
      "\u001b[32mpolitics. here and there\n",
      "they wish even \u001b[34min all spirit, as a great same and pain\u001b[m\n",
      "-----\n",
      "\u001b[32merein it\n",
      "sees its conditions of life, it\u001b[34m is a god, as it is and astiminal spiri\u001b[m\n",
      "-----\n",
      "\u001b[32mnothing genuine about them\" (for dionysi\u001b[34mon of the same assuredly as a great sam\u001b[m\n",
      "-----\n",
      "\u001b[32mwhile copernicus\n",
      "has persuaded us to bel\u001b[34mieve in vainical suffering of the passi\u001b[m\n",
      "-----\n",
      "\u001b[32mcal,\"\n",
      "as old kant wished (consequently t\u001b[34mo the stronger stronger and spirit, as \u001b[m\n",
      "-----\n",
      "\u001b[32m have\n",
      "our virtues, is not to be disputed\u001b[34m to as a meaning of the same and askini\u001b[m\n",
      "-----\n",
      "\u001b[32man attacks himself.\n",
      "\n",
      "77. with his princi\u001b[34mplating and the fangen! and it is a des\u001b[m\n",
      "-----\n",
      "\u001b[32mor as a temporary resting-place. his pec\u001b[34mies--it is strogising as a knowledge of\u001b[m\n",
      "-----\n",
      "\u001b[32ms and curiosity, of which, for example, \u001b[34mand spirit, as it is askine and speakin\u001b[m\n",
      "-----\n",
      "\u001b[32mwhich together have constituted the\n",
      "genu\u001b[34mred and askinity, as a man as a problem\u001b[m\n",
      "-----\n",
      "\u001b[32mvery for the most spiritual and the most\u001b[34m discours of the possibility as a prese\u001b[m\n",
      "-----\n",
      "\u001b[32mview. both are simply sublimations in wh\u001b[34mich as it is proper is and askining and\u001b[m\n",
      "-----\n",
      "\u001b[32metation of phenomena.\n",
      "\n",
      "109. the criminal\u001b[34mless as the same assumptional stronger \u001b[m\n",
      "-----\n",
      "\u001b[32mures like ourselves; though they still m\u001b[34man in artists and askinity as a man, as\u001b[m\n",
      "-----\n",
      "\u001b[32ma good name, the perpetual ratification \u001b[34mof a desires and which is a mistaking, \u001b[m\n",
      "-----\n",
      "\u001b[32misguise, for a\n",
      "cloak, in short, for an o\u001b[34mne in the being questionally as a profo\u001b[m\n",
      "-----\n",
      "\u001b[32mhed: on\n",
      "the contrary that feeling seems \u001b[34mto be respect to be lives, and as it is\u001b[m\n",
      "-----\n",
      "\u001b[32mhumanitarian adjustment and perversion o\u001b[34mf the same strogging and stronger astur\u001b[m\n",
      "-----\n",
      "\u001b[32mrlooked: hence we have here defective th\u001b[34me individually, as in the same and asce\u001b[m\n",
      "-----\n",
      "\u001b[32mat they\n",
      "had to do! and to shatter the st\u001b[34mronger spirit, as a discourd discourse \u001b[m\n",
      "-----\n",
      "\u001b[32msis\n",
      "which has been made by thinking itse\u001b[34mlf as a moralist in variation, as a mas\u001b[m\n",
      "-----\n",
      "\u001b[32my great relapses, but\n",
      "will perhaps just \u001b[34mas a meant to desires, and as it is a m\u001b[m\n",
      "-----\n",
      "\u001b[32mdespiser.\n",
      "\n",
      "79. a soul which knows that i\u001b[34ms a despecting and asturing soul, as a \u001b[m\n",
      "-----\n",
      "\u001b[32moes the first plausible\n",
      "hypothesis of th\u001b[34me scholar, as a master as a man in aris\u001b[m\n",
      "-----\n",
      "\u001b[32msent--this belongs to the tendency and\n",
      "f\u001b[34mrench askinity and account is a claised\u001b[m\n",
      "-----\n",
      "\u001b[32mion of his whole course,\n",
      "anything to ser\u001b[34mve as a preservite in a man as a kindio\u001b[m\n",
      "-----\n",
      "\u001b[32mf one free him from error one will neces\u001b[34msariness as a master as a master and sp\u001b[m\n",
      "-----\n",
      "\u001b[32mpinings of youth that might not understa\u001b[34mnd and man in aristoperhapinitional sen\u001b[m\n",
      "-----\n",
      "\u001b[32me, and at the same time, not bring out a\u001b[34mnd spirit, and as a master as a singles\u001b[m\n",
      "-----\n",
      "\u001b[32mome to pass.\n",
      "therefore: only because man\u001b[34m in the same and problems, where have a\u001b[m\n",
      "-----\n",
      "\u001b[32me another, and that the most powerful an\u001b[34md asturing and state of a desires and a\u001b[m\n",
      "-----\n",
      "\u001b[32mng of pleasure in willing--they are doub\u001b[34mt of the same species of the history of\u001b[m\n",
      "-----\n",
      "\u001b[32m185. \"i dislike him.\"--why?--\"i am not a\u001b[34ms a master and desiress and spirit, as \u001b[m\n",
      "-----\n",
      "\u001b[32me degree and nature of a man's sensualit\u001b[34my of the gradiations and existence, and\u001b[m\n",
      "-----\n",
      "\u001b[32m. a question by the way: a pessimist, a\n",
      "\u001b[34mmaster and spirit, as it is a discours \u001b[m\n",
      "-----\n",
      "\u001b[32mthout a comparison of\n",
      "reality with the p\u001b[34massion of a conditions and askining and\u001b[m\n",
      "-----\n",
      "\u001b[32mhe world\n",
      "would be left after it had been\u001b[34m assured and ask of all the individuall\u001b[m\n",
      "-----\n",
      "\u001b[32mled 'humility,' and also\n",
      "'modesty').\" or\u001b[34m with as a master and spirit, as it wil\u001b[m\n",
      "-----\n",
      "\u001b[32me\n",
      "symptom of the increased weakening and\u001b[34m asturing of the soul, as it is a condi\u001b[m\n",
      "-----\n",
      "\u001b[32msympathy! there is nowadays, throughout \u001b[34mit is a discours of the will to be long\u001b[m\n",
      "-----\n",
      "\u001b[32me scholar in\n",
      "his superiority, in the goo\u001b[34md and species of the \"instinct, as a \"e\u001b[m\n",
      "-----\n",
      "\u001b[32mm\n",
      "science when it put the question: what\u001b[34m is a disclosis himself, and as it is a\u001b[m\n",
      "-----\n",
      "\u001b[32m\n",
      "preponderance of the pre-aryan element \u001b[34mand spirit, and as a kindifyinationally\u001b[m\n",
      "-----\n",
      "\u001b[32mis\n",
      "body--that is to say, contrary, and o\u001b[34mf the soul, as a master as in all one a\u001b[m\n",
      "-----\n",
      "\u001b[32mt importunely, to be insorbed and\n",
      "absorb\u001b[34mine in the same and being with a though\u001b[m\n",
      "-----\n",
      "\u001b[32mlism.\n",
      "what is clear, what is \"explained\"\u001b[34m--as a stronger still morality of the s\u001b[m\n",
      "-----\n",
      "\u001b[32mviduals and pure\n",
      "souled beings, if their\u001b[34m word as a master as a singliness of a \u001b[m\n",
      "-----\n",
      "\u001b[32mgrappling hook of\n",
      "knowledge; to that mat\u001b[34miring and asturing of the passion as a \u001b[m\n",
      "-----\n",
      "\u001b[32mn humane people may desire, they will no\u001b[34mt be a god as a meaning of the same and\u001b[m\n",
      "-----\n",
      "\u001b[32me englishmen--i may mention darwin, john\u001b[34m as a master, in the fact they are as a\u001b[m\n",
      "-----\n",
      "\u001b[32mthe criminal is often enough not equal t\u001b[34mhat is a man and and astultical stronge\u001b[m\n",
      "-----\n",
      "\u001b[32mvexation. let us examine more closely: w\u001b[34mhat is a discours profound to the sighi\u001b[m\n",
      "-----\n",
      "\u001b[32m study physiology with a clear conscienc\u001b[34me, and being with a single and being in\u001b[m\n",
      "-----\n",
      "\u001b[32mt of the subject or the\n",
      "object. i would \u001b[34mbe one and askinity as a master and des\u001b[m\n",
      "-----\n",
      "\u001b[32mously--and even\n",
      "himself--only in relatio\u001b[34mn with a perio-disiness to be desires, \u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "\u001b[32mkes prominent, and falsifies for itself\n",
      "\u001b[34mbecause in the sense of the passive as \u001b[m\n",
      "-----\n",
      "\u001b[32mkind will reveal that it is by no means\n",
      "\u001b[34mof the involvest of the same spirit, as\u001b[m\n",
      "-----\n",
      "\u001b[32meded in\n",
      "severing the whole of the last g\u001b[34mradity and speaking and history as a gr\u001b[m\n",
      "-----\n",
      "\u001b[32mf supreme justice, the art of commanding\u001b[34m and desires, and a man as a master as \u001b[m\n",
      "-----\n",
      "\u001b[32mes not believe\n",
      "that a philosopher--suppo\u001b[34msinized and preservituation of the will\u001b[m\n",
      "-----\n",
      "\u001b[32midable\n",
      "filth of all political agitation.\u001b[34m\n",
      "\n",
      "133. in this passion as a singles and\u001b[m\n",
      "-----\n",
      "\u001b[32mrefore it is true.\n",
      "\n",
      "[17] sache, thing bu\u001b[34mt in all oneself as the same stronger a\u001b[m\n",
      "-----\n",
      "\u001b[32my day: and the dream-fancy does exactly \u001b[34mand the deniarest and spirit, as in thi\u001b[m\n",
      "-----\n",
      "\u001b[32mendation for a defect.\n",
      "(as the opposite \u001b[34mwished as a kindiousical asturing and s\u001b[m\n",
      "-----\n",
      "\u001b[32mnd whatever these honest advocates of \"m\u001b[34moralizaning morality of \"standing of th\u001b[m\n",
      "-----\n",
      "\u001b[32mtant_, as, for example, our notions of t\u001b[34mhe highest and preservite and species o\u001b[m\n",
      "-----\n",
      "\u001b[32mty before god,\" have hitherto swayed\n",
      "the\u001b[34m species of the fact they are as in all\u001b[m\n",
      "-----\n",
      "\u001b[32mm error? the metaphysical philosophy for\u001b[34m a preservite and askinity and desires \u001b[m\n",
      "-----\n",
      "\u001b[32mo mankind,\n",
      "without any redeeming intenti\u001b[34mon of the facting of the philosopher, i\u001b[m\n",
      "-----\n",
      "\u001b[32mhimself, and hence\n",
      "affords a clue to the\u001b[34m sense of the will the same and profoun\u001b[m\n",
      "-----\n",
      "\u001b[32mall secrecy and reverence my first-fruit\u001b[34m--and which is a man in artisted that i\u001b[m\n",
      "-----\n",
      "\u001b[32mbject to the same necessity, would be ju\u001b[34mst as it is a man as it is the same ask\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# For a more complete inspection, print out a load of sentences:\n",
    "#\n",
    "num_sentences = 100             # how many to generate\n",
    "sentence_length = 40            # 100--400 is good\n",
    "sample_temperature = 0.25       # see discussion of temperature up near the top\n",
    "#sample_temperature = 0.1\n",
    "\n",
    "start_index_list = np.random.randint(len(text) - maxlen - 1, size=(1, num_sentences)).flatten().tolist()\n",
    "preview_seeds = [] \n",
    "for start_index in start_index_list:\n",
    "    preview_seeds.append(text[start_index: start_index + maxlen])\n",
    "\n",
    "generated_sentences = generate_sentence_list(preview_seeds, length=sentence_length, temperature=sample_temperature); \n",
    "print_sentences(preview_seeds, generated_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just a checkpoint, which will let you download and re-upload (or add to git) this model.\n",
    "save_model(generator_model, './generator_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating sentences: [####################] 100.0% - done\n"
     ]
    }
   ],
   "source": [
    "# Generating the training fake sentences for the Discriminator network\n",
    "#\n",
    "# These are saved to the file 'fake.pkl' -- you could download this to your\n",
    "# user drive and re-upload it in a subsequent session, to save regenerating\n",
    "# it again (in which case you don't need to evaluate this cell).\n",
    "\n",
    "#training_seeds = pick_sentences(3000, maxlen=40)\n",
    "training_seeds = pick_sentences(5000, maxlen=40)\n",
    "training_generated_sentences = generate_sentence_list(training_seeds, length=40)\n",
    "# Strip out the initial 40 chars (the seed sequence, which is genuine data from the corpus).\n",
    "for i, sentence in enumerate(training_generated_sentences):\n",
    "    training_generated_sentences[i] = sentence[40:40+40]\n",
    "    \n",
    "output = open('fake.pkl', 'wb')\n",
    "pickle.dump(training_seeds, output)\n",
    "pickle.dump(training_generated_sentences, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training set from the file\n",
    "pkl_file = open('fake.pkl', 'rb')\n",
    "training_seeds = pickle.load(pkl_file)\n",
    "training_generated_sentences = pickle.load(pkl_file)\n",
    "pkl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num generated:  15000\n",
      "All training sequences:  30000\n"
     ]
    }
   ],
   "source": [
    "# Make a 50:50 set of 'fake' (generated) and genuine sentences:\n",
    "num_generated = len(training_generated_sentences)\n",
    "print('Num generated: ', num_generated)\n",
    "training_real_sentences = pick_sentences(num_generated, maxlen=40)\n",
    "\n",
    "all_training_sentences = training_generated_sentences + training_real_sentences\n",
    "\n",
    "n = len(all_training_sentences)\n",
    "x = np.zeros((n, 40, len(chars)))\n",
    "y = np.zeros((n, 1))\n",
    "print('All training sequences: ', n)\n",
    "\n",
    "for i, sentence in enumerate(all_training_sentences):\n",
    "    x[i, :, :] = onehot_encode(sentence, maxlen=40)\n",
    "y[num_generated:] = 1  # Encodes the fact that sentences with indexes larger than (num_generated) are real.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotLossAccuracy(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.acc = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.val_acc = []\n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(int(self.i))\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        \n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(16, 6))\n",
    "        plt.plot([1, 2])\n",
    "        plt.subplot(121) \n",
    "        plt.plot(self.x, self.losses, label=\"train loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"validation loss\")\n",
    "        plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.title('Model Loss')\n",
    "        plt.legend()\n",
    "        plt.subplot(122)         \n",
    "        plt.plot(self.x, self.acc, label=\"training accuracy\")\n",
    "        plt.plot(self.x, self.val_acc, label=\"validation accuracy\")\n",
    "        plt.legend()\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "compiled.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_37 (LSTM)               (None, 128)               95232     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 95,361\n",
      "Trainable params: 95,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "\n",
    "# Define some layers here..\n",
    "\n",
    "# Use your layers to create the model.\n",
    "discriminator_model = Sequential()\n",
    "#discriminator_model.add(LSTM(128, dropout=0.6, recurrent_dropout=0.7,\n",
    "#                            input_shape=(maxlen, len(chars))))\n",
    "#discriminator_model.add(LSTM(256, dropout=0.0, recurrent_dropout=0.01,\n",
    "#                             kernel_regularizer=l2(0.2),\n",
    "#                             input_shape=(maxlen, len(chars))))\n",
    "\n",
    "#inputs = Input(shape=(40, 59))\n",
    "#h = LSTM(256)(inputs)\n",
    "#h = Dropout(0.2)(h)\n",
    "#h = Dense(1024, activation='relu')(h)\n",
    "#h = LSTM(256, return_sequences=False)(h)\n",
    "#h = Dense(512, activation='tanh')(h)\n",
    "\n",
    "#output = Dense(1, activation='softmax')(h)\n",
    "\n",
    "discriminator_model = Sequential()\n",
    "#discriminator_model.add(Embedding(4020, 40, input_length=59))\n",
    "discriminator_model.add(LSTM(128, dropout = 0.2, return_sequences=False, \n",
    "                             recurrent_dropout = 0.2, input_shape=(maxlen, len(chars)), unit_forget_bias=True,\n",
    "                             kernel_regularizer=l1(0.01), recurrent_regularizer=l2(0.01)))\n",
    "#discriminator_model.add(LSTM(256, recurrent_dropout=0.0, return_sequences=False, input_shape=(maxlen, len(chars))))\n",
    "#discriminator_model.add(LSTM(128, return_sequences=True))\n",
    "#discriminator_model.add(Conv1D(64, 5, activation='relu', padding='valid', input_shape=(maxlen, len(chars))))\n",
    "#discriminator_model.add(Conv1D(32, 3, activation='tanh', padding='same'))\n",
    "#discriminator_model.add(Dropout(0.7))\n",
    "#discriminator_model.add(Dense(len(chars), activation='relu'))\n",
    "#discriminator_model.add(LSTM(128, return_sequences=False))\n",
    "#discriminator_model.add(Flatten())\n",
    "#discriminator_model.add(Dropout(0.7))\n",
    "#discriminator_model.add(LSTM(256, dropout = 0.5, return_sequences=True, recurrent_dropout = 0.2))\n",
    "#discriminator_model.add(GRU(64))\n",
    "#discriminator_model.add(Flatten())\n",
    "#discriminator_model.add(Dense(len(chars), activation='relu'))\n",
    "#discriminator_model.add(Dense(1, activation='sigmoid'))\n",
    "#discriminator_model.add(Dense(1024))\n",
    "#discriminator_model.add(LeakyReLU(0.2))\n",
    "#discriminator_model.add(Dense(512))\n",
    "#discriminator_model.add(LeakyReLU(0.2))\n",
    "discriminator_model.add(Dropout(0.4))\n",
    "#discriminator_model.add(Dense(1))\n",
    "\n",
    "discriminator_model.add(Dense(1, activation='sigmoid'))\n",
    "opt = RMSprop(lr=0.01)\n",
    "\n",
    "# Setup the optimisation strategy.\n",
    "discriminator_model.compile(optimizer='Adam',\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "                             \n",
    "print('compiled.')\n",
    "discriminator_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22500 samples, validate on 7500 samples\n",
      "Epoch 1/4\n",
      "22500/22500 [==============================] - 50s 2ms/step - loss: 2.3440 - acc: 0.5101 - val_loss: 0.7294 - val_acc: 0.4945\n",
      "Epoch 2/4\n",
      "22500/22500 [==============================] - 43s 2ms/step - loss: 0.7290 - acc: 0.5012 - val_loss: 0.7291 - val_acc: 0.5055\n",
      "Epoch 3/4\n",
      "22500/22500 [==============================] - 43s 2ms/step - loss: 0.7286 - acc: 0.4985 - val_loss: 0.7280 - val_acc: 0.5055\n",
      "Epoch 4/4\n",
      "22500/22500 [==============================] - 43s 2ms/step - loss: 0.7282 - acc: 0.5026 - val_loss: 0.7282 - val_acc: 0.4945\n"
     ]
    }
   ],
   "source": [
    "[x_train, x_test, y_train, y_test] = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "discriminator_model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=4, batch_size=64)\n",
    "pltCallBack = PlotLossAccuracy()\n",
    "#discriminator_model.fit(x_train, y_train, \n",
    "#                        validation_data=(x_test, y_test), \n",
    "#                        epochs=3, batch_size=64,\n",
    "#                        callbacks=[pltCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.73\n",
      "Training Accuracy: 50.18%\n",
      "Validation Accuracy: 49.45%\n"
     ]
    }
   ],
   "source": [
    "# Once you're happy with your discriminator model, evaluate this cell to save it:\n",
    "save_model(discriminator_model, './discriminator_model.h5')\n",
    "# Run these commands in the terminal to submit your model for assessment.\n",
    "# git add lab-07/discriminator_model.h5\n",
    "# git commit -m \"Add/update discriminator model.\"\n",
    "# git push\n",
    "# submit-lab 7\n",
    "\n",
    "score,train = discriminator_model.evaluate(x_train, y_train, batch_size = 64, verbose=0)\n",
    "score,acc = discriminator_model.evaluate(x_test, y_test, batch_size = 64, verbose=0)\n",
    "print(\"Score: %.2f\" % (score))\n",
    "print(\"Training Accuracy: %.2f%%\" % (train*100))\n",
    "print(\"Validation Accuracy: %.2f%%\" % (acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
